{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.39058902859687805\n",
      "Epoch finished in 13.1 seconds\n",
      "Train loss: 0.8892921560340458, Valid loss: 0.7887055277824402, IoU: 0.6312088370323181, Prec: 0.7268484234809875, Rec 0.831296443939209\n",
      "Epoch 2/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.20177322626113892\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.33689122597376503, Valid loss: 0.4741237163543701, IoU: 0.6748331189155579, Prec: 0.8000057339668274, Rec 0.8140961527824402\n",
      "Epoch 3/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.23615537583827972\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.2601142668061786, Valid loss: 0.372917115688324, IoU: 0.6634646654129028, Prec: 0.7638950347900391, Rec 0.8364362716674805\n",
      "Epoch 4/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.23224087059497833\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.23877198199431102, Valid loss: 0.3254929184913635, IoU: 0.6789608597755432, Prec: 0.7723559141159058, Rec 0.8508045077323914\n",
      "Epoch 5/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.19592081010341644\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.22728449338012272, Valid loss: 0.3005802035331726, IoU: 0.6870511770248413, Prec: 0.775997519493103, Rec 0.8589841723442078\n",
      "Epoch 6/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16635416448116302\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.21852663987212712, Valid loss: 0.29047083854675293, IoU: 0.6912155151367188, Prec: 0.7797907590866089, Rec 0.8606487512588501\n",
      "Epoch 7/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.20322860777378082\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.2141379412677553, Valid loss: 0.2851601243019104, IoU: 0.6971951723098755, Prec: 0.7872881889343262, Rec 0.8607996106147766\n",
      "Epoch 8/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.3875901699066162\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.20926135645972357, Valid loss: 0.2796901762485504, IoU: 0.7057332396507263, Prec: 0.8010480999946594, Rec 0.8575149774551392\n",
      "Epoch 9/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13157948851585388\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.20623669160736932, Valid loss: 0.2757205665111542, IoU: 0.7072766423225403, Prec: 0.8032062649726868, Rec 0.8572379350662231\n",
      "Epoch 10/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.24637298285961154\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.20605738792154524, Valid loss: 0.27217525243759155, IoU: 0.70734041929245, Prec: 0.7967039346694946, Rec 0.864851176738739\n",
      "Epoch 11/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15856400132179263\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.20054246650801766, Valid loss: 0.268913209438324, IoU: 0.7076832056045532, Prec: 0.794869065284729, Rec 0.8674705624580383\n",
      "Epoch 12/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17915534973144535\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.19973091284434, Valid loss: 0.26727724075317383, IoU: 0.7089643478393555, Prec: 0.794334352016449, Rec 0.8700379133224487\n",
      "Epoch 13/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15543630719184875\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.19896798332532248, Valid loss: 0.2655166685581207, IoU: 0.7137454152107239, Prec: 0.8047279119491577, Rec 0.8649005889892578\n",
      "Epoch 14/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.36736127734184265\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.19766246676445007, Valid loss: 0.263782799243927, IoU: 0.7135335206985474, Prec: 0.8011249303817749, Rec 0.8687246441841125\n",
      "Epoch 15/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18376173079013824\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.19402358565065597, Valid loss: 0.262116014957428, IoU: 0.712796151638031, Prec: 0.7999950051307678, Rec 0.8688977360725403\n",
      "Epoch 16/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12313366681337357\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1935488623049524, Valid loss: 0.2608530521392822, IoU: 0.7093026638031006, Prec: 0.7857416868209839, Rec 0.8810299038887024\n",
      "Epoch 17/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16505275666713715\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.19270856744713252, Valid loss: 0.259506493806839, IoU: 0.7124999761581421, Prec: 0.7941402196884155, Rec 0.875501811504364\n",
      "Epoch 18/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.35032102465629588\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.192493427462048, Valid loss: 0.25865963101387024, IoU: 0.718631386756897, Prec: 0.8076552152633667, Rec 0.8685786128044128\n",
      "Epoch 19/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.20501695573329926\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.19044296973281435, Valid loss: 0.2568702697753906, IoU: 0.7138758897781372, Prec: 0.7904647588729858, Rec 0.8820638656616211\n",
      "Epoch 20/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.25162541866302495\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18860157595740423, Valid loss: 0.25520792603492737, IoU: 0.7177287936210632, Prec: 0.8016027212142944, Rec 0.8742997050285339\n",
      "Epoch 21/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.23290921747684482\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18774665362305112, Valid loss: 0.255537211894989, IoU: 0.7177509069442749, Prec: 0.799827516078949, Rec 0.8764615058898926\n",
      "Epoch 22/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12781362235546112\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18606194224622513, Valid loss: 0.25338760018348694, IoU: 0.7170207500457764, Prec: 0.7975007891654968, Rec 0.8781582713127136\n",
      "Epoch 23/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17016795277595522\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18712378276718988, Valid loss: 0.2514909505844116, IoU: 0.719405472278595, Prec: 0.7988213300704956, Rec 0.8801196813583374\n",
      "Epoch 24/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14716419577598572\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1841513733069102, Valid loss: 0.2501213252544403, IoU: 0.7241812944412231, Prec: 0.8087494969367981, Rec 0.8753484487533569\n",
      "Epoch 25/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09559971094131472\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1856008980009291, Valid loss: 0.24963922798633575, IoU: 0.7203112840652466, Prec: 0.7999938130378723, Rec 0.8800233006477356\n",
      "Epoch 26/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15845032036304474\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18302291134993234, Valid loss: 0.2501063942909241, IoU: 0.7211847901344299, Prec: 0.8007121086120605, Rec 0.8804833292961121\n",
      "Epoch 27/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.50012964010238653\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18477764791912502, Valid loss: 0.24996665120124817, IoU: 0.7259763479232788, Prec: 0.8095414042472839, Rec 0.8770303726196289\n",
      "Epoch 28/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18440508842468262\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18370245297749838, Valid loss: 0.2477220743894577, IoU: 0.724487841129303, Prec: 0.8055499792098999, Rec 0.8795013427734375\n",
      "Epoch 29/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.19533428549766545\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18238185577922397, Valid loss: 0.24554896354675293, IoU: 0.7250219583511353, Prec: 0.803719162940979, Rec 0.8825139999389648\n",
      "Epoch 30/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11379212886095047\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18165619257423612, Valid loss: 0.24521522223949432, IoU: 0.724716067314148, Prec: 0.8021785616874695, Rec 0.8839090466499329\n",
      "Epoch 31/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17344170808792114\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18113069269392226, Valid loss: 0.24610750377178192, IoU: 0.7247457504272461, Prec: 0.8045642971992493, Rec 0.881054699420929\n",
      "Epoch 32/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12515309453010562\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17988181710243226, Valid loss: 0.2463095635175705, IoU: 0.7213311791419983, Prec: 0.7964720726013184, Rec 0.8858259320259094\n",
      "Epoch 33/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.22586862742900848\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.18013057543171776, Valid loss: 0.24489040672779083, IoU: 0.7289411425590515, Prec: 0.8122965693473816, Rec 0.8780618906021118\n",
      "Epoch 34/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14732466638088226\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1798277798626158, Valid loss: 0.24532847106456757, IoU: 0.7234592437744141, Prec: 0.7999378442764282, Rec 0.8847153782844543\n",
      "Epoch 35/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15124501287937164\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17802996403641172, Valid loss: 0.24398529529571533, IoU: 0.7257518172264099, Prec: 0.8035539388656616, Rec 0.8837878108024597\n",
      "Epoch 36/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18286490440368652\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1782806740866767, Valid loss: 0.2421676218509674, IoU: 0.7270889282226562, Prec: 0.8029347658157349, Rec 0.886555552482605\n",
      "Epoch 37/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18136619031429294\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17845276561048296, Valid loss: 0.24319005012512207, IoU: 0.7305908799171448, Prec: 0.813235878944397, Rec 0.8792936205863953\n",
      "Epoch 38/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18535940349102025\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17784605390495725, Valid loss: 0.24207916855812073, IoU: 0.7297213077545166, Prec: 0.8092687726020813, Rec 0.8827341794967651\n",
      "Epoch 39/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11455594003200531\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17442926002873316, Valid loss: 0.24148520827293396, IoU: 0.7264464497566223, Prec: 0.8013447523117065, Rec 0.8875152468681335\n",
      "Epoch 40/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.20897006988525395\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1748466345998976, Valid loss: 0.23991665244102478, IoU: 0.7306239604949951, Prec: 0.8083465695381165, Rec 0.8851679563522339\n",
      "Epoch 41/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.24394094944000244\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17480982012218899, Valid loss: 0.23930513858795166, IoU: 0.7340990304946899, Prec: 0.8157538175582886, Rec 0.8814108967781067\n",
      "Epoch 42/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17969627678394318\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17577878402339087, Valid loss: 0.2391817271709442, IoU: 0.7330395579338074, Prec: 0.8130041360855103, Rec 0.8830878138542175\n",
      "Epoch 43/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.25464937090873723\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17440316478411358, Valid loss: 0.23841843008995056, IoU: 0.7313154935836792, Prec: 0.8066507577896118, Rec 0.8882425427436829\n",
      "Epoch 44/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11391177773475647\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17270141376389397, Valid loss: 0.23843929171562195, IoU: 0.7293988466262817, Prec: 0.8030692934989929, Rec 0.8897686004638672\n",
      "Epoch 45/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17373219132423496\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17366643283102248, Valid loss: 0.23770833015441895, IoU: 0.7340500354766846, Prec: 0.8141018748283386, Rec 0.8833104968070984\n",
      "Epoch 46/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13287709653377533\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.172856804728508, Valid loss: 0.23713676631450653, IoU: 0.733518123626709, Prec: 0.8118979334831238, Rec 0.8851803541183472\n",
      "Epoch 47/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.40602859854698185\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1722901231712765, Valid loss: 0.2364298552274704, IoU: 0.7359648942947388, Prec: 0.81499844789505, Rec 0.8850270509719849\n",
      "Epoch 48/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14434823393821716\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17252176801363628, Valid loss: 0.23757095634937286, IoU: 0.734016478061676, Prec: 0.8143339157104492, Rec 0.8829271197319031\n",
      "Epoch 49/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.2201983630657196\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17049185766114128, Valid loss: 0.23559024930000305, IoU: 0.7322916388511658, Prec: 0.8052074313163757, Rec 0.8914678692817688\n",
      "Epoch 50/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.37562400102615356\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17196175124910143, Valid loss: 0.2357904464006424, IoU: 0.740573525428772, Prec: 0.8262745141983032, Rec 0.8785985708236694\n",
      "Epoch 51/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18739555776119232\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17067091564337414, Valid loss: 0.23636403679847717, IoU: 0.7321922183036804, Prec: 0.8066233396530151, Rec 0.8895213007926941\n",
      "Epoch 52/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.27168282866477966\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17091758449872335, Valid loss: 0.23395130038261414, IoU: 0.7351899147033691, Prec: 0.8098663091659546, Rec 0.8900852203369141\n",
      "Epoch 53/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17837393283843994\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.17079562346140545, Valid loss: 0.23397354781627655, IoU: 0.7353142499923706, Prec: 0.8111370205879211, Rec 0.8887198567390442\n",
      "Epoch 54/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13865852355957033\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16788131131066217, Valid loss: 0.23291821777820587, IoU: 0.7383710145950317, Prec: 0.8178077936172485, Rec 0.8852075338363647\n",
      "Epoch 55/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15451352298259735\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16804970734649236, Valid loss: 0.23242852091789246, IoU: 0.7397662401199341, Prec: 0.8196199536323547, Rec 0.8850492238998413\n",
      "Epoch 56/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16478870809078217\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16637692153453826, Valid loss: 0.23341703414916992, IoU: 0.7350639700889587, Prec: 0.8090119361877441, Rec 0.8908395767211914\n",
      "Epoch 57/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.29780238866806035\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16740340126885309, Valid loss: 0.232131689786911, IoU: 0.7379216551780701, Prec: 0.8143857717514038, Rec 0.8885542154312134\n",
      "Epoch 58/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.20597451925277716\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16840402947531807, Valid loss: 0.23402777314186096, IoU: 0.7373700141906738, Prec: 0.814799964427948, Rec 0.8873297572135925\n",
      "Epoch 59/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.26304501295089727\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1686961094538371, Valid loss: 0.23274843394756317, IoU: 0.7371206283569336, Prec: 0.813115119934082, Rec 0.8889771699905396\n",
      "Epoch 60/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14655512571334844\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.166304878393809, Valid loss: 0.2306499481201172, IoU: 0.7386258840560913, Prec: 0.8144172430038452, Rec 0.8896425366401672\n",
      "Epoch 61/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.33561736345291148\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1662666466501024, Valid loss: 0.23040306568145752, IoU: 0.7430474758148193, Prec: 0.8233009576797485, Rec 0.8855835795402527\n",
      "Epoch 62/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13200300931930542\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.164785189098782, Valid loss: 0.22903776168823242, IoU: 0.7418030500411987, Prec: 0.8193452954292297, Rec 0.8883711099624634\n",
      "Epoch 63/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14591954648494724\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16605461140473685, Valid loss: 0.2292223423719406, IoU: 0.7431723475456238, Prec: 0.8226466178894043, Rec 0.8865111470222473\n",
      "Epoch 64/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18590357899665833\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16580608752038745, Valid loss: 0.2318497598171234, IoU: 0.7392380833625793, Prec: 0.8142976760864258, Rec 0.8907827138900757\n",
      "Epoch 65/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.26480129361152653\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1651636090543535, Valid loss: 0.23217757046222687, IoU: 0.7455993890762329, Prec: 0.8313829302787781, Rec 0.8799911737442017\n",
      "Epoch 66/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18241548538208008\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16490448580847847, Valid loss: 0.23056283593177795, IoU: 0.7418323755264282, Prec: 0.819855809211731, Rec 0.8878763914108276\n",
      "Epoch 67/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13787055015563965\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16494942704836527, Valid loss: 0.2288663387298584, IoU: 0.744503915309906, Prec: 0.8252130746841431, Rec 0.8854203224182129\n",
      "Epoch 68/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13688322901725773\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1639425297578176, Valid loss: 0.22769677639007568, IoU: 0.7465956211090088, Prec: 0.82813560962677, Rec 0.8851062059402466\n",
      "Epoch 69/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13418915867805486\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1625635802745819, Valid loss: 0.22738775610923767, IoU: 0.7401665449142456, Prec: 0.811781108379364, Rec 0.8951805233955383\n",
      "Epoch 70/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14146918058395386\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16305379337734646, Valid loss: 0.22764214873313904, IoU: 0.7452908754348755, Prec: 0.8249656558036804, Rec 0.8869389295578003\n",
      "Epoch 71/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.21992991864681244\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16118492450979022, Valid loss: 0.22744664549827576, IoU: 0.7469345927238464, Prec: 0.8257104754447937, Rec 0.8884032368659973\n",
      "Epoch 72/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17693428695201874\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16254530251026153, Valid loss: 0.22921021282672882, IoU: 0.7501333951950073, Prec: 0.8379483222961426, Rec 0.8790165781974792\n",
      "Epoch 73/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.21161341667175293\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16204609870910644, Valid loss: 0.22596633434295654, IoU: 0.7466715574264526, Prec: 0.8240560293197632, Rec 0.8899515867233276\n",
      "Epoch 74/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16062667965888977\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16141962276564703, Valid loss: 0.2262682467699051, IoU: 0.7458387613296509, Prec: 0.8233034014701843, Rec 0.88972407579422\n",
      "Epoch 75/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17415849864482884\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16094480852286022, Valid loss: 0.22575950622558594, IoU: 0.7509793043136597, Prec: 0.8348373174667358, Rec 0.8838076591491699\n",
      "Epoch 76/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16531263291835785\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.16081569890181224, Valid loss: 0.22712913155555725, IoU: 0.7468141913414001, Prec: 0.8260575532913208, Rec 0.8879926800727844\n",
      "Epoch 77/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.31485381722450256\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1602042529318068, Valid loss: 0.2275986224412918, IoU: 0.7498457431793213, Prec: 0.8346473574638367, Rec 0.8824545741081238\n",
      "Epoch 78/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11785268038511276\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15913427919149398, Valid loss: 0.2276703417301178, IoU: 0.7454131245613098, Prec: 0.8235145807266235, Rec 0.8890191316604614\n",
      "Epoch 79/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.20283390581607819\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15877691871590086, Valid loss: 0.22544033825397491, IoU: 0.7465977072715759, Prec: 0.8240619897842407, Rec 0.8900481462478638\n",
      "Epoch 80/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15589717030525208\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1578942490948571, Valid loss: 0.2255449742078781, IoU: 0.7501477599143982, Prec: 0.8317371606826782, Rec 0.8861673474311829\n",
      "Epoch 81/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14950546622276306\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.15827612545755174, Valid loss: 0.22453603148460388, IoU: 0.7537662386894226, Prec: 0.8375334739685059, Rec 0.8846906423568726\n",
      "Epoch 82/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14832547307014465\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15858309268951415, Valid loss: 0.22496776282787323, IoU: 0.7522629499435425, Prec: 0.8346783518791199, Rec 0.8858036994934082\n",
      "Epoch 83/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.27523946762084964\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15652681125534906, Valid loss: 0.22459359467029572, IoU: 0.7544504404067993, Prec: 0.8396955728530884, Rec 0.8832065463066101\n",
      "Epoch 84/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18107658624649048\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15623913076188828, Valid loss: 0.22368016839027405, IoU: 0.7556115388870239, Prec: 0.8403776288032532, Rec 0.8840698003768921\n",
      "Epoch 85/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18568423390388498\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15623425046602885, Valid loss: 0.22464892268180847, IoU: 0.7511113882064819, Prec: 0.8311927914619446, Rec 0.8880916833877563\n",
      "Epoch 86/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14238514006137848\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15621992515193092, Valid loss: 0.22252564132213593, IoU: 0.7536353468894958, Prec: 0.8358926773071289, Rec 0.886345386505127\n",
      "Epoch 87/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15806855261325836\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1538955718278885, Valid loss: 0.22317619621753693, IoU: 0.755740761756897, Prec: 0.8396466970443726, Rec 0.8850493431091309\n",
      "Epoch 88/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13162101805210114\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15591792431142595, Valid loss: 0.22217929363250732, IoU: 0.7543648481369019, Prec: 0.8370218276977539, Rec 0.8860832452774048\n",
      "Epoch 89/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10592365264892578\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1544880959722731, Valid loss: 0.22282150387763977, IoU: 0.7525918483734131, Prec: 0.8322636485099792, Rec 0.8891156315803528\n",
      "Epoch 90/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10167163610458374\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15270006921556262, Valid loss: 0.22228428721427917, IoU: 0.7536349892616272, Prec: 0.8339173197746277, Rec 0.888690173625946\n",
      "Epoch 91/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14634867012500763\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1528628538052241, Valid loss: 0.2208545207977295, IoU: 0.7562691569328308, Prec: 0.8385831713676453, Rec 0.8870800137519836\n",
      "Epoch 92/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.19167578220367432\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15257255501217312, Valid loss: 0.22189824283123016, IoU: 0.7534459233283997, Prec: 0.832297682762146, Rec 0.8902732133865356\n",
      "Epoch 93/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13859927654266357\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15343729787402682, Valid loss: 0.22030127048492432, IoU: 0.7579969763755798, Prec: 0.8412443995475769, Rec 0.8864270448684692\n",
      "Epoch 94/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18283075094223022\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15290465619828966, Valid loss: 0.22393211722373962, IoU: 0.7548438310623169, Prec: 0.8369325399398804, Rec 0.8869612812995911\n",
      "Epoch 95/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17747402191162115\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15222327444288467, Valid loss: 0.22058823704719543, IoU: 0.7565804123878479, Prec: 0.8377909660339355, Rec 0.8884180784225464\n",
      "Epoch 96/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14541596174240112\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15092159907023112, Valid loss: 0.22087857127189636, IoU: 0.7600557208061218, Prec: 0.8464123010635376, Rec 0.8837259411811829\n",
      "Epoch 97/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12850610911846168\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1507050762573878, Valid loss: 0.22008009254932404, IoU: 0.7571406364440918, Prec: 0.8377622365951538, Rec 0.8893629908561707\n",
      "Epoch 98/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15788596868515015\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.15043873455789353, Valid loss: 0.21983034908771515, IoU: 0.7583110332489014, Prec: 0.8416054844856262, Rec 0.8866990804672241\n",
      "Epoch 99/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16276231408119202\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1496146500110626, Valid loss: 0.22159282863140106, IoU: 0.757992148399353, Prec: 0.8412420153617859, Rec 0.886590301990509\n",
      "Epoch 100/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11487588286399841\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1493636151154836, Valid loss: 0.22108086943626404, IoU: 0.7607517242431641, Prec: 0.8479628562927246, Rec 0.8829666376113892\n",
      "Epoch 101/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18693074584007263\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14912101096577116, Valid loss: 0.22225506603717804, IoU: 0.760362446308136, Prec: 0.8463462591171265, Rec 0.8841118812561035\n",
      "Epoch 102/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16226240992546082\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14952717423439027, Valid loss: 0.22200071811676025, IoU: 0.7606486082077026, Prec: 0.8478744626045227, Rec 0.8828083872795105\n",
      "Epoch 103/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.26630336046218873\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1481027728981442, Valid loss: 0.21697652339935303, IoU: 0.7583011388778687, Prec: 0.8374834060668945, Rec 0.8912279009819031\n",
      "Epoch 104/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15991170704364777\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14923489524258507, Valid loss: 0.22305123507976532, IoU: 0.7615681886672974, Prec: 0.8508642315864563, Rec 0.8809680938720703\n",
      "Epoch 105/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.1430346965789795\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14791292548179627, Valid loss: 0.22024396061897278, IoU: 0.7603963017463684, Prec: 0.8445640802383423, Rec 0.8862044215202332\n",
      "Epoch 106/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14818941056728363\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14774805009365083, Valid loss: 0.2192045897245407, IoU: 0.7597227096557617, Prec: 0.8419440984725952, Rec 0.8882251977920532\n",
      "Epoch 107/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13015581667423248\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1462359458208084, Valid loss: 0.21953646838665009, IoU: 0.7622060775756836, Prec: 0.8485811352729797, Rec 0.8843121528625488\n",
      "Epoch 108/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12006580829620361\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14768397079573736, Valid loss: 0.22119605541229248, IoU: 0.7612466812133789, Prec: 0.8455709218978882, Rec 0.8863576650619507\n",
      "Epoch 109/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17579716444015503\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14638592667049832, Valid loss: 0.21847482025623322, IoU: 0.7587026953697205, Prec: 0.8387464284896851, Rec 0.8904808759689331\n",
      "Epoch 110/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11323836445808416\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1449661307864719, Valid loss: 0.21820473670959473, IoU: 0.7624072432518005, Prec: 0.8462774157524109, Rec 0.8872159719467163\n",
      "Epoch 111/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16013264656066895\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14459237919913398, Valid loss: 0.22331073880195618, IoU: 0.7637495994567871, Prec: 0.8542630076408386, Rec 0.8804091215133667\n",
      "Epoch 112/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13209579885005958\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1449330253733529, Valid loss: 0.22009634971618652, IoU: 0.762099027633667, Prec: 0.8472387194633484, Rec 0.8856775164604187\n",
      "Epoch 113/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09436714649200442\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14549914730919733, Valid loss: 0.21971039474010468, IoU: 0.7629252076148987, Prec: 0.84770667552948, Rec 0.8863601684570312\n",
      "Epoch 114/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.20112466812133793\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1440673549969991, Valid loss: 0.22233346104621887, IoU: 0.7639713883399963, Prec: 0.8515626192092896, Rec 0.8835701942443848\n",
      "Epoch 115/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.3101204037666321\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14407905605104235, Valid loss: 0.2268553227186203, IoU: 0.7638790011405945, Prec: 0.8578367233276367, Rec 0.8768919110298157\n",
      "Epoch 116/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15101855993270874\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14319644835260179, Valid loss: 0.21799568831920624, IoU: 0.7606717348098755, Prec: 0.8427324295043945, Rec 0.8888806104660034\n",
      "Epoch 117/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15665280818939216\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14185132185618082, Valid loss: 0.22233319282531738, IoU: 0.7640039920806885, Prec: 0.8524425625801086, Rec 0.8826673626899719\n",
      "Epoch 118/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10763733834028244\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14254976295762592, Valid loss: 0.2181709110736847, IoU: 0.7620908617973328, Prec: 0.844089150428772, Rec 0.8891452550888062\n",
      "Epoch 119/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10077334940433502\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14044631156656479, Valid loss: 0.21949978172779083, IoU: 0.7635701298713684, Prec: 0.849104106426239, Rec 0.8856058120727539\n",
      "Epoch 120/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15328273177146912\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14079473945829604, Valid loss: 0.2250102013349533, IoU: 0.7637926340103149, Prec: 0.8529320955276489, Rec 0.8816977739334106\n",
      "Epoch 121/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17023119330406194\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.140917350186242, Valid loss: 0.2177153080701828, IoU: 0.7644292116165161, Prec: 0.8481548428535461, Rec 0.8878219723701477\n",
      "Epoch 122/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12484496086835861\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1402845698926184, Valid loss: 0.21921534836292267, IoU: 0.7638224959373474, Prec: 0.846606433391571, Rec 0.8887792825698853\n",
      "Epoch 123/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10464087128639221\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.14029832349883187, Valid loss: 0.2206096351146698, IoU: 0.7634464502334595, Prec: 0.846095085144043, Rec 0.8887718319892883\n",
      "Epoch 124/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11124891042709354\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13767238855361938, Valid loss: 0.22118337452411652, IoU: 0.764797568321228, Prec: 0.8522698283195496, Rec 0.8837828636169434\n",
      "Epoch 125/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08627997338771825\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1383211635881, Valid loss: 0.2206617146730423, IoU: 0.7664070725440979, Prec: 0.8554550409317017, Rec 0.8825362920761108\n",
      "Epoch 126/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.22825889289379125\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13784069981839922, Valid loss: 0.22321629524230957, IoU: 0.7650278806686401, Prec: 0.851791262626648, Rec 0.8845990896224976\n",
      "Epoch 127/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13756869733333588\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13700348503059812, Valid loss: 0.22475869953632355, IoU: 0.7656402587890625, Prec: 0.8559435606002808, Rec 0.8809458613395691\n",
      "Epoch 128/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08546904474496841\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13784035990635554, Valid loss: 0.22200798988342285, IoU: 0.7664551138877869, Prec: 0.8543712496757507, Rec 0.8838373422622681\n",
      "Epoch 129/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16545864939689636\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13686608009868198, Valid loss: 0.22267088294029236, IoU: 0.766922116279602, Prec: 0.855179488658905, Rec 0.8835652470588684\n",
      "Epoch 130/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14526511728763583\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13667028380764856, Valid loss: 0.22332099080085754, IoU: 0.7672504782676697, Prec: 0.8569971323013306, Rec 0.8821455240249634\n",
      "Epoch 131/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11158117651939392\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1361419743961758, Valid loss: 0.22528047859668732, IoU: 0.7670237421989441, Prec: 0.8569146394729614, Rec 0.8817744255065918\n",
      "Epoch 132/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08967241644859314\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13534977104928758, Valid loss: 0.22252920269966125, IoU: 0.7662681937217712, Prec: 0.8526715040206909, Rec 0.8853782415390015\n",
      "Epoch 133/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15580414235591888\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13516631623109182, Valid loss: 0.22051283717155457, IoU: 0.7644659280776978, Prec: 0.8474797010421753, Rec 0.8886234164237976\n",
      "Epoch 134/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10515763610601425\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13626369684934617, Valid loss: 0.22736398875713348, IoU: 0.767418622970581, Prec: 0.8606258630752563, Rec 0.8785663843154907\n",
      "Epoch 135/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16214521229267122\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13657987150881026, Valid loss: 0.22216518223285675, IoU: 0.764209508895874, Prec: 0.8495203852653503, Rec 0.8862390518188477\n",
      "Epoch 136/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.21650040149688727\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13508932259347703, Valid loss: 0.22620590031147003, IoU: 0.7687378525733948, Prec: 0.8611724972724915, Rec 0.8796473741531372\n",
      "Epoch 137/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09225275367498398\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13383349494801627, Valid loss: 0.2236444056034088, IoU: 0.7665642499923706, Prec: 0.8562858700752258, Rec 0.8820242881774902\n",
      "Epoch 138/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11662974953651428\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13293465508355035, Valid loss: 0.2198927402496338, IoU: 0.7643030285835266, Prec: 0.846135139465332, Rec 0.890023410320282\n",
      "Epoch 139/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09642577171325684\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13436058825916714, Valid loss: 0.22035786509513855, IoU: 0.7662716507911682, Prec: 0.8511208295822144, Rec 0.887203574180603\n",
      "Epoch 140/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.1147218570113182\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13138050155507194, Valid loss: 0.21875163912773132, IoU: 0.7669528126716614, Prec: 0.8507744073867798, Rec 0.8883662223815918\n",
      "Epoch 141/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12498445063829422\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13210616724358665, Valid loss: 0.2267332524061203, IoU: 0.7676913142204285, Prec: 0.8581845164299011, Rec 0.8814281225204468\n",
      "Epoch 142/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.23143357038497925\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13170111642943488, Valid loss: 0.23132331669330597, IoU: 0.7678813338279724, Prec: 0.863995373249054, Rec 0.8755982518196106\n",
      "Epoch 143/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15798668563365936\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1318388260073132, Valid loss: 0.22109761834144592, IoU: 0.7639597058296204, Prec: 0.846906304359436, Rec 0.8885071873664856\n",
      "Epoch 144/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11159248650074005\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13121520909998152, Valid loss: 0.22502703964710236, IoU: 0.7678453922271729, Prec: 0.8595156669616699, Rec 0.8803249597549438\n",
      "Epoch 145/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12612652778625488\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.132609580622779, Valid loss: 0.22869357466697693, IoU: 0.7694162130355835, Prec: 0.8639037013053894, Rec 0.8777229189872742\n",
      "Epoch 146/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13562345504760742\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13134940332836575, Valid loss: 0.2312949150800705, IoU: 0.7682121396064758, Prec: 0.8631541132926941, Rec 0.8770081400871277\n",
      "Epoch 147/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11571307480335236\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13053248557779523, Valid loss: 0.2217758446931839, IoU: 0.7650310397148132, Prec: 0.8482920527458191, Rec 0.8886381983757019\n",
      "Epoch 148/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14987957477569588\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.12985297242800395, Valid loss: 0.22510778903961182, IoU: 0.7665363550186157, Prec: 0.8552025556564331, Rec 0.883238673210144\n",
      "Epoch 149/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.24926814436912537\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.12957917054494222, Valid loss: 0.2345709502696991, IoU: 0.7699753046035767, Prec: 0.8695537447929382, Rec 0.8727117776870728\n",
      "Epoch 150/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11864328384399414\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.12970488137669034, Valid loss: 0.23142623901367188, IoU: 0.765463650226593, Prec: 0.8588024973869324, Rec 0.8780915141105652\n",
      "Epoch 151/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.24995774030685425\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.13104340831438702, Valid loss: 0.22752627730369568, IoU: 0.7673198580741882, Prec: 0.8550661206245422, Rec 0.884178638458252\n",
      "Epoch 152/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13931791484355927\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1313425663444731, Valid loss: 0.23834314942359924, IoU: 0.7650620341300964, Prec: 0.8634904623031616, Rec 0.8728379011154175\n",
      "Epoch 153/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11671651154756546\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.12818213784032398, Valid loss: 0.22354674339294434, IoU: 0.7662903070449829, Prec: 0.8514954447746277, Rec 0.8868029713630676\n",
      "Epoch 154/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14359223842620859\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.12800254888004728, Valid loss: 0.23461563885211945, IoU: 0.7684941291809082, Prec: 0.8661358952522278, Rec 0.8742205500602722\n",
      "Epoch 155/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11118635535240173\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.12680332528220284, Valid loss: 0.22397927939891815, IoU: 0.7671079039573669, Prec: 0.8537516593933105, Rec 0.8853287696838379\n",
      "Epoch 156/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14839841425418854\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12606912751992544, Valid loss: 0.24145746231079102, IoU: 0.7687019109725952, Prec: 0.8720719218254089, Rec 0.8685365915298462\n",
      "Epoch 157/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16920563578605652\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12687277065383062, Valid loss: 0.22882981598377228, IoU: 0.7657935619354248, Prec: 0.8550507426261902, Rec 0.8821924328804016\n",
      "Epoch 158/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10530015081167221\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12567447738515006, Valid loss: 0.22331373393535614, IoU: 0.7659906148910522, Prec: 0.8511465787887573, Rec 0.8867213129997253\n",
      "Epoch 159/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12106324732303626\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12617324888706208, Valid loss: 0.2336268424987793, IoU: 0.7680290937423706, Prec: 0.8628793954849243, Rec 0.877060055732727\n",
      "Epoch 160/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09014612436294556\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12447406649589539, Valid loss: 0.22070439159870148, IoU: 0.7663708925247192, Prec: 0.8512897491455078, Rec 0.8870503306388855\n",
      "Epoch 161/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14309583604335785\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.12467897567484114, Valid loss: 0.23621729016304016, IoU: 0.7686477899551392, Prec: 0.8662049174308777, Rec 0.874336838722229\n",
      "Epoch 162/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12517623603343964\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12470849388175541, Valid loss: 0.2305242270231247, IoU: 0.7663095593452454, Prec: 0.8584257364273071, Rec 0.8794519305229187\n",
      "Epoch 163/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17018385231494904\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12347759836249882, Valid loss: 0.22950494289398193, IoU: 0.7659893035888672, Prec: 0.8522331118583679, Rec 0.8855192065238953\n",
      "Epoch 164/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13220028579235077\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12363075448407067, Valid loss: 0.23938822746276855, IoU: 0.7683395147323608, Prec: 0.8665422201156616, Rec 0.8736912608146667\n",
      "Epoch 165/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.22306193411350255\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12458562619156308, Valid loss: 0.2415146380662918, IoU: 0.769132137298584, Prec: 0.8712627291679382, Rec 0.8698202967643738\n",
      "Epoch 166/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14768841862678528\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12371838688850403, Valid loss: 0.23720736801624298, IoU: 0.7663230299949646, Prec: 0.860085666179657, Rec 0.8778292536735535\n",
      "Epoch 167/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12472693622112274\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12389456729094188, Valid loss: 0.22934742271900177, IoU: 0.765499472618103, Prec: 0.8552395105361938, Rec 0.8817497491836548\n",
      "Epoch 168/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14505504071712494\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12289971609910329, Valid loss: 0.23122787475585938, IoU: 0.7684764862060547, Prec: 0.8608747720718384, Rec 0.8797091245651245\n",
      "Epoch 169/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17951300740242004\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12266470458772448, Valid loss: 0.24094215035438538, IoU: 0.7659765481948853, Prec: 0.8644784688949585, Rec 0.8729714155197144\n",
      "Epoch 170/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09878028929233551\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12287469009558359, Valid loss: 0.22988459467887878, IoU: 0.7674703598022461, Prec: 0.8560643196105957, Rec 0.8833797574043274\n",
      "Epoch 171/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10117852687835693\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12242396871248881, Valid loss: 0.24286778271198273, IoU: 0.7683344483375549, Prec: 0.86933434009552, Rec 0.8708839416503906\n",
      "Epoch 172/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11645259708166122\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12109851953056124, Valid loss: 0.22862668335437775, IoU: 0.7667685747146606, Prec: 0.8528059124946594, Rec 0.885850727558136\n",
      "Epoch 173/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.19188210368156433\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12101209428575303, Valid loss: 0.23523569107055664, IoU: 0.7681924104690552, Prec: 0.8604615330696106, Rec 0.8796398043632507\n",
      "Epoch 174/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15030285716056824\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.1219291263156467, Valid loss: 0.24896018207073212, IoU: 0.7686705589294434, Prec: 0.872984766960144, Rec 0.8675273656845093\n",
      "Epoch 175/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11970808357000351\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12261691606707043, Valid loss: 0.24095061421394348, IoU: 0.7649322748184204, Prec: 0.8616897463798523, Rec 0.8744381666183472\n",
      "Epoch 176/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13481834530830383\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12038296593560113, Valid loss: 0.23611462116241455, IoU: 0.7671960592269897, Prec: 0.8570828437805176, Rec 0.8819154500961304\n",
      "Epoch 177/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18906129896640778\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12183461421065861, Valid loss: 0.24493281543254852, IoU: 0.7657303214073181, Prec: 0.8687701225280762, Rec 0.8682818412780762\n",
      "Epoch 178/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13111983239650726\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.12037211755911509, Valid loss: 0.23055386543273926, IoU: 0.7658745646476746, Prec: 0.8513343930244446, Rec 0.8862835168838501\n",
      "Epoch 179/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13218274712562568\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11941736274295384, Valid loss: 0.23545770347118378, IoU: 0.7667036056518555, Prec: 0.8594053983688354, Rec 0.8788310289382935\n",
      "Epoch 180/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17725786566734314\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11922798289193047, Valid loss: 0.24475428462028503, IoU: 0.7670115232467651, Prec: 0.8670465350151062, Rec 0.8715096712112427\n",
      "Epoch 181/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12333628535270691\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11736122767130534, Valid loss: 0.23535537719726562, IoU: 0.7644202709197998, Prec: 0.8538625836372375, Rec 0.8817521929740906\n",
      "Epoch 182/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09835323691368103\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11915078891648187, Valid loss: 0.23510055243968964, IoU: 0.7652519941329956, Prec: 0.8528095483779907, Rec 0.8838719129562378\n",
      "Epoch 183/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12964107096195227\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11641211873955197, Valid loss: 0.24066893756389618, IoU: 0.76764976978302, Prec: 0.8654487729072571, Rec 0.8739237785339355\n",
      "Epoch 184/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11563249677419662\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11683738678693771, Valid loss: 0.24188275635242462, IoU: 0.7682856917381287, Prec: 0.864654541015625, Rec 0.8753607869148254\n",
      "Epoch 185/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08621965348720551\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11779164837466347, Valid loss: 0.24232706427574158, IoU: 0.7659119367599487, Prec: 0.8631688356399536, Rec 0.8739534616470337\n",
      "Epoch 186/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.1347607821226127\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11819081140889062, Valid loss: 0.2543702721595764, IoU: 0.7657042145729065, Prec: 0.8692194223403931, Rec 0.8676436543464661\n",
      "Epoch 187/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12558221817016602\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11712064809269375, Valid loss: 0.23927204310894012, IoU: 0.7668136358261108, Prec: 0.8605766296386719, Rec 0.8778367042541504\n",
      "Epoch 188/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10261330753564835\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11685213529401356, Valid loss: 0.23982051014900208, IoU: 0.7676520347595215, Prec: 0.8617115020751953, Rec 0.8777328729629517\n",
      "Epoch 189/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15196105837821966\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11607619524002075, Valid loss: 0.2543049454689026, IoU: 0.766875147819519, Prec: 0.8702409863471985, Rec 0.8681185841560364\n",
      "Epoch 190/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14376430213451385\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11516249080499014, Valid loss: 0.23975911736488342, IoU: 0.7665244340896606, Prec: 0.8603723645210266, Rec 0.8776339292526245\n",
      "Epoch 191/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14452257752418518\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11765176918771532, Valid loss: 0.2322409600019455, IoU: 0.7651044130325317, Prec: 0.8505064845085144, Rec 0.886093020439148\n",
      "Epoch 192/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11012665927410126\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11596781644556257, Valid loss: 0.2510184645652771, IoU: 0.7660480737686157, Prec: 0.8680353164672852, Rec 0.869402289390564\n",
      "Epoch 193/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10952502489089966\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11445748209953308, Valid loss: 0.233439639210701, IoU: 0.7644758224487305, Prec: 0.8500224947929382, Rec 0.8858432769775391\n",
      "Epoch 194/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14322412014007568\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11546247866418627, Valid loss: 0.25138959288597107, IoU: 0.7680290341377258, Prec: 0.8690928220748901, Rec 0.8707453608512878\n",
      "Epoch 195/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12182538956403732\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11501072032584084, Valid loss: 0.23155935108661652, IoU: 0.7652722597122192, Prec: 0.8499205708503723, Rec 0.8870107531547546\n",
      "Epoch 196/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10886211693286896\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11747392382886675, Valid loss: 0.2593570947647095, IoU: 0.766899049282074, Prec: 0.8733862638473511, Rec 0.8649600148200989\n",
      "Epoch 197/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11240096390247345\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11404444409741296, Valid loss: 0.23965179920196533, IoU: 0.7632485628128052, Prec: 0.8518129587173462, Rec 0.8822592496871948\n",
      "Epoch 198/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14031836390495399\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11336511174837748, Valid loss: 0.24504606425762177, IoU: 0.7665164470672607, Prec: 0.8623196482658386, Rec 0.8756254315376282\n",
      "Epoch 199/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13171987235546112\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1119090759091907, Valid loss: 0.25225502252578735, IoU: 0.7654260396957397, Prec: 0.8629149198532104, Rec 0.8735700845718384\n",
      "Epoch 200/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11971317976713188\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11282551536957423, Valid loss: 0.24918432533740997, IoU: 0.7660115957260132, Prec: 0.864514172077179, Rec 0.8727067708969116\n",
      "Epoch 201/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16275393962860107\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11278487311469185, Valid loss: 0.24659614264965057, IoU: 0.7658841013908386, Prec: 0.860157310962677, Rec 0.8769833445549011\n",
      "Epoch 202/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09277563542127609\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11217303524414698, Valid loss: 0.24729855358600616, IoU: 0.7666191458702087, Prec: 0.8651296496391296, Rec 0.8729318380355835\n",
      "Epoch 203/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09708530455827713\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11261075486739476, Valid loss: 0.2508229613304138, IoU: 0.7673814296722412, Prec: 0.8663069009780884, Rec 0.87250155210495\n",
      "Epoch 204/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15787315368652344\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11231362885899014, Valid loss: 0.24373631179332733, IoU: 0.7644475102424622, Prec: 0.8541509509086609, Rec 0.8813095092773438\n",
      "Epoch 205/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11265555024147034\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11147629022598267, Valid loss: 0.25377124547958374, IoU: 0.766792893409729, Prec: 0.8671914935112, Rec 0.8710199594497681\n",
      "Epoch 206/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10819761455059052\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.1107644455300437, Valid loss: 0.25052106380462646, IoU: 0.7636691927909851, Prec: 0.8589922785758972, Rec 0.8752692937850952\n",
      "Epoch 207/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09437263011932373\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11346528132756552, Valid loss: 0.2471069097518921, IoU: 0.7666275501251221, Prec: 0.8613543510437012, Rec 0.8768102526664734\n",
      "Epoch 208/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10920467227697372\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11260566827323702, Valid loss: 0.23956581950187683, IoU: 0.7651675343513489, Prec: 0.8519485592842102, Rec 0.8846312761306763\n",
      "Epoch 209/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10805456340312958\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1114735957649019, Valid loss: 0.26479965448379517, IoU: 0.7654856443405151, Prec: 0.8725193738937378, Rec 0.8642451167106628\n",
      "Epoch 210/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07681792229413986\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11230306343899833, Valid loss: 0.24371865391731262, IoU: 0.7656649947166443, Prec: 0.8582539558410645, Rec 0.8787864446640015\n",
      "Epoch 211/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08089599758386612\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10982780539327197, Valid loss: 0.2494371235370636, IoU: 0.7675225734710693, Prec: 0.8654424548149109, Rec 0.8736987113952637\n",
      "Epoch 212/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09472029656171799\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10943007055256102, Valid loss: 0.25617748498916626, IoU: 0.7661083340644836, Prec: 0.8677979707717896, Rec 0.8695160746574402\n",
      "Epoch 213/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13096646964550018\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11060811049408383, Valid loss: 0.25830766558647156, IoU: 0.7653321027755737, Prec: 0.8651043772697449, Rec 0.8712153434753418\n",
      "Epoch 214/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10404487699270248\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11126843608087963, Valid loss: 0.24617338180541992, IoU: 0.7663037180900574, Prec: 0.8593577146530151, Rec 0.8783165812492371\n",
      "Epoch 215/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13797757029533386\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.11299110783471002, Valid loss: 0.24587926268577576, IoU: 0.7639095783233643, Prec: 0.8532814979553223, Rec 0.8815839886665344\n",
      "Epoch 216/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16578306257724762\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11115299695067936, Valid loss: 0.26385873556137085, IoU: 0.7655162215232849, Prec: 0.8679141998291016, Rec 0.8687616586685181\n",
      "Epoch 217/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13391491770744324\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.11039525005552504, Valid loss: 0.24039623141288757, IoU: 0.7645144462585449, Prec: 0.8497478365898132, Rec 0.886323094367981\n",
      "Epoch 218/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09481828659772873\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10999160922235912, Valid loss: 0.2518506646156311, IoU: 0.7657154202461243, Prec: 0.8624364733695984, Rec 0.874638557434082\n",
      "Epoch 219/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10525347292423248\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10841021239757538, Valid loss: 0.24058213829994202, IoU: 0.7640353441238403, Prec: 0.8495699167251587, Rec 0.8858159780502319\n",
      "Epoch 220/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09584792703390121\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10832100295358234, Valid loss: 0.26679667830467224, IoU: 0.7671416997909546, Prec: 0.8748742938041687, Rec 0.8640028238296509\n",
      "Epoch 221/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16849042475223547\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1080897910727395, Valid loss: 0.26800137758255005, IoU: 0.7654055953025818, Prec: 0.8718671798706055, Rec 0.8646458387374878\n",
      "Epoch 222/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08790399134159088\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10790094435214996, Valid loss: 0.24569793045520782, IoU: 0.7648290395736694, Prec: 0.8554884791374207, Rec 0.8807059526443481\n",
      "Epoch 223/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10930700600147247\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1079723917775684, Valid loss: 0.2529882490634918, IoU: 0.7658528089523315, Prec: 0.8621156811714172, Rec 0.874923050403595\n",
      "Epoch 224/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08446498960256577\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10713855806324217, Valid loss: 0.24628481268882751, IoU: 0.7656596899032593, Prec: 0.8554794192314148, Rec 0.8815444111824036\n",
      "Epoch 225/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18467886745929718\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10704677138063642, Valid loss: 0.26336562633514404, IoU: 0.7657691836357117, Prec: 0.8687540888786316, Rec 0.8681210279464722\n",
      "Epoch 226/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13312453031539917\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.1059787094593048, Valid loss: 0.25353503227233887, IoU: 0.76542067527771, Prec: 0.8613024950027466, Rec 0.8750813603401184\n",
      "Epoch 227/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.18125455081462862\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10753023193942177, Valid loss: 0.2787589132785797, IoU: 0.7646554708480835, Prec: 0.8724568486213684, Rec 0.8630999326705933\n",
      "Epoch 228/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09943796694278717\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10881621539592742, Valid loss: 0.2515353858470917, IoU: 0.7637326717376709, Prec: 0.8545850515365601, Rec 0.8799242973327637\n",
      "Epoch 229/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08465500175952911\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10756931801637014, Valid loss: 0.2582813799381256, IoU: 0.7655147314071655, Prec: 0.8613945245742798, Rec 0.8751901388168335\n",
      "Epoch 230/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11511950939893723\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10707150946060816, Valid loss: 0.2536117136478424, IoU: 0.7654134631156921, Prec: 0.8601275682449341, Rec 0.8763650059700012\n",
      "Epoch 231/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11140614748001099\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10688799685902066, Valid loss: 0.2661551833152771, IoU: 0.7649301290512085, Prec: 0.8686412572860718, Rec 0.867297351360321\n",
      "Epoch 232/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12116068601608276\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10762855145666335, Valid loss: 0.24651679396629333, IoU: 0.7669998407363892, Prec: 0.8579381704330444, Rec 0.8806514739990234\n",
      "Epoch 233/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10950088500976562\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10621412793795268, Valid loss: 0.25492146611213684, IoU: 0.7663828730583191, Prec: 0.8641881942749023, Rec 0.8734859228134155\n",
      "Epoch 234/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09479664266109467\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.1064185874329673, Valid loss: 0.2593452036380768, IoU: 0.7649708390235901, Prec: 0.8630591630935669, Rec 0.8729368448257446\n",
      "Epoch 235/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09370548278093338\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10632850743002362, Valid loss: 0.2748554050922394, IoU: 0.765576183795929, Prec: 0.8727342486381531, Rec 0.8640176057815552\n",
      "Epoch 236/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12539373338222504\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10435547928015391, Valid loss: 0.2587813138961792, IoU: 0.7646619081497192, Prec: 0.8598338961601257, Rec 0.8757071495056152\n",
      "Epoch 237/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09183523803949356\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10506767514679168, Valid loss: 0.2512107789516449, IoU: 0.7656094431877136, Prec: 0.8554869890213013, Rec 0.8813861608505249\n",
      "Epoch 238/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15226490795612335\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10713593926694658, Valid loss: 0.2819805145263672, IoU: 0.7667702436447144, Prec: 0.8793551325798035, Rec 0.8591548204421997\n",
      "Epoch 239/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06986755877733238\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.106269185576174, Valid loss: 0.26452574133872986, IoU: 0.7610431909561157, Prec: 0.8590308427810669, Rec 0.8718979954719543\n",
      "Epoch 240/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11192447692155838\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10571445375680924, Valid loss: 0.24570664763450623, IoU: 0.7628375291824341, Prec: 0.8457605242729187, Rec 0.8882498741149902\n",
      "Epoch 241/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08352531492710114\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10347602135605283, Valid loss: 0.2660854458808899, IoU: 0.7661107182502747, Prec: 0.8699849843978882, Rec 0.8673146963119507\n",
      "Epoch 242/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16414451599121094\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10309378306070964, Valid loss: 0.2655387222766876, IoU: 0.7661916017532349, Prec: 0.8669700622558594, Rec 0.8703595399856567\n",
      "Epoch 243/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10528954863548279\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10518348283237881, Valid loss: 0.28078773617744446, IoU: 0.7658195495605469, Prec: 0.8766665458679199, Rec 0.8604880571365356\n",
      "Epoch 244/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10943293571472168\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10541726218329536, Valid loss: 0.2501603960990906, IoU: 0.7641081809997559, Prec: 0.8523505330085754, Rec 0.8828973770141602\n",
      "Epoch 245/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13649247586727142\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10535445776250628, Valid loss: 0.2792184352874756, IoU: 0.7657977342605591, Prec: 0.872905433177948, Rec 0.864113986492157\n",
      "Epoch 246/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17682808637619019\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10408424801296658, Valid loss: 0.2518116533756256, IoU: 0.7639821171760559, Prec: 0.8537538647651672, Rec 0.8810447454452515\n",
      "Epoch 247/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16523268818855286\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10476833250787523, Valid loss: 0.2734343707561493, IoU: 0.7662476301193237, Prec: 0.8705075979232788, Rec 0.8670030832290649\n",
      "Epoch 248/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11417691409587866\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10300818383693695, Valid loss: 0.2566297650337219, IoU: 0.7638572454452515, Prec: 0.855667233467102, Rec 0.878905177116394\n",
      "Epoch 249/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08128669112920761\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10484743962685267, Valid loss: 0.2717207372188568, IoU: 0.7641764879226685, Prec: 0.86955326795578, Rec 0.8654026985168457\n",
      "Epoch 250/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13437017798423767\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1024202843507131, Valid loss: 0.25749653577804565, IoU: 0.7651926279067993, Prec: 0.8565597534179688, Rec 0.8796967267990112\n",
      "Epoch 251/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12165255844593048\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10401425527201759, Valid loss: 0.2789003551006317, IoU: 0.7635756731033325, Prec: 0.8737804293632507, Rec 0.8605152368545532\n",
      "Epoch 252/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13815896213054657\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10228460927804311, Valid loss: 0.2649304270744324, IoU: 0.7659136056900024, Prec: 0.8621556162834167, Rec 0.8748735189437866\n",
      "Epoch 253/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10159769654273987\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10325007239977518, Valid loss: 0.2496224343776703, IoU: 0.765573263168335, Prec: 0.8545823097229004, Rec 0.8820737600326538\n",
      "Epoch 254/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10723090171813965\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10279819236861334, Valid loss: 0.303078830242157, IoU: 0.7614413499832153, Prec: 0.8794102668762207, Rec 0.8525309562683105\n",
      "Epoch 255/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07252963632345215\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10318567471371756, Valid loss: 0.247776597738266, IoU: 0.7621874213218689, Prec: 0.844206690788269, Rec 0.888781726360321\n",
      "Epoch 256/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11155497282743454\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10283033632569843, Valid loss: 0.3131259083747864, IoU: 0.761491596698761, Prec: 0.8862425684928894, Rec 0.8462706804275513\n",
      "Epoch 257/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13800354301929474\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10257449448108673, Valid loss: 0.24858920276165009, IoU: 0.7629758715629578, Prec: 0.8470035791397095, Rec 0.8869959115982056\n",
      "Epoch 258/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11776497215032578\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10200840085744858, Valid loss: 0.28323253989219666, IoU: 0.7656216025352478, Prec: 0.8760707974433899, Rec 0.8608343005180359\n",
      "Epoch 259/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08263606578111649\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10153544694185257, Valid loss: 0.2537233829498291, IoU: 0.764156699180603, Prec: 0.852527916431427, Rec 0.8826401829719543\n",
      "Epoch 260/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12621933221817017\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10157866742875842, Valid loss: 0.28407230973243713, IoU: 0.7646662592887878, Prec: 0.8731986284255981, Rec 0.8624395132064819\n",
      "Epoch 261/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08570274710655212\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10032514399952358, Valid loss: 0.27115100622177124, IoU: 0.7647495865821838, Prec: 0.8646472692489624, Rec 0.8709704279899597\n",
      "Epoch 262/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12139344215393066\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10134069389767117, Valid loss: 0.25721168518066406, IoU: 0.7657255530357361, Prec: 0.8553203344345093, Rec 0.8817051649093628\n",
      "Epoch 263/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10646215081214905\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.1009083436595069, Valid loss: 0.28670734167099, IoU: 0.7640933990478516, Prec: 0.8725744485855103, Rec 0.8622986078262329\n",
      "Epoch 264/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12580184638500214\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10043939252694448, Valid loss: 0.26623111963272095, IoU: 0.7654606103897095, Prec: 0.8623824119567871, Rec 0.8739484548568726\n",
      "Epoch 265/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09550055861473083\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10042764279577467, Valid loss: 0.2782178521156311, IoU: 0.7626655101776123, Prec: 0.8645227551460266, Rec 0.8683065176010132\n",
      "Epoch 266/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11425745487213135\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09952390458848741, Valid loss: 0.2677707076072693, IoU: 0.7643395662307739, Prec: 0.8606265187263489, Rec 0.8743664622306824\n",
      "Epoch 267/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13932453095912933\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10124247107240888, Valid loss: 0.2825939655303955, IoU: 0.7647599577903748, Prec: 0.8712703585624695, Rec 0.8641907572746277\n",
      "Epoch 268/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11177340149879456\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.1003253632121616, Valid loss: 0.2692667543888092, IoU: 0.7632312774658203, Prec: 0.8594183921813965, Rec 0.8742798566818237\n",
      "Epoch 269/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11642657220363617\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.10171463323964013, Valid loss: 0.2909477651119232, IoU: 0.763415515422821, Prec: 0.8717164993286133, Rec 0.8623653650283813\n",
      "Epoch 270/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16242653131484985\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09940350982877943, Valid loss: 0.28679943084716797, IoU: 0.7640392780303955, Prec: 0.8703244924545288, Rec 0.8644777536392212\n",
      "Epoch 271/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09387303143739776\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.099829620288478, Valid loss: 0.26253482699394226, IoU: 0.7625640630722046, Prec: 0.8528091311454773, Rec 0.8802087903022766\n",
      "Epoch 272/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14682435989379883\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09892636934916178, Valid loss: 0.28400683403015137, IoU: 0.7649773359298706, Prec: 0.869853138923645, Rec 0.8660260438919067\n",
      "Epoch 273/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09350509941577911\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09894984861214956, Valid loss: 0.2680273652076721, IoU: 0.7631944417953491, Prec: 0.8579384684562683, Rec 0.8755933046340942\n",
      "Epoch 274/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10838009417057037\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09945730600092147, Valid loss: 0.28961724042892456, IoU: 0.7636963725090027, Prec: 0.8703690767288208, Rec 0.8638494610786438\n",
      "Epoch 275/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11185357719659805\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09857290536165238, Valid loss: 0.27235642075538635, IoU: 0.7644320726394653, Prec: 0.8618033528327942, Rec 0.8732386827468872\n",
      "Epoch 276/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10418902337551117\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09887126386165619, Valid loss: 0.2825225293636322, IoU: 0.7630404233932495, Prec: 0.8659690022468567, Rec 0.8675249814987183\n",
      "Epoch 277/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08545791357755661\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.10219629986418619, Valid loss: 0.26979827880859375, IoU: 0.762764573097229, Prec: 0.8565750122070312, Rec 0.8765653371810913\n",
      "Epoch 278/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10824470221996307\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09864301118585798, Valid loss: 0.2730262279510498, IoU: 0.7643705606460571, Prec: 0.863238513469696, Rec 0.8718830943107605\n",
      "Epoch 279/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10907194018363953\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09754114415910509, Valid loss: 0.2724342346191406, IoU: 0.7639342546463013, Prec: 0.861424446105957, Rec 0.8729616403579712\n",
      "Epoch 280/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11023940891027459\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09837640109989378, Valid loss: 0.27570801973342896, IoU: 0.763623833656311, Prec: 0.8635537028312683, Rec 0.8705078959465027\n",
      "Epoch 281/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08379991352558136\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09821621477603912, Valid loss: 0.284229576587677, IoU: 0.7632124423980713, Prec: 0.8658329844474792, Rec 0.8676807284355164\n",
      "Epoch 282/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09120426326990128\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09847383780611886, Valid loss: 0.26559513807296753, IoU: 0.7636109590530396, Prec: 0.8568543195724487, Rec 0.8772208094596863\n",
      "Epoch 283/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12644313275814056\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0991852558321423, Valid loss: 0.2765123248100281, IoU: 0.7646350860595703, Prec: 0.8646934628486633, Rec 0.8706761598587036\n",
      "Epoch 284/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09421811997890472\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09825911952389611, Valid loss: 0.26576152443885803, IoU: 0.7631332278251648, Prec: 0.8543972969055176, Rec 0.8791748285293579\n",
      "Epoch 285/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11254860460758209\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09745543830924563, Valid loss: 0.27484986186027527, IoU: 0.7637351155281067, Prec: 0.8616825938224792, Rec 0.8725188374519348\n",
      "Epoch 286/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08103913068771362\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0982990152306027, Valid loss: 0.2737273573875427, IoU: 0.7634574174880981, Prec: 0.8598346710205078, Rec 0.873898983001709\n",
      "Epoch 287/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10050810873508453\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09699751171800826, Valid loss: 0.2915017902851105, IoU: 0.7634023427963257, Prec: 0.8716819882392883, Rec 0.8622045516967773\n",
      "Epoch 288/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14394335448741913\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09776474932829539, Valid loss: 0.2652234137058258, IoU: 0.7628333568572998, Prec: 0.8516391515731812, Rec 0.8816086649894714\n",
      "Epoch 289/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08083535730838776\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09780736598703596, Valid loss: 0.325981080532074, IoU: 0.7593019604682922, Prec: 0.8829202651977539, Rec 0.846582293510437\n",
      "Epoch 290/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12598384916782384\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0986993455224567, Valid loss: 0.2709885537624359, IoU: 0.7619003057479858, Prec: 0.854390025138855, Rec 0.8776141405105591\n",
      "Epoch 291/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11191324889659882\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09611590405305227, Valid loss: 0.26837149262428284, IoU: 0.7609660625457764, Prec: 0.850101113319397, Rec 0.8810621500015259\n",
      "Epoch 292/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11660500615835197\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09684947513871722, Valid loss: 0.27055367827415466, IoU: 0.7638815641403198, Prec: 0.8579525947570801, Rec 0.876459002494812\n",
      "Epoch 293/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09705608338117657\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09681760850879881, Valid loss: 0.27281850576400757, IoU: 0.7647724747657776, Prec: 0.8622640371322632, Rec 0.8732608556747437\n",
      "Epoch 294/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10592947155237198\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09851960291465124, Valid loss: 0.28785791993141174, IoU: 0.7637166976928711, Prec: 0.8687330484390259, Rec 0.8654521703720093\n",
      "Epoch 295/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15189360082149506\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09757884244124095, Valid loss: 0.27299368381500244, IoU: 0.762453556060791, Prec: 0.8554558753967285, Rec 0.8773074150085449\n",
      "Epoch 296/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12649182975292206\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09768633478217655, Valid loss: 0.28404149413108826, IoU: 0.7651650905609131, Prec: 0.8681610822677612, Rec 0.8678044080734253\n",
      "Epoch 297/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08880468457937242\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09616548468669256, Valid loss: 0.29285746812820435, IoU: 0.7622650861740112, Prec: 0.8689520955085754, Rec 0.863456130027771\n",
      "Epoch 298/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08791318535804749\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09655628403027852, Valid loss: 0.2743321657180786, IoU: 0.763374388217926, Prec: 0.8577035069465637, Rec 0.8762240409851074\n",
      "Epoch 299/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12187603861093521\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09649671531385845, Valid loss: 0.2762787938117981, IoU: 0.7650020718574524, Prec: 0.8646138310432434, Rec 0.8710471391677856\n",
      "Epoch 300/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09881815314292908\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09532132479879592, Valid loss: 0.29511559009552, IoU: 0.7622570991516113, Prec: 0.8684501647949219, Rec 0.8638073801994324\n",
      "Epoch 301/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10325723886489868\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09514705936113993, Valid loss: 0.2805050313472748, IoU: 0.7616009712219238, Prec: 0.856209397315979, Rec 0.8753212094306946\n",
      "Epoch 302/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17058376967906952\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09603115220864614, Valid loss: 0.2938135266304016, IoU: 0.7637218236923218, Prec: 0.8702634572982788, Rec 0.8638618588447571\n",
      "Epoch 303/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08143666386604309\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09516894552442763, Valid loss: 0.2729494571685791, IoU: 0.7612309455871582, Prec: 0.8523858785629272, Rec 0.8787370920181274\n",
      "Epoch 304/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10291249305009842\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09546403106715944, Valid loss: 0.2885797917842865, IoU: 0.7639560103416443, Prec: 0.8671665191650391, Rec 0.8672083020210266\n",
      "Epoch 305/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12269353121519089\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09590137054522832, Valid loss: 0.2903105616569519, IoU: 0.7629983425140381, Prec: 0.8674777746200562, Rec 0.8657094836235046\n",
      "Epoch 306/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09625004976987839\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09450265285041597, Valid loss: 0.28087228536605835, IoU: 0.7620980143547058, Prec: 0.8585447072982788, Rec 0.8736665844917297\n",
      "Epoch 307/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07811085879802704\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09518021974298689, Valid loss: 0.2770831286907196, IoU: 0.7628176808357239, Prec: 0.8589556813240051, Rec 0.8740993738174438\n",
      "Epoch 308/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13267318904399872\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09705920252535079, Valid loss: 0.2973328232765198, IoU: 0.7643264532089233, Prec: 0.8736845850944519, Rec 0.8614056706428528\n",
      "Epoch 309/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11045936495065689\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09710933450195525, Valid loss: 0.30903124809265137, IoU: 0.7609733939170837, Prec: 0.872065544128418, Rec 0.8588283658027649\n",
      "Epoch 310/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10656650364398956\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09564655323823293, Valid loss: 0.2581472098827362, IoU: 0.758743166923523, Prec: 0.8371634483337402, Rec 0.8919254541397095\n",
      "Epoch 311/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07713406533002853\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09671084268225563, Valid loss: 0.32107144594192505, IoU: 0.7588476538658142, Prec: 0.8778694272041321, Rec 0.8506733775138855\n",
      "Epoch 312/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10427744686603546\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09488870998223622, Valid loss: 0.27543845772743225, IoU: 0.7638529539108276, Prec: 0.8578840494155884, Rec 0.8764491081237793\n",
      "Epoch 313/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06315202265977867\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09453623841206232, Valid loss: 0.2786109149456024, IoU: 0.7618670463562012, Prec: 0.8580945730209351, Rec 0.8735551834106445\n",
      "Epoch 314/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.17177233099937444\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09796979427337646, Valid loss: 0.2888905704021454, IoU: 0.7627871036529541, Prec: 0.8644684553146362, Rec 0.8684054613113403\n",
      "Epoch 315/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07844392955303192\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09709372354878319, Valid loss: 0.28204306960105896, IoU: 0.7624714374542236, Prec: 0.8605289459228516, Rec 0.8719226717948914\n",
      "Epoch 316/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07982783764600754\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09378422879510456, Valid loss: 0.2773948311805725, IoU: 0.7623819708824158, Prec: 0.8580843210220337, Rec 0.8743120431900024\n",
      "Epoch 317/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09244950860738754\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09426174412171046, Valid loss: 0.2920280396938324, IoU: 0.7633039951324463, Prec: 0.867894172668457, Rec 0.8656476140022278\n",
      "Epoch 318/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09793686866760254\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09503388007481893, Valid loss: 0.2829502522945404, IoU: 0.7622717618942261, Prec: 0.8613204956054688, Rec 0.8708987236022949\n",
      "Epoch 319/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08607371896505356\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09384035782681571, Valid loss: 0.28180351853370667, IoU: 0.7622231245040894, Prec: 0.8567391633987427, Rec 0.8754473924636841\n",
      "Epoch 320/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10391513258218765\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09325653463602065, Valid loss: 0.28764209151268005, IoU: 0.7623546123504639, Prec: 0.8629811406135559, Rec 0.8693281412124634\n",
      "Epoch 321/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09866318851709366\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0946369954281383, Valid loss: 0.2773332893848419, IoU: 0.7611598968505859, Prec: 0.8549124598503113, Rec 0.8760187029838562\n",
      "Epoch 322/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10523639619350433\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09347580373287201, Valid loss: 0.29552537202835083, IoU: 0.7633070349693298, Prec: 0.8664552569389343, Rec 0.8669980764389038\n",
      "Epoch 323/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09194076061248779\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09347293112013075, Valid loss: 0.2836536765098572, IoU: 0.7615320086479187, Prec: 0.8612216114997864, Rec 0.8699885606765747\n",
      "Epoch 324/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08262355625629425\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09352889623906878, Valid loss: 0.3027039170265198, IoU: 0.7626725435256958, Prec: 0.8705045580863953, Rec 0.8622862100601196\n",
      "Epoch 325/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08660441637039185\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09353360070122613, Valid loss: 0.28410783410072327, IoU: 0.7624729871749878, Prec: 0.8600365519523621, Rec 0.8724916577339172\n",
      "Epoch 326/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08096177130937576\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0948087998562389, Valid loss: 0.2852259576320648, IoU: 0.762313961982727, Prec: 0.8605591058731079, Rec 0.8717495799064636\n",
      "Epoch 327/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08097439259290695\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0929863550596767, Valid loss: 0.2844475507736206, IoU: 0.7628840208053589, Prec: 0.8601068258285522, Rec 0.8729541897773743\n",
      "Epoch 328/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13600724935531616\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09478610025511848, Valid loss: 0.30062562227249146, IoU: 0.7620220184326172, Prec: 0.8698924779891968, Rec 0.8620635867118835\n",
      "Epoch 329/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12143287062644958\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09277963505850897, Valid loss: 0.3084409236907959, IoU: 0.7615677118301392, Prec: 0.8706177473068237, Rec 0.8608144521713257\n",
      "Epoch 330/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08280883729457855\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09395185874568092, Valid loss: 0.2833838164806366, IoU: 0.7603681087493896, Prec: 0.8536918759346008, Rec 0.876251220703125\n",
      "Epoch 331/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08381451666355133\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09305022325780657, Valid loss: 0.2773928940296173, IoU: 0.7619856595993042, Prec: 0.8540029525756836, Rec 0.8780519366264343\n",
      "Epoch 332/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06739418208599094\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09234223133987851, Valid loss: 0.296404629945755, IoU: 0.7625631093978882, Prec: 0.867967426776886, Rec 0.8646309971809387\n",
      "Epoch 333/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12123463302850723\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09463683118422826, Valid loss: 0.28798946738243103, IoU: 0.7619867324829102, Prec: 0.8620570302009583, Rec 0.869748592376709\n",
      "Epoch 334/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07071854174137115\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09241219460964203, Valid loss: 0.2735435664653778, IoU: 0.7595201730728149, Prec: 0.8487396240234375, Rec 0.8803200721740723\n",
      "Epoch 335/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12801189720630646\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09238834612899356, Valid loss: 0.28148922324180603, IoU: 0.763257622718811, Prec: 0.8625456690788269, Rec 0.8708220720291138\n",
      "Epoch 336/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08646712452173233\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09393833627303441, Valid loss: 0.2826787829399109, IoU: 0.7612686157226562, Prec: 0.8559142351150513, Rec 0.8749700784683228\n",
      "Epoch 337/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08388151973485947\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09118919223546981, Valid loss: 0.283986359834671, IoU: 0.7627711296081543, Prec: 0.8583992719650269, Rec 0.8744827508926392\n",
      "Epoch 338/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13520199060440063\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09211829370922513, Valid loss: 0.3155611455440521, IoU: 0.761675238609314, Prec: 0.8736553192138672, Rec 0.8580046892166138\n",
      "Epoch 339/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07457090914249422\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09226841496096717, Valid loss: 0.2891205847263336, IoU: 0.7609063982963562, Prec: 0.8590113520622253, Rec 0.8713390231132507\n",
      "Epoch 340/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07386208325624466\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09111530731121699, Valid loss: 0.27890923619270325, IoU: 0.7618892788887024, Prec: 0.853873610496521, Rec 0.8779653310775757\n",
      "Epoch 341/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09831559658050537\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09112298356162177, Valid loss: 0.31165802478790283, IoU: 0.7607285380363464, Prec: 0.8717616200447083, Rec 0.8585488200187683\n",
      "Epoch 342/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06782127171754837\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09263182166549895, Valid loss: 0.28156745433807373, IoU: 0.7609256505966187, Prec: 0.8549879193305969, Rec 0.8755884170532227\n",
      "Epoch 343/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11555214226245885\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09129519297016991, Valid loss: 0.3058144450187683, IoU: 0.7622788548469543, Prec: 0.8701580166816711, Rec 0.8621575236320496\n",
      "Epoch 344/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09597950428724289\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09180761956506306, Valid loss: 0.27495431900024414, IoU: 0.7600922584533691, Prec: 0.8476611375808716, Rec 0.8822543025016785\n",
      "Epoch 345/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09192240238189697\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09260039991802639, Valid loss: 0.3071802854537964, IoU: 0.761875569820404, Prec: 0.871738076210022, Rec 0.8602331876754761\n",
      "Epoch 346/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10009149461984634\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09021143201324675, Valid loss: 0.28319498896598816, IoU: 0.761498749256134, Prec: 0.8556659817695618, Rec 0.8756230473518372\n",
      "Epoch 347/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08758802711963654\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09134666555457645, Valid loss: 0.2981535792350769, IoU: 0.7619689702987671, Prec: 0.8663517236709595, Rec 0.8655239343643188\n",
      "Epoch 348/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08513050526380539\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09207651002539528, Valid loss: 0.2916155159473419, IoU: 0.7619250416755676, Prec: 0.8602507710456848, Rec 0.8714998364448547\n",
      "Epoch 349/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09698078036308289\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08947722249560885, Valid loss: 0.28705325722694397, IoU: 0.760596752166748, Prec: 0.8549768328666687, Rec 0.875202476978302\n",
      "Epoch 350/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08441437780857086\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09027043349213071, Valid loss: 0.3024527430534363, IoU: 0.7609378099441528, Prec: 0.8647757768630981, Rec 0.8657490015029907\n",
      "Epoch 351/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08695893734693527\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09124328345060348, Valid loss: 0.28906235098838806, IoU: 0.7625681757926941, Prec: 0.8590232133865356, Rec 0.8735181093215942\n",
      "Epoch 352/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07071419060230255\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09042085839642419, Valid loss: 0.30436673760414124, IoU: 0.7603804469108582, Prec: 0.8661236763000488, Rec 0.8637207746505737\n",
      "Epoch 353/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07724820822477341\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08987429721487893, Valid loss: 0.2833086848258972, IoU: 0.7615903615951538, Prec: 0.854334831237793, Rec 0.8770724534988403\n",
      "Epoch 354/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16099484264850616\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09151843090852102, Valid loss: 0.3180803656578064, IoU: 0.7616758346557617, Prec: 0.8742799758911133, Rec 0.8573046922683716\n",
      "Epoch 355/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08515667915344238\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09078247745831808, Valid loss: 0.27921798825263977, IoU: 0.7609305381774902, Prec: 0.8500795364379883, Rec 0.8807083964347839\n",
      "Epoch 356/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08706007152795792\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09050693197382821, Valid loss: 0.3021279275417328, IoU: 0.7627061009407043, Prec: 0.8667011260986328, Rec 0.8660556674003601\n",
      "Epoch 357/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06862967461347582\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0893457735578219, Valid loss: 0.3008178174495697, IoU: 0.7615069150924683, Prec: 0.8661878705024719, Rec 0.8649624586105347\n",
      "Epoch 358/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09925694018602371\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0907276353902287, Valid loss: 0.2813999056816101, IoU: 0.7614949941635132, Prec: 0.8520585298538208, Rec 0.8792911767959595\n",
      "Epoch 359/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09441929310560226\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09049936052825716, Valid loss: 0.319550484418869, IoU: 0.7599467039108276, Prec: 0.874840259552002, Rec 0.8546902537345886\n",
      "Epoch 360/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11986915022134781\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0909573162595431, Valid loss: 0.30611079931259155, IoU: 0.7616658210754395, Prec: 0.8663139343261719, Rec 0.865068793296814\n",
      "Epoch 361/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08423230051994324\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0897255692217085, Valid loss: 0.2867084741592407, IoU: 0.761577308177948, Prec: 0.8566101789474487, Rec 0.874730110168457\n",
      "Epoch 362/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08646263182163239\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08891419867674509, Valid loss: 0.3122420310974121, IoU: 0.7598192095756531, Prec: 0.8659324645996094, Rec 0.8631569147109985\n",
      "Epoch 363/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09713449329137802\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08902264949348238, Valid loss: 0.2804892361164093, IoU: 0.7604495286941528, Prec: 0.8502818942070007, Rec 0.8797462582588196\n",
      "Epoch 364/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08454316109418869\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08889927317698797, Valid loss: 0.3094714283943176, IoU: 0.7614197134971619, Prec: 0.8682449460029602, Rec 0.8628303408622742\n",
      "Epoch 365/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.061645131558179855\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08891182964046797, Valid loss: 0.30215245485305786, IoU: 0.7603486180305481, Prec: 0.8641262054443359, Rec 0.8655808568000793\n",
      "Epoch 366/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08289291709661484\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08988507373465432, Valid loss: 0.2990954518318176, IoU: 0.761054515838623, Prec: 0.860405445098877, Rec 0.8700453639030457\n",
      "Epoch 367/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10519403964281082\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08854138669040468, Valid loss: 0.31408965587615967, IoU: 0.7608779668807983, Prec: 0.8676005601882935, Rec 0.8627561330795288\n",
      "Epoch 368/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07969867438077927\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08867979496717453, Valid loss: 0.3000951409339905, IoU: 0.7601354718208313, Prec: 0.8611782193183899, Rec 0.8682323694229126\n",
      "Epoch 369/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06892924010753632\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08935307032532162, Valid loss: 0.29685238003730774, IoU: 0.7599542737007141, Prec: 0.8568527102470398, Rec 0.8723729252815247\n",
      "Epoch 370/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09105587005615234\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08880108528667026, Valid loss: 0.306835412979126, IoU: 0.7611733078956604, Prec: 0.8664582967758179, Rec 0.8642946481704712\n",
      "Epoch 371/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09736842662096024\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08900620026720894, Valid loss: 0.2838364243507385, IoU: 0.7611644864082336, Prec: 0.8526312708854675, Rec 0.8783437609672546\n",
      "Epoch 372/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08105064928531647\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08857215676042769, Valid loss: 0.30241164565086365, IoU: 0.761585533618927, Prec: 0.865705668926239, Rec 0.8655586242675781\n",
      "Epoch 373/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08405788242816925\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09003553887208303, Valid loss: 0.3169202208518982, IoU: 0.7605509161949158, Prec: 0.8697623014450073, Rec 0.860240638256073\n",
      "Epoch 374/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10902099311351776\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08867648740609486, Valid loss: 0.2860575318336487, IoU: 0.7607764601707458, Prec: 0.8525535464286804, Rec 0.8779752850532532\n",
      "Epoch 375/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14699630439281464\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08894053002198538, Valid loss: 0.3112525939941406, IoU: 0.7623337507247925, Prec: 0.8670304417610168, Rec 0.8651628494262695\n",
      "Epoch 376/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08476487547159195\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08874569684267045, Valid loss: 0.3051041066646576, IoU: 0.7605565786361694, Prec: 0.8628414273262024, Rec 0.8671094179153442\n",
      "Epoch 377/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09956055879592896\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08786542614301046, Valid loss: 0.3003948926925659, IoU: 0.761266827583313, Prec: 0.8589177131652832, Rec 0.8720167279243469\n",
      "Epoch 378/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11521357297897339\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08858455022176107, Valid loss: 0.3102617859840393, IoU: 0.7615830302238464, Prec: 0.8651241064071655, Rec 0.8661324381828308\n",
      "Epoch 379/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09518411010503769\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0881048227349917, Valid loss: 0.29272839426994324, IoU: 0.7608470916748047, Prec: 0.8557400703430176, Rec 0.8746064305305481\n",
      "Epoch 380/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08106571435928345\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08765476942062378, Valid loss: 0.3047330975532532, IoU: 0.7601538896560669, Prec: 0.8618134260177612, Rec 0.8675719499588013\n",
      "Epoch 381/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10256189107894897\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09019798901345995, Valid loss: 0.30715101957321167, IoU: 0.7599867582321167, Prec: 0.8610495328903198, Rec 0.8682076334953308\n",
      "Epoch 382/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07486638426780744\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08767610059844123, Valid loss: 0.3103131651878357, IoU: 0.7597585916519165, Prec: 0.8627775311470032, Rec 0.8661967515945435\n",
      "Epoch 383/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10456888377666473\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.09037663175000085, Valid loss: 0.3052506446838379, IoU: 0.7611831426620483, Prec: 0.8619604110717773, Rec 0.8686898946762085\n",
      "Epoch 384/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10247845947742462\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08886464933554332, Valid loss: 0.3184357285499573, IoU: 0.7597206234931946, Prec: 0.8679359555244446, Rec 0.8610469698905945\n",
      "Epoch 385/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10062673687934875\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08871808846791586, Valid loss: 0.2950812578201294, IoU: 0.7596501708030701, Prec: 0.8548780679702759, Rec 0.874082088470459\n",
      "Epoch 386/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06129330024123192\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08765889464153184, Valid loss: 0.2821859121322632, IoU: 0.761021077632904, Prec: 0.8503350019454956, Rec 0.8805822134017944\n",
      "Epoch 387/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08146707713603973\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08756714959939321, Valid loss: 0.3186364769935608, IoU: 0.7599866986274719, Prec: 0.8709341883659363, Rec 0.8584771156311035\n",
      "Epoch 388/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.16594476997852325\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0886561158630583, Valid loss: 0.3218088746070862, IoU: 0.7607284784317017, Prec: 0.8709121942520142, Rec 0.8594837188720703\n",
      "Epoch 389/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09960750490427017\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08789687636825773, Valid loss: 0.291515588760376, IoU: 0.7552984952926636, Prec: 0.8442543745040894, Rec 0.8796695470809937\n",
      "Epoch 390/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08389291912317276\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08749952465295792, Valid loss: 0.30396825075149536, IoU: 0.7596070170402527, Prec: 0.8584260940551758, Rec 0.8704980611801147\n",
      "Epoch 391/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07272424548864365\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08805770592557059, Valid loss: 0.3247072696685791, IoU: 0.7593162059783936, Prec: 0.8741286993026733, Rec 0.854556679725647\n",
      "Epoch 392/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13305273652076728\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0889579435189565, Valid loss: 0.29774877429008484, IoU: 0.7598258256912231, Prec: 0.8576305508613586, Rec 0.8714329600334167\n",
      "Epoch 393/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09147065132856369\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08715654727485445, Valid loss: 0.29487553238868713, IoU: 0.7585169076919556, Prec: 0.8517382740974426, Rec 0.8757861852645874\n",
      "Epoch 394/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10416397452354431\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0875466333495246, Valid loss: 0.32328879833221436, IoU: 0.7588034868240356, Prec: 0.8690605163574219, Rec 0.8587417602539062\n",
      "Epoch 395/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06364515423774719\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08824766476949056, Valid loss: 0.2962145209312439, IoU: 0.7589176893234253, Prec: 0.8525508046150208, Rec 0.8754746317863464\n",
      "Epoch 396/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10501355677843094\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08733975241581599, Valid loss: 0.3068852722644806, IoU: 0.7612012624740601, Prec: 0.8648741841316223, Rec 0.8658232688903809\n",
      "Epoch 397/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10009393095970154\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08805660870340136, Valid loss: 0.3154481053352356, IoU: 0.759472131729126, Prec: 0.8645557165145874, Rec 0.8640349507331848\n",
      "Epoch 398/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09263234585523605\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08766563187042872, Valid loss: 0.2947062849998474, IoU: 0.7601641416549683, Prec: 0.8529407382011414, Rec 0.876619815826416\n",
      "Epoch 399/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08260911703109741\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08848903576533, Valid loss: 0.33241501450538635, IoU: 0.7590988874435425, Prec: 0.8777036666870117, Rec 0.8508663177490234\n",
      "Epoch 400/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15031039714813232\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08736352721850077, Valid loss: 0.29853400588035583, IoU: 0.7600199580192566, Prec: 0.8541720509529114, Rec 0.8752816319465637\n",
      "Epoch 401/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10094273835420609\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08657862428161833, Valid loss: 0.3039708733558655, IoU: 0.7591871023178101, Prec: 0.8593541979789734, Rec 0.8688457608222961\n",
      "Epoch 402/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.30057016015052795\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.09145267672008939, Valid loss: 0.3313151001930237, IoU: 0.759762167930603, Prec: 0.8726497888565063, Rec 0.856560230255127\n",
      "Epoch 403/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11967325210571289\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08777753975656298, Valid loss: 0.3131861090660095, IoU: 0.7575508952140808, Prec: 0.8586786985397339, Rec 0.8675892949104309\n",
      "Epoch 404/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14869940280914307\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08773587478531732, Valid loss: 0.3303561806678772, IoU: 0.7584154009819031, Prec: 0.8696414828300476, Rec 0.8578761219978333\n",
      "Epoch 405/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07797488570213318\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08867315318849352, Valid loss: 0.2803340554237366, IoU: 0.7527950406074524, Prec: 0.8364681005477905, Rec 0.8846708536148071\n",
      "Epoch 406/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13047958910465241\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08750737739933862, Valid loss: 0.2917085886001587, IoU: 0.7590698003768921, Prec: 0.8513751029968262, Rec 0.8770996332168579\n",
      "Epoch 407/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09356038272380829\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08710336453384823, Valid loss: 0.3045370280742645, IoU: 0.7601764798164368, Prec: 0.8636136054992676, Rec 0.8659197092056274\n",
      "Epoch 408/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08289203047752387\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08623325692282782, Valid loss: 0.3007504343986511, IoU: 0.7589894533157349, Prec: 0.8567310571670532, Rec 0.8712474703788757\n",
      "Epoch 409/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06934236735105515\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08584991875622007, Valid loss: 0.30733931064605713, IoU: 0.7584532499313354, Prec: 0.8607948422431946, Rec 0.8664787411689758\n",
      "Epoch 410/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11655870079994202\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08521996935208638, Valid loss: 0.3142564296722412, IoU: 0.7592507600784302, Prec: 0.8639254570007324, Rec 0.8642896413803101\n",
      "Epoch 411/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08020196855068207\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0857346710231569, Valid loss: 0.30067434906959534, IoU: 0.7582407593727112, Prec: 0.8545293807983398, Rec 0.87250155210495\n",
      "Epoch 412/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09907685220241547\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08551020787821875, Valid loss: 0.3179684281349182, IoU: 0.7600921392440796, Prec: 0.8665457963943481, Rec 0.8627883195877075\n",
      "Epoch 413/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11640699952840805\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08596262981494268, Valid loss: 0.32003432512283325, IoU: 0.7587422728538513, Prec: 0.8647763133049011, Rec 0.8627759218215942\n",
      "Epoch 414/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07834129780530937\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08592295961247551, Valid loss: 0.29247593879699707, IoU: 0.7571908235549927, Prec: 0.8473812341690063, Rec 0.8786752820014954\n",
      "Epoch 415/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08379738777875932\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08553218758768505, Valid loss: 0.30361440777778625, IoU: 0.7577587962150574, Prec: 0.8548581004142761, Rec 0.8716036677360535\n",
      "Epoch 416/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10479914397001266\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08560980343156391, Valid loss: 0.30435505509376526, IoU: 0.7596861720085144, Prec: 0.8589469194412231, Rec 0.8699241876602173\n",
      "Epoch 417/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13385203480720527\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08737065659628974, Valid loss: 0.3337917625904083, IoU: 0.7582370042800903, Prec: 0.8701457977294922, Rec 0.8569583892822266\n",
      "Epoch 418/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11719904094934464\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08696200135681365, Valid loss: 0.3026069700717926, IoU: 0.7562783360481262, Prec: 0.8478830456733704, Rec 0.8770526647567749\n",
      "Epoch 419/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11247701197862625\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0866256477104293, Valid loss: 0.3086552619934082, IoU: 0.7594462037086487, Prec: 0.8575302362442017, Rec 0.8710001111030579\n",
      "Epoch 420/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10772696137428284\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08545825878779094, Valid loss: 0.32281559705734253, IoU: 0.7578727006912231, Prec: 0.8660266995429993, Rec 0.8605374097824097\n",
      "Epoch 421/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07613466680049896\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08496719366974301, Valid loss: 0.30246925354003906, IoU: 0.7578616142272949, Prec: 0.8531894683837891, Rec 0.8733549118041992\n",
      "Epoch 422/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10350362211465836\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08542178157303068, Valid loss: 0.3121921420097351, IoU: 0.7578362226486206, Prec: 0.8565561175346375, Rec 0.8698376417160034\n",
      "Epoch 423/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08069057762622833\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08670146630869971, Valid loss: 0.2964988648891449, IoU: 0.7583827972412109, Prec: 0.8527366518974304, Rec 0.8745743036270142\n",
      "Epoch 424/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07446469366550446\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08490163452095456, Valid loss: 0.3123008906841278, IoU: 0.7600318789482117, Prec: 0.8623310923576355, Rec 0.866958498954773\n",
      "Epoch 425/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07913834601640701\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08524351335234112, Valid loss: 0.31913143396377563, IoU: 0.7588066458702087, Prec: 0.8648656010627747, Rec 0.8628204464912415\n",
      "Epoch 426/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10166012495756149\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08598984794484245, Valid loss: 0.3083309531211853, IoU: 0.7569074034690857, Prec: 0.8535480499267578, Rec 0.8718608617782593\n",
      "Epoch 427/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09072633832693144\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0845605398217837, Valid loss: 0.3092273473739624, IoU: 0.7586312294006348, Prec: 0.8578720092773438, Rec 0.8695952296257019\n",
      "Epoch 428/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09400256723165512\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08453643967707952, Valid loss: 0.31608861684799194, IoU: 0.7587282061576843, Prec: 0.8609352111816406, Rec 0.8666592836380005\n",
      "Epoch 429/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08091481775045395\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0842366925544209, Valid loss: 0.31444838643074036, IoU: 0.7583848237991333, Prec: 0.8593956828117371, Rec 0.8678193092346191\n",
      "Epoch 430/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09195637702941895\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08376656174659729, Valid loss: 0.3277830481529236, IoU: 0.7581378221511841, Prec: 0.8665796518325806, Rec 0.8602951169013977\n",
      "Epoch 431/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09531112015247345\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08444343838426802, Valid loss: 0.31427934765815735, IoU: 0.7585011720657349, Prec: 0.8587335348129272, Rec 0.8685340881347656\n",
      "Epoch 432/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09893216937780384\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08517486767636405, Valid loss: 0.306475967168808, IoU: 0.7592377066612244, Prec: 0.8562263250350952, Rec 0.8720043301582336\n",
      "Epoch 433/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11929027736186981\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08665377663241493, Valid loss: 0.33214864134788513, IoU: 0.7594426274299622, Prec: 0.871139407157898, Rec 0.8575619459152222\n",
      "Epoch 434/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.054967232048511505\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08478682984908421, Valid loss: 0.3236028254032135, IoU: 0.7560116052627563, Prec: 0.85893315076828, Rec 0.8652321100234985\n",
      "Epoch 435/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14136305451393127\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08549321558740404, Valid loss: 0.32348766922950745, IoU: 0.7581156492233276, Prec: 0.861965000629425, Rec 0.8648635149002075\n",
      "Epoch 436/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08334835618734361\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08519303980800841, Valid loss: 0.304537832736969, IoU: 0.7563212513923645, Prec: 0.8525349497795105, Rec 0.8719746470451355\n",
      "Epoch 437/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08130078762769699\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08431703299283981, Valid loss: 0.31237882375717163, IoU: 0.7593106031417847, Prec: 0.8595221638679504, Rec 0.8689273595809937\n",
      "Epoch 438/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11291413754224777\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08435405674907896, Valid loss: 0.33766674995422363, IoU: 0.7571527361869812, Prec: 0.8707160949707031, Rec 0.8550440073013306\n",
      "Epoch 439/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09871481359004974\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08454464508427514, Valid loss: 0.3035975992679596, IoU: 0.758476734161377, Prec: 0.8518235087394714, Rec 0.875627875328064\n",
      "Epoch 440/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10611657053232193\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08435317559374703, Valid loss: 0.34058877825737, IoU: 0.7579103112220764, Prec: 0.8728300333023071, Rec 0.8539853096008301\n",
      "Epoch 441/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11729349195957184\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08400324086348215, Valid loss: 0.3155358135700226, IoU: 0.7572722434997559, Prec: 0.855745792388916, Rec 0.8699365854263306\n",
      "Epoch 442/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08988624811172485\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08542335629463196, Valid loss: 0.31259527802467346, IoU: 0.7587069272994995, Prec: 0.8576070666313171, Rec 0.8700330853462219\n",
      "Epoch 443/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12719923257827764\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08530895643764072, Valid loss: 0.316101610660553, IoU: 0.7584346532821655, Prec: 0.8565605878829956, Rec 0.8707553148269653\n",
      "Epoch 444/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10121521353721619\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0856643603907691, Valid loss: 0.3382493853569031, IoU: 0.7573259472846985, Prec: 0.8682041168212891, Rec 0.8578364253044128\n",
      "Epoch 445/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06317836791276932\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08430305073658625, Valid loss: 0.3159182071685791, IoU: 0.7564470767974854, Prec: 0.8559085130691528, Rec 0.8688260316848755\n",
      "Epoch 446/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10586380958557129\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08280215726958381, Valid loss: 0.31678909063339233, IoU: 0.7589247822761536, Prec: 0.8626561164855957, Rec 0.8652048110961914\n",
      "Epoch 447/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07102277874946594\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0844790346092648, Valid loss: 0.3082987666130066, IoU: 0.7586938142776489, Prec: 0.8579986691474915, Rec 0.8695679903030396\n",
      "Epoch 448/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10145045071840286\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0835580403606097, Valid loss: 0.31871888041496277, IoU: 0.7574129700660706, Prec: 0.8568485379219055, Rec 0.8691302537918091\n",
      "Epoch 449/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08901781588792801\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0836382582783699, Valid loss: 0.30868062376976013, IoU: 0.7574058771133423, Prec: 0.8542629480361938, Rec 0.8717619180679321\n",
      "Epoch 450/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05391939729452133\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0828097672926055, Valid loss: 0.30628523230552673, IoU: 0.7576320767402649, Prec: 0.8544617891311646, Rec 0.8719350695610046\n",
      "Epoch 451/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08086173236370087\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08268546164035798, Valid loss: 0.32516220211982727, IoU: 0.7582978010177612, Prec: 0.8643226623535156, Rec 0.8627808690071106\n",
      "Epoch 452/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10869606584310532\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08355669097767936, Valid loss: 0.32579147815704346, IoU: 0.7579327821731567, Prec: 0.863392174243927, Rec 0.8631494641304016\n",
      "Epoch 453/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12508782744407654\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08355909519725375, Valid loss: 0.33912020921707153, IoU: 0.7573350071907043, Prec: 0.8668633699417114, Rec 0.8589396476745605\n",
      "Epoch 454/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07965794950723648\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08389431122276518, Valid loss: 0.31646424531936646, IoU: 0.7558035850524902, Prec: 0.851179301738739, Rec 0.8728947639465332\n",
      "Epoch 455/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11090932041406631\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08322682595915265, Valid loss: 0.32627326250076294, IoU: 0.7584480047225952, Prec: 0.8632165193557739, Rec 0.8640275001525879\n",
      "Epoch 456/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08388938009738922\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08386326332887013, Valid loss: 0.3133278489112854, IoU: 0.7580397725105286, Prec: 0.8571117520332336, Rec 0.8695457577705383\n",
      "Epoch 457/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09581439942121506\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08411946346362432, Valid loss: 0.32488563656806946, IoU: 0.7587248086929321, Prec: 0.8625389933586121, Rec 0.8650614023208618\n",
      "Epoch 458/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.056682050228118896\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08285760217242771, Valid loss: 0.3211115300655365, IoU: 0.7572012543678284, Prec: 0.858430027961731, Rec 0.8672677278518677\n",
      "Epoch 459/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07307327538728714\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08241598423984316, Valid loss: 0.3204997181892395, IoU: 0.758259117603302, Prec: 0.8613033294677734, Rec 0.8657416105270386\n",
      "Epoch 460/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09358013421297073\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08305657489432229, Valid loss: 0.3166962265968323, IoU: 0.7585498094558716, Prec: 0.8582728505134583, Rec 0.8690757751464844\n",
      "Epoch 461/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08113025128841435\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08228755626413557, Valid loss: 0.3116402328014374, IoU: 0.7587339282035828, Prec: 0.8559390902519226, Rec 0.8716704249382019\n",
      "Epoch 462/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11102969944477081\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08396418525113, Valid loss: 0.3349456191062927, IoU: 0.7577440738677979, Prec: 0.8656057119369507, Rec 0.8607279062271118\n",
      "Epoch 463/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10543798655271533\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08335080395142237, Valid loss: 0.315084308385849, IoU: 0.7570990324020386, Prec: 0.8532373309135437, Rec 0.8723629713058472\n",
      "Epoch 464/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09679333865642548\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08238400783803727, Valid loss: 0.3238759934902191, IoU: 0.7577034831047058, Prec: 0.8604995012283325, Rec 0.8657638430595398\n",
      "Epoch 465/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06876881420612335\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08333607150448694, Valid loss: 0.3244324326515198, IoU: 0.7582894563674927, Prec: 0.8620527386665344, Rec 0.864945113658905\n",
      "Epoch 466/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08973605930805206\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0830016146103541, Valid loss: 0.32476717233657837, IoU: 0.757720947265625, Prec: 0.8601706624031067, Rec 0.8661101460456848\n",
      "Epoch 467/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09095237404108047\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08283142861392763, Valid loss: 0.3209764361381531, IoU: 0.7575525045394897, Prec: 0.8582867383956909, Rec 0.8678415417671204\n",
      "Epoch 468/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07115118950605392\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08227987868918313, Valid loss: 0.3304843306541443, IoU: 0.7570463418960571, Prec: 0.8628060221672058, Rec 0.862625002861023\n",
      "Epoch 469/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10473620891571045\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08275902801089817, Valid loss: 0.32266655564308167, IoU: 0.7586830258369446, Prec: 0.860695481300354, Rec 0.8667755126953125\n",
      "Epoch 470/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07935124635696411\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0820857220225864, Valid loss: 0.33109402656555176, IoU: 0.7564783096313477, Prec: 0.8610204458236694, Rec 0.863743007183075\n",
      "Epoch 471/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07891356199979782\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08259715156422721, Valid loss: 0.3206879198551178, IoU: 0.7588645219802856, Prec: 0.8574764132499695, Rec 0.8702927827835083\n",
      "Epoch 472/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09884504228830338\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08284361312786738, Valid loss: 0.32867735624313354, IoU: 0.7571443915367126, Prec: 0.8602498769760132, Rec 0.8652592897415161\n",
      "Epoch 473/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11242900788784027\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08441934751139747, Valid loss: 0.33582526445388794, IoU: 0.7584514021873474, Prec: 0.8661972880363464, Rec 0.8610965013504028\n",
      "Epoch 474/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08138757199048996\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08301412181721793, Valid loss: 0.31453412771224976, IoU: 0.7556729912757874, Prec: 0.8494431376457214, Rec 0.8744653463363647\n",
      "Epoch 475/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08289768546819687\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08199433932701747, Valid loss: 0.3340372145175934, IoU: 0.7582367658615112, Prec: 0.8662645220756531, Rec 0.8607279062271118\n",
      "Epoch 476/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06874216347932816\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08239582727352777, Valid loss: 0.3188421130180359, IoU: 0.757839560508728, Prec: 0.8575454950332642, Rec 0.8688680529594421\n",
      "Epoch 477/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08412507921457297\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08239800880352656, Valid loss: 0.3281485438346863, IoU: 0.7565624713897705, Prec: 0.8602374196052551, Rec 0.8646112680435181\n",
      "Epoch 478/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12964215874671936\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08240360352728102, Valid loss: 0.32197505235671997, IoU: 0.7569018602371216, Prec: 0.8549773097038269, Rec 0.8703323602676392\n",
      "Epoch 479/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10136573016643524\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08135650389724308, Valid loss: 0.3234848976135254, IoU: 0.7578220367431641, Prec: 0.8594323992729187, Rec 0.8668422698974609\n",
      "Epoch 480/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10614247620105743\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08227785726388295, Valid loss: 0.339107483625412, IoU: 0.7588734030723572, Prec: 0.8689540028572083, Rec 0.8587961196899414\n",
      "Epoch 481/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10427007079124453\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08287770284546746, Valid loss: 0.31679901480674744, IoU: 0.7551925778388977, Prec: 0.8467329740524292, Rec 0.8765900731086731\n",
      "Epoch 482/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09340880811214447\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08269447452492185, Valid loss: 0.32575127482414246, IoU: 0.7579468488693237, Prec: 0.859640896320343, Rec 0.8668745160102844\n",
      "Epoch 483/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07325618714094162\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08105965306361516, Valid loss: 0.32840999960899353, IoU: 0.7567240595817566, Prec: 0.8589202761650085, Rec 0.865944504737854\n",
      "Epoch 484/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09411423653364182\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08237967011001375, Valid loss: 0.32130807638168335, IoU: 0.7572536468505859, Prec: 0.855294406414032, Rec 0.8704436421394348\n",
      "Epoch 485/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06429753452539444\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08184881822930443, Valid loss: 0.32314735651016235, IoU: 0.7572037577629089, Prec: 0.8595923185348511, Rec 0.8659839630126953\n",
      "Epoch 486/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09800985455513705\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0820367005136278, Valid loss: 0.3266445994377136, IoU: 0.7574979066848755, Prec: 0.8583950996398926, Rec 0.8675891757011414\n",
      "Epoch 487/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12653414905071259\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08182035916381412, Valid loss: 0.3259196877479553, IoU: 0.7590345144271851, Prec: 0.8618640899658203, Rec 0.8659766316413879\n",
      "Epoch 488/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07820896804332733\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.082592663831181, Valid loss: 0.3325308561325073, IoU: 0.7556462287902832, Prec: 0.8586030006408691, Rec 0.8650070428848267\n",
      "Epoch 489/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06700500845909119\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08099035819371542, Valid loss: 0.3085104525089264, IoU: 0.7557076215744019, Prec: 0.8450472950935364, Rec 0.8791724443435669\n",
      "Epoch 490/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08475811779499054\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08120130532317692, Valid loss: 0.33945232629776, IoU: 0.7576201558113098, Prec: 0.8674300909042358, Rec 0.8586872816085815\n",
      "Epoch 491/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08227579295635223\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08125472830401527, Valid loss: 0.3063972592353821, IoU: 0.7581697702407837, Prec: 0.8489898443222046, Rec 0.8781929016113281\n",
      "Epoch 492/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08632988482713705\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08298581457800336, Valid loss: 0.38131317496299744, IoU: 0.7540081143379211, Prec: 0.8807617425918579, Rec 0.8417937159538269\n",
      "Epoch 493/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07547450810670853\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0811300312479337, Valid loss: 0.30957892537117004, IoU: 0.7555745840072632, Prec: 0.8435183763504028, Rec 0.8806143999099731\n",
      "Epoch 494/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07734099030494691\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08091813921928406, Valid loss: 0.3477957546710968, IoU: 0.7578412890434265, Prec: 0.870888352394104, Rec 0.8556820750236511\n",
      "Epoch 495/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09763342887163162\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08207120382123523, Valid loss: 0.32377588748931885, IoU: 0.7580913305282593, Prec: 0.8561099767684937, Rec 0.8707082867622375\n",
      "Epoch 496/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07050932943820953\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08156079484356774, Valid loss: 0.3397665023803711, IoU: 0.7553908824920654, Prec: 0.8616711497306824, Rec 0.8616431355476379\n",
      "Epoch 497/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.26232460141181946\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08358313573731316, Valid loss: 0.34951648116111755, IoU: 0.7586604952812195, Prec: 0.8686292767524719, Rec 0.8589643239974976\n",
      "Epoch 498/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09117786586284637\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08267229828569624, Valid loss: 0.3252861797809601, IoU: 0.7558519840240479, Prec: 0.8568792343139648, Rec 0.8669214248657227\n",
      "Epoch 499/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07798024266958237\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08217323273420334, Valid loss: 0.3166918158531189, IoU: 0.7570976614952087, Prec: 0.8524726033210754, Rec 0.8730778694152832\n",
      "Epoch 500/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08134313672780991\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08157598425944647, Valid loss: 0.32746678590774536, IoU: 0.7551552057266235, Prec: 0.8568190336227417, Rec 0.8661348223686218\n",
      "Epoch 501/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07389299571514131\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08162669572565291, Valid loss: 0.3158906102180481, IoU: 0.7566319704055786, Prec: 0.8517317771911621, Rec 0.8734488487243652\n",
      "Epoch 502/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08850829303264618\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0816112369298935, Valid loss: 0.3369636833667755, IoU: 0.7573831081390381, Prec: 0.8642126321792603, Rec 0.8616752624511719\n",
      "Epoch 503/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06998226791620255\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0801329740219646, Valid loss: 0.3192072808742523, IoU: 0.7569441795349121, Prec: 0.8546613454818726, Rec 0.8706439733505249\n",
      "Epoch 504/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14874306321144104\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0818337125910653, Valid loss: 0.3426080346107483, IoU: 0.7586969137191772, Prec: 0.8678471446037292, Rec 0.8597484827041626\n",
      "Epoch 505/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08087281882762909\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08149094250467089, Valid loss: 0.3178800046443939, IoU: 0.756172239780426, Prec: 0.8510009050369263, Rec 0.8735255002975464\n",
      "Epoch 506/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09575320780277252\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08130425181653765, Valid loss: 0.33222144842147827, IoU: 0.7571491599082947, Prec: 0.8592572212219238, Rec 0.8663797378540039\n",
      "Epoch 507/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07597841322422028\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08181507421864403, Valid loss: 0.34354645013809204, IoU: 0.7552984356880188, Prec: 0.863991379737854, Rec 0.8593056797981262\n",
      "Epoch 508/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07290602475404744\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08128868225548003, Valid loss: 0.3189143240451813, IoU: 0.7553063631057739, Prec: 0.8500339388847351, Rec 0.8734167218208313\n",
      "Epoch 509/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05785796046257019\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07968510124418471, Valid loss: 0.32394275069236755, IoU: 0.7567907571792603, Prec: 0.8566076159477234, Rec 0.8685935139656067\n",
      "Epoch 510/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07055788487195969\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08025467975272073, Valid loss: 0.33141571283340454, IoU: 0.758333683013916, Prec: 0.8633313179016113, Rec 0.8637133836746216\n",
      "Epoch 511/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06569633632898331\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08103985736767451, Valid loss: 0.3244974613189697, IoU: 0.7565978169441223, Prec: 0.8562237024307251, Rec 0.868598461151123\n",
      "Epoch 512/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07647733390331268\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0810140997171402, Valid loss: 0.3184100389480591, IoU: 0.7567288875579834, Prec: 0.8566640019416809, Rec 0.868299126625061\n",
      "Epoch 513/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06339460611343384\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08088557124137878, Valid loss: 0.32106736302375793, IoU: 0.7572262287139893, Prec: 0.8569876551628113, Rec 0.8686478734016418\n",
      "Epoch 514/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07881713658571243\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07967887934711244, Valid loss: 0.32852548360824585, IoU: 0.7563128471374512, Prec: 0.8576661944389343, Rec 0.8668521642684937\n",
      "Epoch 515/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06459135562181473\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08079290406571495, Valid loss: 0.33552101254463196, IoU: 0.7546873688697815, Prec: 0.8587625622749329, Rec 0.863641619682312\n",
      "Epoch 516/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10984598100185394\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08190132081508636, Valid loss: 0.3226729929447174, IoU: 0.7566528916358948, Prec: 0.8537718653678894, Rec 0.8712202906608582\n",
      "Epoch 517/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11289212107658386\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0810292661190033, Valid loss: 0.34688305854797363, IoU: 0.7556881904602051, Prec: 0.8627904057502747, Rec 0.8609530329704285\n",
      "Epoch 518/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06681478023529053\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07974586553043789, Valid loss: 0.3260432779788971, IoU: 0.7560831904411316, Prec: 0.8541289567947388, Rec 0.8701121211051941\n",
      "Epoch 519/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07068051397800446\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08030968805154165, Valid loss: 0.3329021632671356, IoU: 0.7561926245689392, Prec: 0.860698401927948, Rec 0.8635204434394836\n",
      "Epoch 520/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07640608400106438\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08090786586205165, Valid loss: 0.33197730779647827, IoU: 0.7561278939247131, Prec: 0.8587591052055359, Rec 0.865415096282959\n",
      "Epoch 521/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14883695542812347\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08125544157293108, Valid loss: 0.33395469188690186, IoU: 0.7569640278816223, Prec: 0.8599861860275269, Rec 0.8653359413146973\n",
      "Epoch 522/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07090862095355988\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08081771367126041, Valid loss: 0.3350073993206024, IoU: 0.752870500087738, Prec: 0.8535276651382446, Rec 0.8665701746940613\n",
      "Epoch 523/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06368009746074677\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08056943184799618, Valid loss: 0.3202136158943176, IoU: 0.7558539509773254, Prec: 0.851253867149353, Rec 0.8728700876235962\n",
      "Epoch 524/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10515395551919937\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08052738193008635, Valid loss: 0.33835726976394653, IoU: 0.7572620511054993, Prec: 0.8618923425674438, Rec 0.8637579083442688\n",
      "Epoch 525/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08724472671747208\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08005816820594999, Valid loss: 0.3311282694339752, IoU: 0.7573001980781555, Prec: 0.8601608276367188, Rec 0.8655363321304321\n",
      "Epoch 526/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06751474738121033\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08003254863950941, Valid loss: 0.33249062299728394, IoU: 0.7560585737228394, Prec: 0.8577830195426941, Rec 0.8663673400878906\n",
      "Epoch 527/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07428996264934547\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07977204157246484, Valid loss: 0.3251374661922455, IoU: 0.7573724389076233, Prec: 0.8555160760879517, Rec 0.8703545331954956\n",
      "Epoch 528/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08565351366996765\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08134395281473795, Valid loss: 0.3464721143245697, IoU: 0.7561352252960205, Prec: 0.8663692474365234, Rec 0.8579082489013672\n",
      "Epoch 529/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10983061790466309\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08043276402685377, Valid loss: 0.3407197594642639, IoU: 0.7566913366317749, Prec: 0.8609107732772827, Rec 0.8639854192733765\n",
      "Epoch 530/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08933090418577194\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.0791720997956064, Valid loss: 0.32735884189605713, IoU: 0.7572455406188965, Prec: 0.857440173625946, Rec 0.8682026863098145\n",
      "Epoch 531/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10399227589368826\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07930486351251602, Valid loss: 0.33149275183677673, IoU: 0.7573645710945129, Prec: 0.8585440516471863, Rec 0.8671860694885254\n",
      "Epoch 532/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06472799926996231\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07964807632896635, Valid loss: 0.33968061208724976, IoU: 0.7575265765190125, Prec: 0.8641448020935059, Rec 0.8618385195732117\n",
      "Epoch 533/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08201547712087631\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07916146831379997, Valid loss: 0.3373834490776062, IoU: 0.7570213079452515, Prec: 0.8610036969184875, Rec 0.8642179369926453\n",
      "Epoch 534/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08302573859691623\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07987964120176104, Valid loss: 0.3449306786060333, IoU: 0.7559341788291931, Prec: 0.8620437383651733, Rec 0.8618335723876953\n",
      "Epoch 535/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09799759835004807\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08002702908383476, Valid loss: 0.3281937539577484, IoU: 0.7565521001815796, Prec: 0.853436291217804, Rec 0.8713983297348022\n",
      "Epoch 536/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09581203758716583\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07981319195694393, Valid loss: 0.3532636761665344, IoU: 0.7551797032356262, Prec: 0.8644374012947083, Rec 0.8586230278015137\n",
      "Epoch 537/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12767885625362396\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08104710545804765, Valid loss: 0.32006093859672546, IoU: 0.7562021017074585, Prec: 0.850265383720398, Rec 0.8743541836738586\n",
      "Epoch 538/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08778126537799835\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.079961206846767, Valid loss: 0.3316819369792938, IoU: 0.7580655217170715, Prec: 0.8608673214912415, Rec 0.8658355474472046\n",
      "Epoch 539/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10161241143941879\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08005739500125249, Valid loss: 0.3466988801956177, IoU: 0.7566959261894226, Prec: 0.8656736612319946, Rec 0.8592635989189148\n",
      "Epoch 540/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07681516557931995\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07970511267582575, Valid loss: 0.32044678926467896, IoU: 0.7545169591903687, Prec: 0.847710132598877, Rec 0.8747869729995728\n",
      "Epoch 541/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09961646050214767\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.08029166112343471, Valid loss: 0.3500943183898926, IoU: 0.7556168437004089, Prec: 0.8680693507194519, Rec 0.8557117581367493\n",
      "Epoch 542/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08768980950117111\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07992804298798244, Valid loss: 0.3253251612186432, IoU: 0.7572745680809021, Prec: 0.8564311861991882, Rec 0.8693354725837708\n",
      "Epoch 543/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09666028618812561\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0788724660873413, Valid loss: 0.3502086400985718, IoU: 0.7568308115005493, Prec: 0.8663738369941711, Rec 0.8587862849235535\n",
      "Epoch 544/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08108591288328171\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07980228712161382, Valid loss: 0.33027002215385437, IoU: 0.7567814588546753, Prec: 0.8557720184326172, Rec 0.8693231344223022\n",
      "Epoch 545/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08909264951944351\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07882782833443748, Valid loss: 0.34084832668304443, IoU: 0.7564674615859985, Prec: 0.8600460886955261, Rec 0.8645147085189819\n",
      "Epoch 546/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09448949247598648\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07878828992446264, Valid loss: 0.3311956524848938, IoU: 0.7565773129463196, Prec: 0.8550323247909546, Rec 0.8697807192802429\n",
      "Epoch 547/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07785199582576752\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07830571697817909, Valid loss: 0.3475398123264313, IoU: 0.7556833028793335, Prec: 0.8628032803535461, Rec 0.8607872724533081\n",
      "Epoch 548/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10036414116621017\n",
      "Epoch finished in 0.3 seconds\n",
      "Train loss: 0.07855459898710251, Valid loss: 0.33385857939720154, IoU: 0.7560937404632568, Prec: 0.8564136624336243, Rec 0.8677277565002441\n",
      "Epoch 549/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13869380950927734\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07923287550608317, Valid loss: 0.3527293801307678, IoU: 0.7580091953277588, Prec: 0.8679453134536743, Rec 0.858729362487793\n",
      "Epoch 550/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07113905996084213\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07915636748075486, Valid loss: 0.33442825078964233, IoU: 0.754379391670227, Prec: 0.8521034121513367, Rec 0.8699489831924438\n",
      "Epoch 551/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07793281972408295\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07899635467264388, Valid loss: 0.3372746706008911, IoU: 0.7568565011024475, Prec: 0.8575446009635925, Rec 0.8676214218139648\n",
      "Epoch 552/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07109795510768895\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07822362813684676, Valid loss: 0.3434237837791443, IoU: 0.7551649808883667, Prec: 0.858983039855957, Rec 0.8639112710952759\n",
      "Epoch 553/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08775122463703156\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08036067055331336, Valid loss: 0.32450366020202637, IoU: 0.7559612989425659, Prec: 0.8500789403915405, Rec 0.8741289973258972\n",
      "Epoch 554/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.062291380017995834\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07990753576159478, Valid loss: 0.3587133288383484, IoU: 0.7562190294265747, Prec: 0.8682559132575989, Rec 0.8560382723808289\n",
      "Epoch 555/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07727974653244019\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08002780543433295, Valid loss: 0.3400445878505707, IoU: 0.7539618015289307, Prec: 0.8543347120285034, Rec 0.8671292066574097\n",
      "Epoch 556/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09057369828224182\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07864909900559319, Valid loss: 0.33047178387641907, IoU: 0.7553468346595764, Prec: 0.8535252809524536, Rec 0.8698153495788574\n",
      "Epoch 557/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07511600852012634\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07924444874127706, Valid loss: 0.3423963785171509, IoU: 0.7553183436393738, Prec: 0.8595544099807739, Rec 0.8635624647140503\n",
      "Epoch 558/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08915375918149948\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07868960416979259, Valid loss: 0.33285194635391235, IoU: 0.7568179965019226, Prec: 0.8579941987991333, Rec 0.8671340942382812\n",
      "Epoch 559/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.061448175460100174\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07836141164104143, Valid loss: 0.3379340171813965, IoU: 0.7563313841819763, Prec: 0.8596875071525574, Rec 0.8646953701972961\n",
      "Epoch 560/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08563015609979639\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07867062174611622, Valid loss: 0.3442193567752838, IoU: 0.7561283707618713, Prec: 0.8617105484008789, Rec 0.8624098896980286\n",
      "Epoch 561/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07195965945720673\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07847388287385305, Valid loss: 0.3364441394805908, IoU: 0.7563835382461548, Prec: 0.8584381341934204, Rec 0.866063117980957\n",
      "Epoch 562/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11618157476186752\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07956190357605616, Valid loss: 0.3483986258506775, IoU: 0.7564436793327332, Prec: 0.8641672134399414, Rec 0.8604286313056946\n",
      "Epoch 563/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14542379975318912\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07926065590646532, Valid loss: 0.3434126377105713, IoU: 0.7553091049194336, Prec: 0.8557056188583374, Rec 0.8675397634506226\n",
      "Epoch 564/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08641058951616287\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07778442982170317, Valid loss: 0.3433113694190979, IoU: 0.7557100057601929, Prec: 0.8585022687911987, Rec 0.8651579022407532\n",
      "Epoch 565/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09750811755657196\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07864373690552182, Valid loss: 0.35878250002861023, IoU: 0.755061686038971, Prec: 0.865480899810791, Rec 0.8573269844055176\n",
      "Epoch 566/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09276936948299408\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07815960347652436, Valid loss: 0.32910212874412537, IoU: 0.7534953951835632, Prec: 0.8462435007095337, Rec 0.8749725222587585\n",
      "Epoch 567/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11276744306087494\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07878704369068146, Valid loss: 0.3457964360713959, IoU: 0.7567664980888367, Prec: 0.8619699478149414, Rec 0.8630925416946411\n",
      "Epoch 568/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.32680663466453557\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.08323706852065192, Valid loss: 0.38553348183631897, IoU: 0.7548151612281799, Prec: 0.8779013752937317, Rec 0.8452838063240051\n",
      "Epoch 569/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06731155514717102\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08049662775463529, Valid loss: 0.33538389205932617, IoU: 0.7510532140731812, Prec: 0.8461508750915527, Rec 0.871848464012146\n",
      "Epoch 570/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.0768483430147171\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07843732072247399, Valid loss: 0.33669227361679077, IoU: 0.7548819780349731, Prec: 0.8540010452270508, Rec 0.8687641024589539\n",
      "Epoch 571/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10277391970157623\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07912856770886315, Valid loss: 0.348859578371048, IoU: 0.756990373134613, Prec: 0.8684135675430298, Rec 0.8569262623786926\n",
      "Epoch 572/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08418262004852295\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07860991623666551, Valid loss: 0.3322560489177704, IoU: 0.7546573877334595, Prec: 0.8528709411621094, Rec 0.869402289390564\n",
      "Epoch 573/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06704758852720264\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07762243929836485, Valid loss: 0.32192349433898926, IoU: 0.7540953755378723, Prec: 0.8465474843978882, Rec 0.8754053115844727\n",
      "Epoch 574/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10747705399990082\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07881936464044782, Valid loss: 0.34675371646881104, IoU: 0.756736159324646, Prec: 0.8638497591018677, Rec 0.8611113429069519\n",
      "Epoch 575/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07543801516294484\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07833059148655998, Valid loss: 0.3298186659812927, IoU: 0.7553609013557434, Prec: 0.8537576794624329, Rec 0.8694888949394226\n",
      "Epoch 576/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06974995881319046\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07734032819668452, Valid loss: 0.32614415884017944, IoU: 0.7569497227668762, Prec: 0.8548415899276733, Rec 0.870488166809082\n",
      "Epoch 577/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14260643720626834\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.08022412988874647, Valid loss: 0.3511398434638977, IoU: 0.7578953504562378, Prec: 0.8677328824996948, Rec 0.8587541580200195\n",
      "Epoch 578/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09015504270792007\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0788180614511172, Valid loss: 0.340889036655426, IoU: 0.7564719319343567, Prec: 0.8585456013679504, Rec 0.8660730123519897\n",
      "Epoch 579/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10601497441530228\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07844518307182524, Valid loss: 0.33216923475265503, IoU: 0.7542651295661926, Prec: 0.8485175371170044, Rec 0.8736368417739868\n",
      "Epoch 580/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05898447707295418\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07727449643943045, Valid loss: 0.33164599537849426, IoU: 0.7560039758682251, Prec: 0.8557912707328796, Rec 0.8682793378829956\n",
      "Epoch 581/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06017622724175453\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07793320028318299, Valid loss: 0.3316742777824402, IoU: 0.7556279897689819, Prec: 0.8550203442573547, Rec 0.8685019612312317\n",
      "Epoch 582/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07310455292463303\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.0777180372012986, Valid loss: 0.33523863554000854, IoU: 0.7549945116043091, Prec: 0.8552764058113098, Rec 0.8674977421760559\n",
      "Epoch 583/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06265898793935776\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07737349652581745, Valid loss: 0.3356204032897949, IoU: 0.7545219659805298, Prec: 0.8544957041740417, Rec 0.8677302598953247\n",
      "Epoch 584/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.04901200160384178\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07815732947654194, Valid loss: 0.33344370126724243, IoU: 0.7564188241958618, Prec: 0.8596933484077454, Rec 0.8648363351821899\n",
      "Epoch 585/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07958211749792099\n",
      "Epoch finished in 0.6 seconds\n",
      "Train loss: 0.0771034954322709, Valid loss: 0.3348618149757385, IoU: 0.7561282515525818, Prec: 0.8572368621826172, Rec 0.8669659495353699\n",
      "Epoch 586/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07135263085365295\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07809797326723734, Valid loss: 0.3390578627586365, IoU: 0.7571346163749695, Prec: 0.8604512214660645, Rec 0.8650614023208618\n",
      "Epoch 587/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12497723102569584\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07798272371292114, Valid loss: 0.3515070378780365, IoU: 0.7557876706123352, Prec: 0.8632079362869263, Rec 0.8605077862739563\n",
      "Epoch 588/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08116162568330765\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.0771981300579177, Valid loss: 0.3424236476421356, IoU: 0.7545456886291504, Prec: 0.8554391860961914, Rec 0.8667532205581665\n",
      "Epoch 589/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06438906490802765\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07737063467502595, Valid loss: 0.3439934253692627, IoU: 0.7553030848503113, Prec: 0.8581754565238953, Rec 0.8649724125862122\n",
      "Epoch 590/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07984904944896698\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07804641425609589, Valid loss: 0.3466074764728546, IoU: 0.754796028137207, Prec: 0.8585299253463745, Rec 0.863965630531311\n",
      "Epoch 591/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06251348555088043\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07742762598726484, Valid loss: 0.3350357413291931, IoU: 0.754967987537384, Prec: 0.8537582159042358, Rec 0.8690411448478699\n",
      "Epoch 592/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06967049092054367\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07760576655467351, Valid loss: 0.3537972569465637, IoU: 0.755395233631134, Prec: 0.8629001379013062, Rec 0.8602876663208008\n",
      "Epoch 593/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10163339972496033\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07708079947365655, Valid loss: 0.33942675590515137, IoU: 0.7565232515335083, Prec: 0.8570548892021179, Rec 0.867606520652771\n",
      "Epoch 594/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08063683658838272\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07800959828827116, Valid loss: 0.3458327651023865, IoU: 0.7554914355278015, Prec: 0.8592979311943054, Rec 0.8640424013137817\n",
      "Epoch 595/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07872788608074188\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07816868556870354, Valid loss: 0.3385528326034546, IoU: 0.7561805248260498, Prec: 0.857201874256134, Rec 0.8671315908432007\n",
      "Epoch 596/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08873560279607773\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0775071394112375, Valid loss: 0.35407593846321106, IoU: 0.7550933957099915, Prec: 0.8622933626174927, Rec 0.8605597615242004\n",
      "Epoch 597/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15841723978519448\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07916400531927745, Valid loss: 0.36101970076560974, IoU: 0.7552347779273987, Prec: 0.8653512001037598, Rec 0.8577919006347656\n",
      "Epoch 598/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07733039557933807\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07750738031334348, Valid loss: 0.34819474816322327, IoU: 0.7520204782485962, Prec: 0.8508085012435913, Rec 0.868252158164978\n",
      "Epoch 599/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06644542515277863\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0777730468246672, Valid loss: 0.35089558362960815, IoU: 0.7545716166496277, Prec: 0.8580468893051147, Rec 0.8642303347587585\n",
      "Epoch 600/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10383693873882294\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0788696351978514, Valid loss: 0.3542789816856384, IoU: 0.7540198564529419, Prec: 0.8585805892944336, Rec 0.8629268407821655\n",
      "Epoch 601/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07316873222589493\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07705249538024267, Valid loss: 0.33837470412254333, IoU: 0.7533419132232666, Prec: 0.8502505421638489, Rec 0.870582103729248\n",
      "Epoch 602/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07348634302616122\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07716068724791209, Valid loss: 0.34739217162132263, IoU: 0.7546547651290894, Prec: 0.8574663400650024, Rec 0.8648883104324341\n",
      "Epoch 603/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06063562259078026\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07693848204281595, Valid loss: 0.3372703194618225, IoU: 0.7556871771812439, Prec: 0.8545953035354614, Rec 0.8691079020500183\n",
      "Epoch 604/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06890460103750229\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07617829359240003, Valid loss: 0.34192103147506714, IoU: 0.755562424659729, Prec: 0.8570615649223328, Rec 0.8664044141769409\n",
      "Epoch 605/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11052732169628143\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07839412788550058, Valid loss: 0.3442121148109436, IoU: 0.7566390633583069, Prec: 0.8618823885917664, Rec 0.8629218935966492\n",
      "Epoch 606/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07786838710308075\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07756998042265574, Valid loss: 0.34029510617256165, IoU: 0.7532371282577515, Prec: 0.8513134717941284, Rec 0.8691104650497437\n",
      "Epoch 607/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07850711792707443\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07742007788684634, Valid loss: 0.33332517743110657, IoU: 0.7541405558586121, Prec: 0.85003262758255, Rec 0.8718163371086121\n",
      "Epoch 608/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09748482704162598\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07707455986075931, Valid loss: 0.3639592230319977, IoU: 0.7554155588150024, Prec: 0.8663938641548157, Rec 0.8569015264511108\n",
      "Epoch 609/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06046122685074806\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07742430774701967, Valid loss: 0.33887046575546265, IoU: 0.755200982093811, Prec: 0.8546550869941711, Rec 0.8683338165283203\n",
      "Epoch 610/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07879400253295898\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07788761920399136, Valid loss: 0.357785165309906, IoU: 0.755113422870636, Prec: 0.8637779355049133, Rec 0.8590905070304871\n",
      "Epoch 611/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13372816145420074\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07823052903016409, Valid loss: 0.33966541290283203, IoU: 0.7550947070121765, Prec: 0.8537428975105286, Rec 0.8691970109939575\n",
      "Epoch 612/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10464461147785187\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07731249497996437, Valid loss: 0.33823490142822266, IoU: 0.7548972964286804, Prec: 0.8537853956222534, Rec 0.8688260316848755\n",
      "Epoch 613/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07765225321054459\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0789977479312155, Valid loss: 0.3519911468029022, IoU: 0.7564763426780701, Prec: 0.8649107813835144, Rec 0.8596222996711731\n",
      "Epoch 614/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08411407470703125\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0776559915807512, Valid loss: 0.3377074599266052, IoU: 0.7547177076339722, Prec: 0.8540822267532349, Rec 0.8682694435119629\n",
      "Epoch 615/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08584932237863545\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0776449582642979, Valid loss: 0.3584333062171936, IoU: 0.7551450729370117, Prec: 0.8622722625732422, Rec 0.8607230186462402\n",
      "Epoch 616/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11744381487369537\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07667352457841238, Valid loss: 0.35559120774269104, IoU: 0.7548418641090393, Prec: 0.8598386645317078, Rec 0.8627066612243652\n",
      "Epoch 617/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13585330545902252\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07785392502943675, Valid loss: 0.34860357642173767, IoU: 0.7549603581428528, Prec: 0.8557186126708984, Rec 0.867027759552002\n",
      "Epoch 618/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09410432726144795\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07789950850937101, Valid loss: 0.34906381368637085, IoU: 0.7543511986732483, Prec: 0.8545719385147095, Rec 0.8674433827400208\n",
      "Epoch 619/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15525479614734653\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07783130572901832, Valid loss: 0.36493945121765137, IoU: 0.7552168369293213, Prec: 0.8662418127059937, Rec 0.8569337129592896\n",
      "Epoch 620/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10073556005954742\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.078894947303666, Valid loss: 0.35142290592193604, IoU: 0.7530544400215149, Prec: 0.8555719256401062, Rec 0.8648263812065125\n",
      "Epoch 621/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.04855373501777649\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07740070886082119, Valid loss: 0.33013203740119934, IoU: 0.7530376315116882, Prec: 0.8478580713272095, Rec 0.8727785348892212\n",
      "Epoch 622/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07675004005432129\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07679991788334317, Valid loss: 0.3440408408641815, IoU: 0.7564905881881714, Prec: 0.8609374761581421, Rec 0.8637406229972839\n",
      "Epoch 623/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06741694360971451\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07666837688949373, Valid loss: 0.3354502320289612, IoU: 0.7550126314163208, Prec: 0.8547986745834351, Rec 0.8679677248001099\n",
      "Epoch 624/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07065645605325699\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07604070057471593, Valid loss: 0.32964277267456055, IoU: 0.7554367780685425, Prec: 0.8529564142227173, Rec 0.8704262971878052\n",
      "Epoch 625/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09556571394205093\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07638007783227496, Valid loss: 0.3533115088939667, IoU: 0.7546898722648621, Prec: 0.8598887324333191, Rec 0.8624395132064819\n",
      "Epoch 626/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07339581847190857\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07763774262534248, Valid loss: 0.33848837018013, IoU: 0.7549997568130493, Prec: 0.8535510897636414, Rec 0.8692464828491211\n",
      "Epoch 627/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12663307785987854\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07700360351138645, Valid loss: 0.37304574251174927, IoU: 0.7550866603851318, Prec: 0.8690550923347473, Rec 0.8539086580276489\n",
      "Epoch 628/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07718829065561295\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07560244484080209, Valid loss: 0.34467509388923645, IoU: 0.7541527152061462, Prec: 0.8541983366012573, Rec 0.8675323724746704\n",
      "Epoch 629/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09851628541946411\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07552694678306579, Valid loss: 0.3365548253059387, IoU: 0.7544703483581543, Prec: 0.8505465388298035, Rec 0.8717050552368164\n",
      "Epoch 630/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08784765750169754\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0767678706182374, Valid loss: 0.36071085929870605, IoU: 0.754926323890686, Prec: 0.8641639947891235, Rec 0.8584524393081665\n",
      "Epoch 631/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09390153735876083\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07590573148594962, Valid loss: 0.34375351667404175, IoU: 0.755382239818573, Prec: 0.8562377691268921, Rec 0.866995632648468\n",
      "Epoch 632/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07338058203458786\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07710442658927706, Valid loss: 0.3533267080783844, IoU: 0.7544674873352051, Prec: 0.8588253855705261, Rec 0.8631717562675476\n",
      "Epoch 633/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06808408349752426\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07631900757551194, Valid loss: 0.3552798628807068, IoU: 0.7537644505500793, Prec: 0.8574511408805847, Rec 0.8637059330940247\n",
      "Epoch 634/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11924877762794495\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07614622049861484, Valid loss: 0.35222774744033813, IoU: 0.7557902932167053, Prec: 0.859821617603302, Rec 0.8639483451843262\n",
      "Epoch 635/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07807264477014542\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07632767375972536, Valid loss: 0.3575408458709717, IoU: 0.7544916868209839, Prec: 0.8607252240180969, Rec 0.8613067865371704\n",
      "Epoch 636/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09200066328048706\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07680157820383708, Valid loss: 0.3510691523551941, IoU: 0.7544534802436829, Prec: 0.8557718396186829, Rec 0.8663104772567749\n",
      "Epoch 637/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09327272325754166\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07684342016776403, Valid loss: 0.3527907729148865, IoU: 0.7553157210350037, Prec: 0.8602558970451355, Rec 0.8628970980644226\n",
      "Epoch 638/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09915041923522949\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0759948452313741, Valid loss: 0.3539366126060486, IoU: 0.7553204298019409, Prec: 0.8614751696586609, Rec 0.8616876602172852\n",
      "Epoch 639/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09065896272659302\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.075684169265959, Valid loss: 0.3558914065361023, IoU: 0.75397789478302, Prec: 0.8562275171279907, Rec 0.8652592897415161\n",
      "Epoch 640/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06837159395217896\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07648288210233052, Valid loss: 0.34640365839004517, IoU: 0.753860592842102, Prec: 0.8535900115966797, Rec 0.8677252531051636\n",
      "Epoch 641/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07533249258995056\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07637303140428331, Valid loss: 0.34888365864753723, IoU: 0.7548441290855408, Prec: 0.858555793762207, Rec 0.8639112710952759\n",
      "Epoch 642/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.075959853827953344\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0753472849726677, Valid loss: 0.34492453932762146, IoU: 0.7543692588806152, Prec: 0.8542904853820801, Rec 0.8676437139511108\n",
      "Epoch 643/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08619399368762975\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07645097672939301, Valid loss: 0.3581993877887726, IoU: 0.7535504102706909, Prec: 0.8578882217407227, Rec 0.862936794757843\n",
      "Epoch 644/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05481911078095436\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07707365759544903, Valid loss: 0.3421867787837982, IoU: 0.7523876428604126, Prec: 0.8516902923583984, Rec 0.8677153587341309\n",
      "Epoch 645/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10114994645118713\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07609282930692036, Valid loss: 0.34276801347732544, IoU: 0.7543200254440308, Prec: 0.8517128229141235, Rec 0.8703075647354126\n",
      "Epoch 646/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06068985164165497\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07650814354419708, Valid loss: 0.3653937578201294, IoU: 0.754645824432373, Prec: 0.8651788830757141, Rec 0.8571316003799438\n",
      "Epoch 647/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09210375696420674\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07607103536526362, Valid loss: 0.3456919491291046, IoU: 0.754185676574707, Prec: 0.8536001443862915, Rec 0.8681556582450867\n",
      "Epoch 648/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07095494121313095\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0764317888352606, Valid loss: 0.359625905752182, IoU: 0.753616988658905, Prec: 0.8585765957832336, Rec 0.8623653650283813\n",
      "Epoch 649/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.15624725818634033\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07685869601037768, Valid loss: 0.36539146304130554, IoU: 0.7551708221435547, Prec: 0.8620306253433228, Rec 0.8609579801559448\n",
      "Epoch 650/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07974079996347427\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07636228485239877, Valid loss: 0.36229535937309265, IoU: 0.7541362047195435, Prec: 0.8618087768554688, Rec 0.8598548173904419\n",
      "Epoch 651/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07001794129610062\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07564372536208895, Valid loss: 0.34484580159187317, IoU: 0.7543514966964722, Prec: 0.8529582023620605, Rec 0.8690387010574341\n",
      "Epoch 652/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07847408205270767\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07570125543408923, Valid loss: 0.3554111123085022, IoU: 0.7540327310562134, Prec: 0.8577524423599243, Rec 0.8637158274650574\n",
      "Epoch 653/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10060124844312668\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07623738232586119, Valid loss: 0.3522936701774597, IoU: 0.7544247508049011, Prec: 0.8562802076339722, Rec 0.8656722903251648\n",
      "Epoch 654/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07968262583017349\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07619107878870435, Valid loss: 0.35905176401138306, IoU: 0.7540640830993652, Prec: 0.8591684103012085, Rec 0.8622244000434875\n",
      "Epoch 655/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08927552402019501\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0767350650495953, Valid loss: 0.3456133008003235, IoU: 0.7533798217773438, Prec: 0.8517208099365234, Rec 0.8689422607421875\n",
      "Epoch 656/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09505499899387364\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07522230313883888, Valid loss: 0.3549061119556427, IoU: 0.7541481256484985, Prec: 0.8566716909408569, Rec 0.8648980855941772\n",
      "Epoch 657/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07425927370786667\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07715873569250106, Valid loss: 0.3651975691318512, IoU: 0.7543050050735474, Prec: 0.8628339767456055, Rec 0.8588752746582031\n",
      "Epoch 658/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09009969234466553\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07569219999843174, Valid loss: 0.34365546703338623, IoU: 0.753133237361908, Prec: 0.8502370715141296, Rec 0.8702036738395691\n",
      "Epoch 659/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08359908312559128\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07595846239063475, Valid loss: 0.3579843044281006, IoU: 0.7548368573188782, Prec: 0.8607684373855591, Rec 0.8617073893547058\n",
      "Epoch 660/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14153490960597992\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07790807386239369, Valid loss: 0.3852381408214569, IoU: 0.7553638219833374, Prec: 0.8748782277107239, Rec 0.8487712740898132\n",
      "Epoch 661/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06483060866594315\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07649318327506384, Valid loss: 0.34316256642341614, IoU: 0.7514921426773071, Prec: 0.8481709361076355, Rec 0.8702333569526672\n",
      "Epoch 662/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07086901366710663\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07743110491169823, Valid loss: 0.34362465143203735, IoU: 0.7525339722633362, Prec: 0.8487423062324524, Rec 0.8710718154907227\n",
      "Epoch 663/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07921370863914497\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.0776068905989329, Valid loss: 0.35278409719467163, IoU: 0.7544852495193481, Prec: 0.8579331636428833, Rec 0.8641611337661743\n",
      "Epoch 664/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07163272798061371\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07626148462295532, Valid loss: 0.34605640172958374, IoU: 0.7542575597763062, Prec: 0.8556712865829468, Rec 0.8661472201347351\n",
      "Epoch 665/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07853820919990541\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07599521411789788, Valid loss: 0.36238542199134827, IoU: 0.7541013360023499, Prec: 0.8614166975021362, Rec 0.8601442575454712\n",
      "Epoch 666/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07759922742843628\n",
      "Epoch finished in 0.6 seconds\n",
      "Train loss: 0.07583609289593167, Valid loss: 0.34493768215179443, IoU: 0.7516855001449585, Prec: 0.8484266400337219, Rec 0.8701987266540527\n",
      "Epoch 667/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10702585428953171\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07607619414726893, Valid loss: 0.3583572208881378, IoU: 0.7545231580734253, Prec: 0.8605774641036987, Rec 0.8615886569023132\n",
      "Epoch 668/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07472360134124756\n",
      "Epoch finished in 0.6 seconds\n",
      "Train loss: 0.0760036567846934, Valid loss: 0.36232462525367737, IoU: 0.7535713911056519, Prec: 0.8611198663711548, Rec 0.8597360849380493\n",
      "Epoch 669/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08016464114189148\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07553279333644443, Valid loss: 0.34596726298332214, IoU: 0.7534602284431458, Prec: 0.8527695536613464, Rec 0.8680022954940796\n",
      "Epoch 670/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08685394376516342\n",
      "Epoch finished in 0.6 seconds\n",
      "Train loss: 0.07551750590403875, Valid loss: 0.35249537229537964, IoU: 0.7539394497871399, Prec: 0.8568210601806641, Rec 0.8645395040512085\n",
      "Epoch 671/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07743312418460846\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.0745937681860394, Valid loss: 0.3557314872741699, IoU: 0.7539240121841431, Prec: 0.8567497134208679, Rec 0.8645592927932739\n",
      "Epoch 672/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06083354726433754\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07546528023150233, Valid loss: 0.3416195511817932, IoU: 0.7529665231704712, Prec: 0.8495529890060425, Rec 0.8706983327865601\n",
      "Epoch 673/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07813685387372973\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07478442904022005, Valid loss: 0.3522340953350067, IoU: 0.7550907135009766, Prec: 0.8579491376876831, Rec 0.8648585081100464\n",
      "Epoch 674/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06869748979806954\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07451778401931126, Valid loss: 0.3631809651851654, IoU: 0.7536619901657104, Prec: 0.862932562828064, Rec 0.8579626083374023\n",
      "Epoch 675/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08185063302516937\n",
      "Epoch finished in 0.6 seconds\n",
      "Train loss: 0.0747963998052809, Valid loss: 0.34862130880355835, IoU: 0.7522248029708862, Prec: 0.848709225654602, Rec 0.870557427406311\n",
      "Epoch 676/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06576033681631088\n",
      "Epoch finished in 0.6 seconds\n",
      "Train loss: 0.07595671862363815, Valid loss: 0.3579992353916168, IoU: 0.7536488771438599, Prec: 0.858494758605957, Rec 0.8624098896980286\n",
      "Epoch 677/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06072595342993736\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07669938463303778, Valid loss: 0.34288737177848816, IoU: 0.7537729740142822, Prec: 0.8513878583908081, Rec 0.8698153495788574\n",
      "Epoch 678/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06772746890783317\n",
      "Epoch finished in 0.6 seconds\n",
      "Train loss: 0.07485426912705104, Valid loss: 0.35200342535972595, IoU: 0.7540802359580994, Prec: 0.8561422228813171, Rec 0.8653408885002136\n",
      "Epoch 679/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08957687020301819\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07476733658048841, Valid loss: 0.3551800847053528, IoU: 0.7543123960494995, Prec: 0.8580719232559204, Rec 0.8637455105781555\n",
      "Epoch 680/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11475970596075058\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07531953801711401, Valid loss: 0.3660833537578583, IoU: 0.7539037466049194, Prec: 0.8607380986213684, Rec 0.8605622053146362\n",
      "Epoch 681/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.132527053356170655\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.0757794588804245, Valid loss: 0.3758307099342346, IoU: 0.7549272775650024, Prec: 0.8674238324165344, Rec 0.8553506731987\n",
      "Epoch 682/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09028835594654083\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07565922439098358, Valid loss: 0.36038947105407715, IoU: 0.7519062161445618, Prec: 0.8534008264541626, Rec 0.8654398918151855\n",
      "Epoch 683/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09210485219955444\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07526177300347223, Valid loss: 0.3458278775215149, IoU: 0.7518160343170166, Prec: 0.8454011678695679, Rec 0.8736838102340698\n",
      "Epoch 684/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08753767609596252\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07542762955029805, Valid loss: 0.3687116205692291, IoU: 0.7551962733268738, Prec: 0.8645105361938477, Rec 0.8585488200187683\n",
      "Epoch 685/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10875990986824036\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07674248218536377, Valid loss: 0.34621089696884155, IoU: 0.7540031671524048, Prec: 0.8508561253547668, Rec 0.8707898855209351\n",
      "Epoch 686/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09218873083591461\n",
      "Epoch finished in 0.6 seconds\n",
      "Train loss: 0.07571035921573639, Valid loss: 0.3559838533401489, IoU: 0.7556383609771729, Prec: 0.8591197729110718, Rec 0.8644232749938965\n",
      "Epoch 687/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07269018888473511\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07605308890342713, Valid loss: 0.35675546526908875, IoU: 0.7552888989448547, Prec: 0.8599851727485657, Rec 0.8630752563476562\n",
      "Epoch 688/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09058073163032532\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07483737998538548, Valid loss: 0.3580969572067261, IoU: 0.7540941834449768, Prec: 0.8575490713119507, Rec 0.8640077710151672\n",
      "Epoch 689/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08686356246471405\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0751312557193968, Valid loss: 0.35476914048194885, IoU: 0.753322422504425, Prec: 0.8541160821914673, Rec 0.866431713104248\n",
      "Epoch 690/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.054229579865932465\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07488164090447956, Valid loss: 0.3506328761577606, IoU: 0.7539438009262085, Prec: 0.8544198274612427, Rec 0.8669015765190125\n",
      "Epoch 691/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.109246328473091136\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.075087351931466, Valid loss: 0.3622295558452606, IoU: 0.7550427913665771, Prec: 0.8616971969604492, Rec 0.8610519170761108\n",
      "Epoch 692/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06810184568166733\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07480717947085698, Valid loss: 0.36793798208236694, IoU: 0.7530505061149597, Prec: 0.8586784601211548, Rec 0.8614922761917114\n",
      "Epoch 693/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06409507989883423\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07500492102570004, Valid loss: 0.353413850069046, IoU: 0.753692626953125, Prec: 0.8551023602485657, Rec 0.865979015827179\n",
      "Epoch 694/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06380487233400345\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07452615979644987, Valid loss: 0.3554002642631531, IoU: 0.7536114454269409, Prec: 0.8545257449150085, Rec 0.866431713104248\n",
      "Epoch 695/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06938625872135162\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07411710321903228, Valid loss: 0.3553868234157562, IoU: 0.7537693977355957, Prec: 0.8547415733337402, Rec 0.8663921356201172\n",
      "Epoch 696/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08230744302272797\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07403668993049198, Valid loss: 0.36162814497947693, IoU: 0.7535296678543091, Prec: 0.8569329977035522, Rec 0.8638618588447571\n",
      "Epoch 697/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06815829873085022\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07510217295752632, Valid loss: 0.36593109369277954, IoU: 0.753076434135437, Prec: 0.8599651455879211, Rec 0.8601664304733276\n",
      "Epoch 698/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08416713774204254\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07500450644228193, Valid loss: 0.35518383979797363, IoU: 0.754290759563446, Prec: 0.8562387228012085, Rec 0.8655140995979309\n",
      "Epoch 699/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06241173297166824\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07425220823950238, Valid loss: 0.3493078351020813, IoU: 0.7535744905471802, Prec: 0.8521597981452942, Rec 0.8687344789505005\n",
      "Epoch 700/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06650676578283313\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07430515239636103, Valid loss: 0.36556553840637207, IoU: 0.7540585994720459, Prec: 0.863357424736023, Rec 0.8580541610717773\n",
      "Epoch 701/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05555703118443489\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07384798501928648, Valid loss: 0.35940098762512207, IoU: 0.7536541223526001, Prec: 0.8576239347457886, Rec 0.8632557988166809\n",
      "Epoch 702/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09353941679000854\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07466724216938019, Valid loss: 0.3530004024505615, IoU: 0.7521119117736816, Prec: 0.8500738143920898, Rec 0.8689743876457214\n",
      "Epoch 703/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10416197776794434\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07423535287380219, Valid loss: 0.3706318736076355, IoU: 0.7542766332626343, Prec: 0.862812340259552, Rec 0.8589544296264648\n",
      "Epoch 704/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.073215365409851076\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07591908640331692, Valid loss: 0.3585256040096283, IoU: 0.7528476119041443, Prec: 0.8556631803512573, Rec 0.8642278909683228\n",
      "Epoch 705/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09735862165689468\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07473405682378345, Valid loss: 0.357451856136322, IoU: 0.7534900903701782, Prec: 0.854949951171875, Rec 0.8658825755119324\n",
      "Epoch 706/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10325244814157486\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07598850876092911, Valid loss: 0.36874455213546753, IoU: 0.7538677453994751, Prec: 0.8628208041191101, Rec 0.8584300875663757\n",
      "Epoch 707/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05803436040878296\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07372785210609437, Valid loss: 0.35186052322387695, IoU: 0.7512418627738953, Prec: 0.8487938642501831, Rec 0.8692094087600708\n",
      "Epoch 708/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06824274361133575\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0751948227485021, Valid loss: 0.3489742577075958, IoU: 0.7521284818649292, Prec: 0.8489672541618347, Rec 0.8701640963554382\n",
      "Epoch 709/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06767086684703827\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07426902221308815, Valid loss: 0.36959701776504517, IoU: 0.7541016340255737, Prec: 0.8638447523117065, Rec 0.8576732873916626\n",
      "Epoch 710/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09164859354496002\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07462815476788415, Valid loss: 0.3597765862941742, IoU: 0.7533161044120789, Prec: 0.8562858700752258, Rec 0.864180862903595\n",
      "Epoch 711/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08528966456651688\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07465688867701424, Valid loss: 0.36081504821777344, IoU: 0.7528117895126343, Prec: 0.8537958264350891, Rec 0.8661249876022339\n",
      "Epoch 712/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10800104588270187\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07534690548976263, Valid loss: 0.3722190260887146, IoU: 0.7535789608955383, Prec: 0.8586929440498352, Rec 0.8622244000434875\n",
      "Epoch 713/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09264617413282394\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07483931101030773, Valid loss: 0.36254772543907166, IoU: 0.7529562711715698, Prec: 0.8548218607902527, Rec 0.8652617335319519\n",
      "Epoch 714/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07992970198392868\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07392122397820154, Valid loss: 0.35588863492012024, IoU: 0.7532055974006653, Prec: 0.8522545695304871, Rec 0.868259608745575\n",
      "Epoch 715/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09352126717567444\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07435883614752027, Valid loss: 0.3717816472053528, IoU: 0.7533520460128784, Prec: 0.8602217435836792, Rec 0.8603668212890625\n",
      "Epoch 716/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06746423989534378\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07408414632081986, Valid loss: 0.3681267201900482, IoU: 0.7536500692367554, Prec: 0.8594433665275574, Rec 0.861519455909729\n",
      "Epoch 717/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09025116264820099\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07436309986644321, Valid loss: 0.36617836356163025, IoU: 0.7534142732620239, Prec: 0.8569448590278625, Rec 0.8636911511421204\n",
      "Epoch 718/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07666365802288055\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07337247166368696, Valid loss: 0.36095091700553894, IoU: 0.7538139820098877, Prec: 0.857365608215332, Rec 0.8638246655464172\n",
      "Epoch 719/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07767923176288605\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07472734881771935, Valid loss: 0.36202341318130493, IoU: 0.753684937953949, Prec: 0.8579904437065125, Rec 0.8630282282829285\n",
      "Epoch 720/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07046848535537728\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07455095648765564, Valid loss: 0.3669127821922302, IoU: 0.7543200850486755, Prec: 0.8607854843139648, Rec 0.8609901666641235\n",
      "Epoch 721/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07935383170843124\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07353356861405902, Valid loss: 0.3625839948654175, IoU: 0.7534324526786804, Prec: 0.8569988012313843, Rec 0.8636565208435059\n",
      "Epoch 722/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05483962595462799\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07439484629366133, Valid loss: 0.36801886558532715, IoU: 0.7524129152297974, Prec: 0.8581215739250183, Rec 0.8612152338027954\n",
      "Epoch 723/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06845495849847794\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.0733413890004158, Valid loss: 0.36135175824165344, IoU: 0.7510451078414917, Prec: 0.8498455882072449, Rec 0.8678687810897827\n",
      "Epoch 724/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07070956379175186\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07495508674118254, Valid loss: 0.371145635843277, IoU: 0.7535564303398132, Prec: 0.8606036305427551, Rec 0.8602010607719421\n",
      "Epoch 725/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09878708422183996\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07424419820308685, Valid loss: 0.36774593591690063, IoU: 0.7542109489440918, Prec: 0.8586214184761047, Rec 0.8630282282829285\n",
      "Epoch 726/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08797051012516022\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.0743039651049508, Valid loss: 0.37254607677459717, IoU: 0.753503680229187, Prec: 0.858801007270813, Rec 0.861920177936554\n",
      "Epoch 727/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.077675953507423405\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07371435927020178, Valid loss: 0.36659494042396545, IoU: 0.7527877688407898, Prec: 0.8556780815124512, Rec 0.864171028137207\n",
      "Epoch 728/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07404706627130508\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07451382395293978, Valid loss: 0.3652442991733551, IoU: 0.7533802390098572, Prec: 0.8569923639297485, Rec 0.8636342287063599\n",
      "Epoch 729/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07635054737329483\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07447058409452438, Valid loss: 0.37045401334762573, IoU: 0.7535251379013062, Prec: 0.8595398664474487, Rec 0.8612548112869263\n",
      "Epoch 730/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07721869647502899\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07442348500092824, Valid loss: 0.3538409471511841, IoU: 0.7525631785392761, Prec: 0.8503091931343079, Rec 0.8693602681159973\n",
      "Epoch 731/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.073138162493705754\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07567430668407016, Valid loss: 0.3477858603000641, IoU: 0.7542595863342285, Prec: 0.8539810180664062, Rec 0.8677946329116821\n",
      "Epoch 732/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07447445392608643\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0755063815249337, Valid loss: 0.3741064667701721, IoU: 0.7541455030441284, Prec: 0.8648102879524231, Rec 0.856654167175293\n",
      "Epoch 733/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05885779857635498\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07405107650491927, Valid loss: 0.3513597846031189, IoU: 0.753035843372345, Prec: 0.8514235615730286, Rec 0.8687518239021301\n",
      "Epoch 734/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11169254779815674\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07425564494397906, Valid loss: 0.36866074800491333, IoU: 0.7546945810317993, Prec: 0.8601372838020325, Rec 0.8621402978897095\n",
      "Epoch 735/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08869097381830215\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07462315443489287, Valid loss: 0.3793313801288605, IoU: 0.753749668598175, Prec: 0.8641780614852905, Rec 0.8568595051765442\n",
      "Epoch 736/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07550234347581863\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07383342898554272, Valid loss: 0.3538860082626343, IoU: 0.7532866597175598, Prec: 0.8520240783691406, Rec 0.8684772253036499\n",
      "Epoch 737/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07337438315153122\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07391184353166157, Valid loss: 0.36309313774108887, IoU: 0.7537724375724792, Prec: 0.8568822741508484, Rec 0.8642005920410156\n",
      "Epoch 738/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08713324368000034\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07517601781421238, Valid loss: 0.372042715549469, IoU: 0.7535638809204102, Prec: 0.8608675003051758, Rec 0.8599438667297363\n",
      "Epoch 739/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06974554806947708\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07422874718904496, Valid loss: 0.36204540729522705, IoU: 0.7524117827415466, Prec: 0.8538724184036255, Rec 0.8655017018318176\n",
      "Epoch 740/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12390420585870743\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0748975063363711, Valid loss: 0.37656983733177185, IoU: 0.7534099817276001, Prec: 0.862669825553894, Rec 0.858017086982727\n",
      "Epoch 741/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.060558278113603595\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07339825506011645, Valid loss: 0.3610704839229584, IoU: 0.7519058585166931, Prec: 0.8525126576423645, Rec 0.8661745190620422\n",
      "Epoch 742/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08078227192163467\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07464478959639867, Valid loss: 0.36175423860549927, IoU: 0.7527770400047302, Prec: 0.8544472455978394, Rec 0.8653755187988281\n",
      "Epoch 743/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08197702467441559\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07409360673692492, Valid loss: 0.36531955003738403, IoU: 0.7528313994407654, Prec: 0.8550351858139038, Rec 0.8648906946182251\n",
      "Epoch 744/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05578951537609118\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07337523632579379, Valid loss: 0.3633539080619812, IoU: 0.7534667253494263, Prec: 0.8581619262695312, Rec 0.8625385165214539\n",
      "Epoch 745/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07126817852258682\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07374620851543215, Valid loss: 0.35843971371650696, IoU: 0.7535403370857239, Prec: 0.856249988079071, Rec 0.864549458026886\n",
      "Epoch 746/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07958795875310898\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07364970495303472, Valid loss: 0.3562186360359192, IoU: 0.7528119087219238, Prec: 0.851226806640625, Rec 0.8687641024589539\n",
      "Epoch 747/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.082787498831748965\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0744494871960746, Valid loss: 0.36557549238204956, IoU: 0.7537331581115723, Prec: 0.8576706051826477, Rec 0.8633844256401062\n",
      "Epoch 748/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06564930081367493\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07345912257830302, Valid loss: 0.36125820875167847, IoU: 0.753484845161438, Prec: 0.8547905087471008, Rec 0.8659740686416626\n",
      "Epoch 749/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05633638799190521\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07466442551877764, Valid loss: 0.36451178789138794, IoU: 0.7530080080032349, Prec: 0.8570594787597656, Rec 0.8629961013793945\n",
      "Epoch 750/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08329731971025467\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07370119310087628, Valid loss: 0.3713051676750183, IoU: 0.7532451152801514, Prec: 0.8594284057617188, Rec 0.8609159588813782\n",
      "Epoch 751/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08920938521623611\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07350607961416245, Valid loss: 0.3647131025791168, IoU: 0.7536165118217468, Prec: 0.8578556180000305, Rec 0.8629565238952637\n",
      "Epoch 752/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08913049846887589\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07375075370073318, Valid loss: 0.36520278453826904, IoU: 0.7525317668914795, Prec: 0.8537979125976562, Rec 0.8656673431396484\n",
      "Epoch 753/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08496948331594467\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0734149166279369, Valid loss: 0.37025588750839233, IoU: 0.753225564956665, Prec: 0.8585006594657898, Rec 0.861890435218811\n",
      "Epoch 754/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08931570500135422\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07387899143828286, Valid loss: 0.3696814179420471, IoU: 0.7533754110336304, Prec: 0.8587719202041626, Rec 0.8617989420890808\n",
      "Epoch 755/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09666062891483307\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07278204593393538, Valid loss: 0.3782142698764801, IoU: 0.7530258893966675, Prec: 0.8612383008003235, Rec 0.8588679432868958\n",
      "Epoch 756/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07323900610208511\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07320843620432747, Valid loss: 0.3635987341403961, IoU: 0.7517708539962769, Prec: 0.8531001806259155, Rec 0.8654125928878784\n",
      "Epoch 757/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.14594161510467535\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07457452317078908, Valid loss: 0.37275177240371704, IoU: 0.7542317509651184, Prec: 0.8612616658210754, Rec 0.8604657053947449\n",
      "Epoch 758/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.055885832756757736\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07391019951966074, Valid loss: 0.3723415732383728, IoU: 0.7514755129814148, Prec: 0.8561397790908813, Rec 0.8619893789291382\n",
      "Epoch 759/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07795023173093796\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07345747864908642, Valid loss: 0.3618845045566559, IoU: 0.7509081959724426, Prec: 0.8502323031425476, Rec 0.8672429919242859\n",
      "Epoch 760/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12429220229387283\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07633854001760483, Valid loss: 0.3554055690765381, IoU: 0.752048134803772, Prec: 0.8496365547180176, Rec 0.869355320930481\n",
      "Epoch 761/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08077486604452133\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07422190623150932, Valid loss: 0.36974817514419556, IoU: 0.7530139684677124, Prec: 0.8595802187919617, Rec 0.8605052828788757\n",
      "Epoch 762/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09020727872848511\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.0739971333079868, Valid loss: 0.3634442090988159, IoU: 0.7536013722419739, Prec: 0.8576846122741699, Rec 0.8631569147109985\n",
      "Epoch 763/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05121329799294472\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07359804486234983, Valid loss: 0.3765869140625, IoU: 0.7528117895126343, Prec: 0.864287257194519, Rec 0.855573296546936\n",
      "Epoch 764/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08467031270265579\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07331251386139127, Valid loss: 0.3618953227996826, IoU: 0.7531229257583618, Prec: 0.8548282384872437, Rec 0.8653755187988281\n",
      "Epoch 765/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06575132906436924\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.075394007563591, Valid loss: 0.37477412819862366, IoU: 0.7529781460762024, Prec: 0.8609455227851868, Rec 0.8590731620788574\n",
      "Epoch 766/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06701400876045227\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07346075508329604, Valid loss: 0.3693608045578003, IoU: 0.7514522075653076, Prec: 0.8535372614860535, Rec 0.8645569086074829\n",
      "Epoch 767/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08486527949571615\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07272044171889623, Valid loss: 0.3687373101711273, IoU: 0.7513274550437927, Prec: 0.8534502983093262, Rec 0.8645271062850952\n",
      "Epoch 768/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06831386685371399\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07223221328523424, Valid loss: 0.37190985679626465, IoU: 0.7523605227470398, Prec: 0.8571654558181763, Rec 0.8620487451553345\n",
      "Epoch 769/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08523302525281906\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07374761485391193, Valid loss: 0.3680747151374817, IoU: 0.7530807256698608, Prec: 0.8559263944625854, Rec 0.8642154932022095\n",
      "Epoch 770/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07915290445089342\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07327797032064862, Valid loss: 0.36980611085891724, IoU: 0.7532354593276978, Prec: 0.8572293519973755, Rec 0.8631420135498047\n",
      "Epoch 771/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09225649386644363\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07263176722659005, Valid loss: 0.3739151358604431, IoU: 0.7530835866928101, Prec: 0.8589926958084106, Rec 0.8612003326416016\n",
      "Epoch 772/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07772017270326614\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07317011174228456, Valid loss: 0.3718002140522003, IoU: 0.7532435655593872, Prec: 0.8574369549751282, Rec 0.8629169464111328\n",
      "Epoch 773/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10319284349679947\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0730972311562962, Valid loss: 0.36700356006622314, IoU: 0.7527714967727661, Prec: 0.8546711802482605, Rec 0.8651108741760254\n",
      "Epoch 774/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10569232702255249\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.073330424229304, Valid loss: 0.3758610785007477, IoU: 0.7532104253768921, Prec: 0.8601943254470825, Rec 0.8600897789001465\n",
      "Epoch 775/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07772408425807953\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07371197044849395, Valid loss: 0.37754014134407043, IoU: 0.7515128254890442, Prec: 0.8577448725700378, Rec 0.8603816032409668\n",
      "Epoch 776/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07392411679029465\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07252753261062835, Valid loss: 0.36240190267562866, IoU: 0.753049373626709, Prec: 0.8559134602546692, Rec 0.8642822504043579\n",
      "Epoch 777/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10071514546871185\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0733514063888126, Valid loss: 0.37038320302963257, IoU: 0.7521254420280457, Prec: 0.8561779260635376, Rec 0.8628129959106445\n",
      "Epoch 778/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08615197986364365\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07388797783189349, Valid loss: 0.37664705514907837, IoU: 0.7516488432884216, Prec: 0.8581578135490417, Rec 0.8601541519165039\n",
      "Epoch 779/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08994001150131226\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07295254601372612, Valid loss: 0.37070995569229126, IoU: 0.7511473894119263, Prec: 0.8528153300285339, Rec 0.8649154901504517\n",
      "Epoch 780/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09954430907964706\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07400039815240436, Valid loss: 0.3713638186454773, IoU: 0.7529908418655396, Prec: 0.8569064140319824, Rec 0.8631617426872253\n",
      "Epoch 781/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06103360280394554\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0722144695619742, Valid loss: 0.36920565366744995, IoU: 0.7519642114639282, Prec: 0.8568809628486633, Rec 0.8617914915084839\n",
      "Epoch 782/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07495845854282379\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07414691150188446, Valid loss: 0.3579382300376892, IoU: 0.752241313457489, Prec: 0.8506458401679993, Rec 0.8685439825057983\n",
      "Epoch 783/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08619755506515503\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07310775849554274, Valid loss: 0.37027686834335327, IoU: 0.7530747652053833, Prec: 0.8581506609916687, Rec 0.862038791179657\n",
      "Epoch 784/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06468448042869568\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07348108755217658, Valid loss: 0.3666703999042511, IoU: 0.7522357702255249, Prec: 0.8550781011581421, Rec 0.8640176653862\n",
      "Epoch 785/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06692183017730713\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07260245680809022, Valid loss: 0.36427897214889526, IoU: 0.7530859708786011, Prec: 0.8566974401473999, Rec 0.8635031580924988\n",
      "Epoch 786/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.055828116834163666\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0737129279308849, Valid loss: 0.36699503660202026, IoU: 0.7528519630432129, Prec: 0.8574857711791992, Rec 0.8623504638671875\n",
      "Epoch 787/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07008647173643112\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07253836376799477, Valid loss: 0.3729732930660248, IoU: 0.7527014017105103, Prec: 0.8585653305053711, Rec 0.8610469698905945\n",
      "Epoch 788/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08639572560787201\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0732913292116589, Valid loss: 0.37188252806663513, IoU: 0.7521715760231018, Prec: 0.8564052581787109, Rec 0.8625162243843079\n",
      "Epoch 789/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07068984210491187\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07304134964942932, Valid loss: 0.3721383213996887, IoU: 0.7525779008865356, Prec: 0.8582483530044556, Rec 0.8612548112869263\n",
      "Epoch 790/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07403613626956945\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07254990041255951, Valid loss: 0.36738231778144836, IoU: 0.7528783082962036, Prec: 0.855694591999054, Rec 0.864148736000061\n",
      "Epoch 791/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08413498848676682\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07349398252036836, Valid loss: 0.37576836347579956, IoU: 0.7530330419540405, Prec: 0.8593630790710449, Rec 0.8606933355331421\n",
      "Epoch 792/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08349508792161942\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07366105996900135, Valid loss: 0.3719189763069153, IoU: 0.7531693577766418, Prec: 0.858924388885498, Rec 0.8613511919975281\n",
      "Epoch 793/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07276304066181183\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07266932229201, Valid loss: 0.371258020401001, IoU: 0.752779483795166, Prec: 0.8571216464042664, Rec 0.8626497983932495\n",
      "Epoch 794/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06456432491540909\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07271291961272558, Valid loss: 0.3620149493217468, IoU: 0.7525988221168518, Prec: 0.8531317710876465, Rec 0.8664984703063965\n",
      "Epoch 795/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09518715739250183\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07334263258510165, Valid loss: 0.37648141384124756, IoU: 0.7542286515235901, Prec: 0.8616393208503723, Rec 0.8601096272468567\n",
      "Epoch 796/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11497002094984055\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0743544371591674, Valid loss: 0.37032538652420044, IoU: 0.7516101002693176, Prec: 0.853015124797821, Rec 0.8653780221939087\n",
      "Epoch 797/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.070509284734725956\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07349783480167389, Valid loss: 0.36320728063583374, IoU: 0.7518240809440613, Prec: 0.8551343083381653, Rec 0.8635228872299194\n",
      "Epoch 798/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09441836923360825\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07369122488631143, Valid loss: 0.37567782402038574, IoU: 0.7534015774726868, Prec: 0.8613077402114868, Rec 0.8593576550483704\n",
      "Epoch 799/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07982027530670166\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07229758037461174, Valid loss: 0.3776971399784088, IoU: 0.7529284358024597, Prec: 0.8613554835319519, Rec 0.8586403727531433\n",
      "Epoch 800/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.089614033699035645\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07438614004188114, Valid loss: 0.3727812170982361, IoU: 0.7518736124038696, Prec: 0.8565279245376587, Rec 0.8620611429214478\n",
      "Epoch 801/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05886307731270791\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07251440791620148, Valid loss: 0.3577457070350647, IoU: 0.7515641450881958, Prec: 0.8497058153152466, Rec 0.8687122464179993\n",
      "Epoch 802/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10897398740053177\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07380689829587936, Valid loss: 0.3810226321220398, IoU: 0.7537785768508911, Prec: 0.8646198511123657, Rec 0.8565775156021118\n",
      "Epoch 803/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08646558225154877\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07257540656460656, Valid loss: 0.3794814944267273, IoU: 0.7528611421585083, Prec: 0.8601675033569336, Rec 0.8597953915596008\n",
      "Epoch 804/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07177011668682098\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07400954167048136, Valid loss: 0.3695090413093567, IoU: 0.7522834539413452, Prec: 0.8561169505119324, Rec 0.8631073832511902\n",
      "Epoch 805/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.076484791934490205\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07270460410250558, Valid loss: 0.36965635418891907, IoU: 0.7519448399543762, Prec: 0.8540629148483276, Rec 0.8647052049636841\n",
      "Epoch 806/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09813755750656128\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07336703340212504, Valid loss: 0.369975745677948, IoU: 0.7527227401733398, Prec: 0.8568054437637329, Rec 0.8629441261291504\n",
      "Epoch 807/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08315262198448181\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07306781808535258, Valid loss: 0.37104088068008423, IoU: 0.7527884244918823, Prec: 0.8586103320121765, Rec 0.8612201809883118\n",
      "Epoch 808/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06625086069107056\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07313630051083035, Valid loss: 0.37532100081443787, IoU: 0.7517769932746887, Prec: 0.8563629984855652, Rec 0.8621253967285156\n",
      "Epoch 809/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08833402395248413\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.07273916270997789, Valid loss: 0.37429895997047424, IoU: 0.7534213662147522, Prec: 0.8617365956306458, Rec 0.8589123487472534\n",
      "Epoch 810/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12925471365451813\n",
      "Epoch finished in 0.5 seconds\n",
      "Train loss: 0.0725925776693556, Valid loss: 0.3757438063621521, IoU: 0.7533428072929382, Prec: 0.8598616719245911, Rec 0.8606710433959961\n",
      "Epoch 811/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.061201758682727814\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07244996047682233, Valid loss: 0.36973223090171814, IoU: 0.7516576051712036, Prec: 0.8549799919128418, Rec 0.8633893728256226\n",
      "Epoch 812/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07332824170589447\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0733488357729382, Valid loss: 0.3643071949481964, IoU: 0.751257061958313, Prec: 0.8511223793029785, Rec 0.8668521642684937\n",
      "Epoch 813/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09937221556901932\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0719940776626269, Valid loss: 0.3824315667152405, IoU: 0.7538654804229736, Prec: 0.8639275431632996, Rec 0.8573616147041321\n",
      "Epoch 814/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10682179033756256\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07318415873580508, Valid loss: 0.3827248215675354, IoU: 0.7525854110717773, Prec: 0.8605270385742188, Rec 0.8590633273124695\n",
      "Epoch 815/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11551248282194138\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0748645211259524, Valid loss: 0.3885710835456848, IoU: 0.7530522346496582, Prec: 0.8649166822433472, Rec 0.8553803563117981\n",
      "Epoch 816/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10750716924667358\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0722954293092092, Valid loss: 0.3771001398563385, IoU: 0.7511065602302551, Prec: 0.8537524938583374, Rec 0.8639730215072632\n",
      "Epoch 817/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05569853633642197\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07322685172160466, Valid loss: 0.37143680453300476, IoU: 0.7514610290527344, Prec: 0.8548133969306946, Rec 0.8633571863174438\n",
      "Epoch 818/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07843139022588733\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07339570240841972, Valid loss: 0.37457171082496643, IoU: 0.751488983631134, Prec: 0.8566510081291199, Rec 0.861519455909729\n",
      "Epoch 819/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.076769992709159856\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07206405633025699, Valid loss: 0.3722551465034485, IoU: 0.7520579099655151, Prec: 0.8575399518013, Rec 0.8613364100456238\n",
      "Epoch 820/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.051915545016527176\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07223675027489662, Valid loss: 0.3656368851661682, IoU: 0.751900315284729, Prec: 0.8536337614059448, Rec 0.8650391697883606\n",
      "Epoch 821/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08375553041696548\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07265529980262121, Valid loss: 0.3673461079597473, IoU: 0.7525981664657593, Prec: 0.8549235463142395, Rec 0.8647077679634094\n",
      "Epoch 822/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05924875661730766\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07268473530809084, Valid loss: 0.3667568266391754, IoU: 0.7525231838226318, Prec: 0.8566015362739563, Rec 0.8629094958305359\n",
      "Epoch 823/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06960864365100862\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07333822051684062, Valid loss: 0.3724175691604614, IoU: 0.7519406676292419, Prec: 0.856970489025116, Rec 0.8617420196533203\n",
      "Epoch 824/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06733860820531845\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07206211636463801, Valid loss: 0.3718843162059784, IoU: 0.7517949342727661, Prec: 0.8571469187736511, Rec 0.8613685369491577\n",
      "Epoch 825/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08204775303602219\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07334717628028657, Valid loss: 0.3719823658466339, IoU: 0.7510079145431519, Prec: 0.8528779745101929, Rec 0.8646879196166992\n",
      "Epoch 826/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07711365818977356\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07262654370731778, Valid loss: 0.3723483979701996, IoU: 0.752473771572113, Prec: 0.8575348854064941, Rec 0.8619028329849243\n",
      "Epoch 827/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.071812890470027926\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0722781014111307, Valid loss: 0.3621565103530884, IoU: 0.7522566318511963, Prec: 0.8521431684494019, Rec 0.8670352101325989\n",
      "Epoch 828/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09737319499254227\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07333814087841246, Valid loss: 0.37032049894332886, IoU: 0.7538617849349976, Prec: 0.8613583445549011, Rec 0.8598052859306335\n",
      "Epoch 829/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10171199589967728\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07243816802899043, Valid loss: 0.3638003170490265, IoU: 0.7520326972007751, Prec: 0.8515852689743042, Rec 0.8673221468925476\n",
      "Epoch 830/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06948976218700409\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07183825605445437, Valid loss: 0.3693474233150482, IoU: 0.7520860433578491, Prec: 0.8564122915267944, Rec 0.8624964952468872\n",
      "Epoch 831/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06809953600168228\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07320685105191337, Valid loss: 0.3659399151802063, IoU: 0.7528632879257202, Prec: 0.8565726280212402, Rec 0.8633249998092651\n",
      "Epoch 832/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11371383070945748\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07233760555585225, Valid loss: 0.3700186610221863, IoU: 0.7521129846572876, Prec: 0.8551963567733765, Rec 0.8637504577636719\n",
      "Epoch 833/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10850675404071808\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07199067009819879, Valid loss: 0.37737295031547546, IoU: 0.7533048987388611, Prec: 0.8606569170951843, Rec 0.8598325848579407\n",
      "Epoch 834/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07016008347272873\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07229543642865287, Valid loss: 0.37070804834365845, IoU: 0.752623438835144, Prec: 0.8569976687431335, Rec 0.862592875957489\n",
      "Epoch 835/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06704242527484894\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07338342732853359, Valid loss: 0.37131747603416443, IoU: 0.7515426874160767, Prec: 0.855196475982666, Rec 0.8630282282829285\n",
      "Epoch 836/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07489653676748276\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07245257182253731, Valid loss: 0.37019532918930054, IoU: 0.7522802352905273, Prec: 0.8556652069091797, Rec 0.8634957075119019\n",
      "Epoch 837/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06379059702157974\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07230036341481738, Valid loss: 0.36627084016799927, IoU: 0.7527554631233215, Prec: 0.8546048402786255, Rec 0.8652098774909973\n",
      "Epoch 838/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08868625015020376\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07192789167165756, Valid loss: 0.3724467158317566, IoU: 0.7526181936264038, Prec: 0.8572686910629272, Rec 0.8623603582382202\n",
      "Epoch 839/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06108708307147026\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07175462999277644, Valid loss: 0.37353765964508057, IoU: 0.7519029378890991, Prec: 0.8558551073074341, Rec 0.8628575205802917\n",
      "Epoch 840/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06948285549879074\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07199098318815231, Valid loss: 0.3824959397315979, IoU: 0.7519176602363586, Prec: 0.8594862222671509, Rec 0.8592042922973633\n",
      "Epoch 841/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08890033513307571\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07280497799317041, Valid loss: 0.385383665561676, IoU: 0.7522938251495361, Prec: 0.8602744936943054, Rec 0.8589199185371399\n",
      "Epoch 842/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08754973113536835\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07256876528263093, Valid loss: 0.3721316158771515, IoU: 0.7511144876480103, Prec: 0.8513162732124329, Rec 0.8664044141769409\n",
      "Epoch 843/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07205880433320999\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07142729378408856, Valid loss: 0.3692760765552521, IoU: 0.7523559927940369, Prec: 0.855145275592804, Rec 0.8641066551208496\n",
      "Epoch 844/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.055926818400621414\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07264674877127011, Valid loss: 0.36652740836143494, IoU: 0.7522050738334656, Prec: 0.8544851541519165, Rec 0.8645790815353394\n",
      "Epoch 845/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07948616892099386\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0722412551442782, Valid loss: 0.37306615710258484, IoU: 0.7528783082962036, Prec: 0.8578044772148132, Rec 0.8620932698249817\n",
      "Epoch 846/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08696180582046509\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07209984295898014, Valid loss: 0.377500981092453, IoU: 0.7526337504386902, Prec: 0.8590236902236938, Rec 0.8605548143386841\n",
      "Epoch 847/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07733849436044693\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07252346260680093, Valid loss: 0.37582772970199585, IoU: 0.7524961829185486, Prec: 0.8566116094589233, Rec 0.862808108329773\n",
      "Epoch 848/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07112209498882294\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07207803030808767, Valid loss: 0.3744870126247406, IoU: 0.7523294687271118, Prec: 0.8564698100090027, Rec 0.8627660870552063\n",
      "Epoch 849/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06865233927965164\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07292778276734882, Valid loss: 0.38102465867996216, IoU: 0.752223014831543, Prec: 0.8605393171310425, Rec 0.8585265278816223\n",
      "Epoch 850/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.094830863177776344\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07268159571621154, Valid loss: 0.3801864981651306, IoU: 0.7520313262939453, Prec: 0.8582643270492554, Rec 0.8605077862739563\n",
      "Epoch 851/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07049874961376197\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07242828276422289, Valid loss: 0.37334170937538147, IoU: 0.7523334622383118, Prec: 0.858040988445282, Rec 0.8611335754394531\n",
      "Epoch 852/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08362263441085815\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07131046420998044, Valid loss: 0.36966511607170105, IoU: 0.7511562705039978, Prec: 0.8507735133171082, Rec 0.8670376539230347\n",
      "Epoch 853/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06721680611371994\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07210880368947983, Valid loss: 0.377063512802124, IoU: 0.7528852224349976, Prec: 0.8592877388000488, Rec 0.8606487512588501\n",
      "Epoch 854/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06335453689098358\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07310618029700386, Valid loss: 0.3740408420562744, IoU: 0.7528167963027954, Prec: 0.8582988977432251, Rec 0.8615244030952454\n",
      "Epoch 855/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06140291690826416\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07241287430127462, Valid loss: 0.3856533467769623, IoU: 0.7525700330734253, Prec: 0.862013041973114, Rec 0.8574728965759277\n",
      "Epoch 856/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06942109018564224\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07199084013700485, Valid loss: 0.3722766935825348, IoU: 0.7515021562576294, Prec: 0.852784276008606, Rec 0.8653780221939087\n",
      "Epoch 857/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09590225666761398\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07367792146073447, Valid loss: 0.37329158186912537, IoU: 0.7519901990890503, Prec: 0.8550497889518738, Rec 0.8637727499008179\n",
      "Epoch 858/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08507898449897766\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07162723375691307, Valid loss: 0.3730406165122986, IoU: 0.7510161399841309, Prec: 0.8533717393875122, Rec 0.8642129898071289\n",
      "Epoch 859/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11417286098003387\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07260941995514764, Valid loss: 0.393596351146698, IoU: 0.7516751885414124, Prec: 0.8650531768798828, Rec 0.8534189462661743\n",
      "Epoch 860/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07759086787700653\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07244212329387664, Valid loss: 0.3836679458618164, IoU: 0.751197338104248, Prec: 0.8578962087631226, Rec 0.859839916229248\n",
      "Epoch 861/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.04788947477936745\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07161187670297092, Valid loss: 0.37049680948257446, IoU: 0.7508724331855774, Prec: 0.853759765625, Rec 0.8635921478271484\n",
      "Epoch 862/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06833720207214355\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07273573478062947, Valid loss: 0.37306398153305054, IoU: 0.7508082389831543, Prec: 0.8526464700698853, Rec 0.8646730184555054\n",
      "Epoch 863/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10365606844425201\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0715552353196674, Valid loss: 0.38205820322036743, IoU: 0.7517118453979492, Prec: 0.8577831983566284, Rec 0.8606586456298828\n",
      "Epoch 864/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06929145753383636\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07288379569848379, Valid loss: 0.3782067894935608, IoU: 0.7515825033187866, Prec: 0.8571761846542358, Rec 0.8610865473747253\n",
      "Epoch 865/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08651199936866762\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07227185832129585, Valid loss: 0.3742331862449646, IoU: 0.7520047426223755, Prec: 0.8559520840644836, Rec 0.8628427386283875\n",
      "Epoch 866/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07468831539154053\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07248130871189964, Valid loss: 0.3764020800590515, IoU: 0.7522545456886292, Prec: 0.857857346534729, Rec 0.8612275123596191\n",
      "Epoch 867/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10130279511213303\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07106036129924986, Valid loss: 0.3821287155151367, IoU: 0.7522398829460144, Prec: 0.8590059280395508, Rec 0.8600972294807434\n",
      "Epoch 868/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08668604493141174\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07160203324423896, Valid loss: 0.3794766664505005, IoU: 0.7521198987960815, Prec: 0.8588242530822754, Rec 0.8601268529891968\n",
      "Epoch 869/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08322056382894516\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07168495770957735, Valid loss: 0.3799521327018738, IoU: 0.7515729069709778, Prec: 0.856099009513855, Rec 0.8621476888656616\n",
      "Epoch 870/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07289788126945496\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07284333043628269, Valid loss: 0.38256245851516724, IoU: 0.7519396543502808, Prec: 0.8586710095405579, Rec 0.8600502014160156\n",
      "Epoch 871/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05380217358469963\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07171283918950293, Valid loss: 0.3753540813922882, IoU: 0.7513817548751831, Prec: 0.8561171293258667, Rec 0.8618632555007935\n",
      "Epoch 872/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.049181193113327026\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07103380560874939, Valid loss: 0.36845719814300537, IoU: 0.7515770792961121, Prec: 0.8533668518066406, Rec 0.8649154901504517\n",
      "Epoch 873/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10177246481180191\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0722245423330201, Valid loss: 0.38241419196128845, IoU: 0.7518360614776611, Prec: 0.8573077321052551, Rec 0.8612794876098633\n",
      "Epoch 874/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08689466118812561\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07297965652412838, Valid loss: 0.3775703012943268, IoU: 0.7527639269828796, Prec: 0.8596345782279968, Rec 0.8600972294807434\n",
      "Epoch 875/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07636670023202896\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07119563039806154, Valid loss: 0.37416037917137146, IoU: 0.7511663436889648, Prec: 0.8540564775466919, Rec 0.8636293411254883\n",
      "Epoch 876/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06866935640573502\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07138631459739474, Valid loss: 0.37290269136428833, IoU: 0.7512573003768921, Prec: 0.8531370162963867, Rec 0.8646755218505859\n",
      "Epoch 877/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10788759589195251\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07235066526465946, Valid loss: 0.37887224555015564, IoU: 0.7517472505569458, Prec: 0.8548911809921265, Rec 0.8635897636413574\n",
      "Epoch 878/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.13622193038463593\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07274979684087965, Valid loss: 0.38989001512527466, IoU: 0.7534328699111938, Prec: 0.8648484945297241, Rec 0.8558428883552551\n",
      "Epoch 879/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08099152892827988\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07177993307511012, Valid loss: 0.38160598278045654, IoU: 0.7520327568054199, Prec: 0.8584607839584351, Rec 0.8603569269180298\n",
      "Epoch 880/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08434085547924042\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07140939732392629, Valid loss: 0.3760475516319275, IoU: 0.7519052624702454, Prec: 0.8547435998916626, Rec 0.8639062643051147\n",
      "Epoch 881/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09955384582281113\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07116550157467524, Valid loss: 0.37612760066986084, IoU: 0.7526293992996216, Prec: 0.8569547533988953, Rec 0.8626003265380859\n",
      "Epoch 882/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08007830381393433\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0722374227311876, Valid loss: 0.3779938519001007, IoU: 0.7513296008110046, Prec: 0.8565484285354614, Rec 0.8613462448120117\n",
      "Epoch 883/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09346193820238113\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07206680095858044, Valid loss: 0.37427017092704773, IoU: 0.7519689798355103, Prec: 0.8550254702568054, Rec 0.8637059926986694\n",
      "Epoch 884/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08668454736471176\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07283034837908214, Valid loss: 0.38318607211112976, IoU: 0.7520889043807983, Prec: 0.8600846529006958, Rec 0.8587664365768433\n",
      "Epoch 885/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09041904658079147\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07179716676473617, Valid loss: 0.3789612650871277, IoU: 0.7504287362098694, Prec: 0.8532150387763977, Rec 0.8635179400444031\n",
      "Epoch 886/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08780253678560257\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0718431841995981, Valid loss: 0.3754875659942627, IoU: 0.7514820098876953, Prec: 0.8542978167533875, Rec 0.8638296127319336\n",
      "Epoch 887/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06117052212357521\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0723157088789675, Valid loss: 0.37707507610321045, IoU: 0.7520824670791626, Prec: 0.8567439317703247, Rec 0.8621081113815308\n",
      "Epoch 888/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08413675427436829\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07321314579910702, Valid loss: 0.3883588910102844, IoU: 0.7509561777114868, Prec: 0.8597437739372253, Rec 0.8576287031173706\n",
      "Epoch 889/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07614734023809433\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07186980562077629, Valid loss: 0.37926873564720154, IoU: 0.7509065270423889, Prec: 0.8541728854179382, Rec 0.8631914854049683\n",
      "Epoch 890/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.04853874444961548\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07225142584906684, Valid loss: 0.3709661364555359, IoU: 0.751268744468689, Prec: 0.8523041605949402, Rec 0.8655808568000793\n",
      "Epoch 891/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06429922580718994\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07161465916368696, Valid loss: 0.37318307161331177, IoU: 0.7525337338447571, Prec: 0.8576383590698242, Rec 0.8618112802505493\n",
      "Epoch 892/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07127790898084645\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07221853882074356, Valid loss: 0.3779752850532532, IoU: 0.7528935670852661, Prec: 0.8593391180038452, Rec 0.8605622053146362\n",
      "Epoch 893/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.054335758090019226\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07228792541556889, Valid loss: 0.37474334239959717, IoU: 0.7514825463294983, Prec: 0.85406494140625, Rec 0.8640127182006836\n",
      "Epoch 894/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05147862806916237\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07400614329510265, Valid loss: 0.38250142335891724, IoU: 0.7515149712562561, Prec: 0.8605936169624329, Rec 0.8575124740600586\n",
      "Epoch 895/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08042760938405992\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07170489778121313, Valid loss: 0.37046924233436584, IoU: 0.750979483127594, Prec: 0.8526996374130249, Rec 0.864791750907898\n",
      "Epoch 896/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07703513652086258\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07178261760208342, Valid loss: 0.37345391511917114, IoU: 0.7510672807693481, Prec: 0.8534124493598938, Rec 0.8641858100891113\n",
      "Epoch 897/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.050174564123153687\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07139627668592664, Valid loss: 0.3715430796146393, IoU: 0.7521334290504456, Prec: 0.8550456166267395, Rec 0.8639162182807922\n",
      "Epoch 898/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.058713462203741074\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0719617918961578, Valid loss: 0.3668907582759857, IoU: 0.7522416114807129, Prec: 0.8530845642089844, Rec 0.8660507202148438\n",
      "Epoch 899/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08953972160816193\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07100294066800011, Valid loss: 0.3797793388366699, IoU: 0.7515084147453308, Prec: 0.8564227819442749, Rec 0.8616827130317688\n",
      "Epoch 900/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07806240022182465\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0718607270055347, Valid loss: 0.37515050172805786, IoU: 0.7517811059951782, Prec: 0.8552151918411255, Rec 0.8632557988166809\n",
      "Epoch 901/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07343515008687973\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07220097796784507, Valid loss: 0.3767651617527008, IoU: 0.7515621185302734, Prec: 0.8564344644546509, Rec 0.8617445230484009\n",
      "Epoch 902/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10014418512582779\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07261074069473479, Valid loss: 0.37762874364852905, IoU: 0.751106321811676, Prec: 0.8543569445610046, Rec 0.863223671913147\n",
      "Epoch 903/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06279797852039337\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0716215216451221, Valid loss: 0.37599384784698486, IoU: 0.7519327998161316, Prec: 0.8569032549858093, Rec 0.861737072467804\n",
      "Epoch 904/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06913529336452484\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07085585925314161, Valid loss: 0.3762611746788025, IoU: 0.7522110939025879, Prec: 0.858594536781311, Rec 0.8604212999343872\n",
      "Epoch 905/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08665769547224045\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07152062472369936, Valid loss: 0.37210917472839355, IoU: 0.7509067058563232, Prec: 0.851803183555603, Rec 0.8655907511711121\n",
      "Epoch 906/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07303766906261444\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07128510740068224, Valid loss: 0.3797851800918579, IoU: 0.7526999115943909, Prec: 0.8602085113525391, Rec 0.8594566583633423\n",
      "Epoch 907/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06514711678028107\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07164654235045115, Valid loss: 0.37674543261528015, IoU: 0.7513529658317566, Prec: 0.8546336889266968, Rec 0.8632879257202148\n",
      "Epoch 908/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06905020773410797\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07154492537180583, Valid loss: 0.37544745206832886, IoU: 0.7523071765899658, Prec: 0.8574390411376953, Rec 0.8616876602172852\n",
      "Epoch 909/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08677754551172256\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07127477741903729, Valid loss: 0.37671586871147156, IoU: 0.7520396113395691, Prec: 0.8555582165718079, Rec 0.8632360696792603\n",
      "Epoch 910/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.12146867811679848\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0725080904033449, Valid loss: 0.388668030500412, IoU: 0.7529414892196655, Prec: 0.861711323261261, Rec 0.8582817316055298\n",
      "Epoch 911/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07206664234399796\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07183878901931974, Valid loss: 0.38815435767173767, IoU: 0.7526974678039551, Prec: 0.861954391002655, Rec 0.8577054142951965\n",
      "Epoch 912/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10015569627285004\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07156731552547879, Valid loss: 0.3796989321708679, IoU: 0.7515996694564819, Prec: 0.8547338247299194, Rec 0.8635426759719849\n",
      "Epoch 913/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06473133713006973\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0719423159956932, Valid loss: 0.3769412338733673, IoU: 0.7511743307113647, Prec: 0.8539897799491882, Rec 0.8637282252311707\n",
      "Epoch 914/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08770581334829333\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07169094400273429, Valid loss: 0.3768283724784851, IoU: 0.7521743774414062, Prec: 0.8575761914253235, Rec 0.8614230155944824\n",
      "Epoch 915/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.04976716265082359\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07113276281290584, Valid loss: 0.37886539101600647, IoU: 0.7515131235122681, Prec: 0.8591839671134949, Rec 0.8589123487472534\n",
      "Epoch 916/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05933057889342308\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07154849494496981, Valid loss: 0.3754580616950989, IoU: 0.750481128692627, Prec: 0.8536591529846191, Rec 0.8631024360656738\n",
      "Epoch 917/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06214612349867821\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07102843580974473, Valid loss: 0.37598034739494324, IoU: 0.7501271963119507, Prec: 0.8518964648246765, Rec 0.8644653558731079\n",
      "Epoch 918/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09355354309082031\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0713496532705095, Valid loss: 0.3814160227775574, IoU: 0.751038134098053, Prec: 0.8557850122451782, Rec 0.8617371320724487\n",
      "Epoch 919/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.11594402790069587\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07216854393482208, Valid loss: 0.38888636231422424, IoU: 0.7521507740020752, Prec: 0.8614394068717957, Rec 0.8575446009635925\n",
      "Epoch 920/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07846112549304962\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07067766421371036, Valid loss: 0.3823699653148651, IoU: 0.7513800263404846, Prec: 0.8580220341682434, Rec 0.8599241375923157\n",
      "Epoch 921/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08434135466814041\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07149424105882644, Valid loss: 0.3800351023674011, IoU: 0.7506047487258911, Prec: 0.8544953465461731, Rec 0.8624569177627563\n",
      "Epoch 922/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08676908910274506\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07132654388745625, Valid loss: 0.38026127219200134, IoU: 0.751335084438324, Prec: 0.8558198809623718, Rec 0.8620611429214478\n",
      "Epoch 923/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06429971754550934\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07112580902046628, Valid loss: 0.3768598437309265, IoU: 0.7508578896522522, Prec: 0.8537508845329285, Rec 0.8635426759719849\n",
      "Epoch 924/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08723480254411697\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07159966313176686, Valid loss: 0.3884951174259186, IoU: 0.7521123886108398, Prec: 0.8615188598632812, Rec 0.8574011921882629\n",
      "Epoch 925/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09488988667726517\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07215309490760168, Valid loss: 0.37866875529289246, IoU: 0.7517286539077759, Prec: 0.8566509485244751, Rec 0.8617569208145142\n",
      "Epoch 926/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08979112654924393\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07173394345574909, Valid loss: 0.3799469470977783, IoU: 0.7514268755912781, Prec: 0.854806125164032, Rec 0.8632286190986633\n",
      "Epoch 927/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08076886832714081\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07157107459174263, Valid loss: 0.38437747955322266, IoU: 0.7515527606010437, Prec: 0.8575993776321411, Rec 0.8605819940567017\n",
      "Epoch 928/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08058849722146988\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07243697593609492, Valid loss: 0.3872912526130676, IoU: 0.7518136501312256, Prec: 0.8606522679328918, Rec 0.8578859567642212\n",
      "Epoch 929/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09497210383415222\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07279463178581662, Valid loss: 0.3921119272708893, IoU: 0.7522069811820984, Prec: 0.8629136085510254, Rec 0.856159508228302\n",
      "Epoch 930/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06126496568322182\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07134345314568943, Valid loss: 0.3803459107875824, IoU: 0.7510981559753418, Prec: 0.8565605878829956, Rec 0.8610420227050781\n",
      "Epoch 931/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07324280589818954\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07216400255759557, Valid loss: 0.37439969182014465, IoU: 0.7513684034347534, Prec: 0.8535496592521667, Rec 0.8644677996635437\n",
      "Epoch 932/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08669577538967133\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07204211685392592, Valid loss: 0.37901782989501953, IoU: 0.7511569261550903, Prec: 0.8537683486938477, Rec 0.8640077710151672\n",
      "Epoch 933/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.050249215215444565\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07135624215006828, Valid loss: 0.37701621651649475, IoU: 0.7510411143302917, Prec: 0.8546488881111145, Rec 0.8629416227340698\n",
      "Epoch 934/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07274510711431503\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07299299488464991, Valid loss: 0.38053572177886963, IoU: 0.7509198784828186, Prec: 0.8560664057731628, Rec 0.8613488078117371\n",
      "Epoch 935/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08466402441263199\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07195631083514956, Valid loss: 0.384652316570282, IoU: 0.7514833211898804, Prec: 0.8583461046218872, Rec 0.8597930073738098\n",
      "Epoch 936/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08776478469371796\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07171555558840434, Valid loss: 0.38305673003196716, IoU: 0.7512263059616089, Prec: 0.8568381071090698, Rec 0.8609603643417358\n",
      "Epoch 937/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08756295591592789\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0713123114572631, Valid loss: 0.3810172975063324, IoU: 0.7503506541252136, Prec: 0.8536631464958191, Rec 0.8630010485649109\n",
      "Epoch 938/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07367579638957977\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07124246127075619, Valid loss: 0.3827114701271057, IoU: 0.7515013217926025, Prec: 0.8580172657966614, Rec 0.8600996732711792\n",
      "Epoch 939/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06347611546516418\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07152146100997925, Valid loss: 0.385468453168869, IoU: 0.7522560358047485, Prec: 0.8602654337882996, Rec 0.8588505983352661\n",
      "Epoch 940/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07674957811832428\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07136814362472958, Valid loss: 0.3867274522781372, IoU: 0.7520372271537781, Prec: 0.8597061038017273, Rec 0.8591152429580688\n",
      "Epoch 941/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06561437249183655\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07074555522865719, Valid loss: 0.3829196095466614, IoU: 0.7509665489196777, Prec: 0.8549715280532837, Rec 0.8624815940856934\n",
      "Epoch 942/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07005945593118668\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0716557643479771, Valid loss: 0.38297998905181885, IoU: 0.7515235543251038, Prec: 0.8583956956863403, Rec 0.8597658276557922\n",
      "Epoch 943/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.077194094657897954\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07039981484413146, Valid loss: 0.3817732334136963, IoU: 0.7518361806869507, Prec: 0.8583213686943054, Rec 0.8602530360221863\n",
      "Epoch 944/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05903130769729614\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07130298415819804, Valid loss: 0.37717413902282715, IoU: 0.7510313987731934, Prec: 0.8543720245361328, Rec 0.863146960735321\n",
      "Epoch 945/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07799500972032547\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07215682350926929, Valid loss: 0.3862152397632599, IoU: 0.7522150278091431, Prec: 0.8609269857406616, Rec 0.8581234216690063\n",
      "Epoch 946/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06097756698727608\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07200939564241303, Valid loss: 0.3820481598377228, IoU: 0.7512285709381104, Prec: 0.8571079969406128, Rec 0.8606240153312683\n",
      "Epoch 947/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09859414398670197\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07204009228282504, Valid loss: 0.376397967338562, IoU: 0.7525709867477417, Prec: 0.8581264615058899, Rec 0.861380934715271\n",
      "Epoch 948/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06271689385175705\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0722902226779196, Valid loss: 0.380098819732666, IoU: 0.7507972717285156, Prec: 0.8550053834915161, Rec 0.8621947169303894\n",
      "Epoch 949/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.082027539610862734\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07120380136701795, Valid loss: 0.37543338537216187, IoU: 0.7504765391349792, Prec: 0.8521250486373901, Rec 0.8647300004959106\n",
      "Epoch 950/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08871708810329437\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07134692503346338, Valid loss: 0.38045018911361694, IoU: 0.7510496973991394, Prec: 0.8556740880012512, Rec 0.8618632555007935\n",
      "Epoch 951/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08643221855163574\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07114862435393864, Valid loss: 0.38221046328544617, IoU: 0.7516686916351318, Prec: 0.8573620915412903, Rec 0.8609678149223328\n",
      "Epoch 952/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.10426398366689682\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07133622318506241, Valid loss: 0.37440985441207886, IoU: 0.7514546513557434, Prec: 0.8527933359146118, Rec 0.8653384447097778\n",
      "Epoch 953/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08666925877332687\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07071297549539142, Valid loss: 0.3782670497894287, IoU: 0.7513979077339172, Prec: 0.8540048599243164, Rec 0.8640077710151672\n",
      "Epoch 954/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08280827850103378\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07155381888151169, Valid loss: 0.3866630494594574, IoU: 0.7518962621688843, Prec: 0.861223578453064, Rec 0.857418417930603\n",
      "Epoch 955/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06292500346899033\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07163999991284477, Valid loss: 0.3846992552280426, IoU: 0.7513458132743835, Prec: 0.8581966161727905, Rec 0.8597038984298706\n",
      "Epoch 956/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09066482633352288\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07150623053312302, Valid loss: 0.38370001316070557, IoU: 0.7522498965263367, Prec: 0.8587106466293335, Rec 0.8603618741035461\n",
      "Epoch 957/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06763280183076859\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07236660437451468, Valid loss: 0.38153573870658875, IoU: 0.7505067586898804, Prec: 0.8530648946762085, Rec 0.8638123273849487\n",
      "Epoch 958/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.060414671897888184\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07207109663221571, Valid loss: 0.3848925530910492, IoU: 0.7519398927688599, Prec: 0.8599560856819153, Rec 0.8587467074394226\n",
      "Epoch 959/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09255512803792953\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07069369074371126, Valid loss: 0.38304081559181213, IoU: 0.7525809407234192, Prec: 0.8595151901245117, Rec 0.8600378036499023\n",
      "Epoch 960/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.060834918171167374\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07161561159623994, Valid loss: 0.38028600811958313, IoU: 0.7521308064460754, Prec: 0.8578834533691406, Rec 0.861071765422821\n",
      "Epoch 961/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06785432994365692\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07364893092049493, Valid loss: 0.38448458909988403, IoU: 0.7518574595451355, Prec: 0.8580095171928406, Rec 0.8605819940567017\n",
      "Epoch 962/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06455267965793617\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07119958897431691, Valid loss: 0.3820532262325287, IoU: 0.7510297298431396, Prec: 0.856448769569397, Rec 0.8610643148422241\n",
      "Epoch 963/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07559645175933838\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07134057614538404, Valid loss: 0.37738969922065735, IoU: 0.751129686832428, Prec: 0.8536466360092163, Rec 0.8640521764755249\n",
      "Epoch 964/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07644934207201004\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07073592957523134, Valid loss: 0.3742663264274597, IoU: 0.7510431408882141, Prec: 0.8529471158981323, Rec 0.8646508455276489\n",
      "Epoch 965/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.085935294628143315\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07187202738391028, Valid loss: 0.37848764657974243, IoU: 0.7510312795639038, Prec: 0.8551970720291138, Rec 0.8623480796813965\n",
      "Epoch 966/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08360264450311661\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07173812240362168, Valid loss: 0.3787424564361572, IoU: 0.7518624663352966, Prec: 0.8564985394477844, Rec 0.8621106147766113\n",
      "Epoch 967/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05006440728902817\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07135858519209756, Valid loss: 0.3824184834957123, IoU: 0.7513472437858582, Prec: 0.8581815958023071, Rec 0.8597262501716614\n",
      "Epoch 968/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09443969279527664\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07103482964966032, Valid loss: 0.3761354088783264, IoU: 0.7516943216323853, Prec: 0.8550294637680054, Rec 0.8633571863174438\n",
      "Epoch 969/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.106584466993808754\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07179331299331453, Valid loss: 0.38766247034072876, IoU: 0.7522392868995667, Prec: 0.8606823682785034, Rec 0.8583979606628418\n",
      "Epoch 970/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06700332462787628\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07122099465794034, Valid loss: 0.3828565180301666, IoU: 0.7510166764259338, Prec: 0.855467677116394, Rec 0.8620190620422363\n",
      "Epoch 971/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06457755714654922\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07198723173803753, Valid loss: 0.3786776661872864, IoU: 0.7508362531661987, Prec: 0.855002224445343, Rec 0.8622293472290039\n",
      "Epoch 972/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06395081430673599\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07216502212815815, Valid loss: 0.3725730776786804, IoU: 0.7510334253311157, Prec: 0.8550319671630859, Rec 0.8624939918518066\n",
      "Epoch 973/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07748422026634216\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07106817000442081, Valid loss: 0.37955978512763977, IoU: 0.7497426867485046, Prec: 0.8527691960334778, Rec 0.8630949854850769\n",
      "Epoch 974/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.054329656064510345\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07074643654955758, Valid loss: 0.37569865584373474, IoU: 0.7509877681732178, Prec: 0.8536617159843445, Rec 0.8638321161270142\n",
      "Epoch 975/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.064384028315544134\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0709666113058726, Valid loss: 0.3815193176269531, IoU: 0.7515251040458679, Prec: 0.8582429885864258, Rec 0.8599017858505249\n",
      "Epoch 976/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09387347102165222\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07049983971648746, Valid loss: 0.38328105211257935, IoU: 0.7519404292106628, Prec: 0.8570306897163391, Rec 0.8616703152656555\n",
      "Epoch 977/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08276643604040146\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0710031454761823, Valid loss: 0.3819175064563751, IoU: 0.7523534893989563, Prec: 0.8594413995742798, Rec 0.8597930073738098\n",
      "Epoch 978/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.04471496120095253\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07286188213361634, Valid loss: 0.38131529092788696, IoU: 0.7511280179023743, Prec: 0.8564704060554504, Rec 0.8611533045768738\n",
      "Epoch 979/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.107259802520275126\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07203834371434317, Valid loss: 0.38459309935569763, IoU: 0.7520353198051453, Prec: 0.8588468432426453, Rec 0.8599660992622375\n",
      "Epoch 980/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07778319716453552\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07171879642539554, Valid loss: 0.37319785356521606, IoU: 0.7515667080879211, Prec: 0.853873074054718, Rec 0.8643712997436523\n",
      "Epoch 981/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09848248213529587\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07151561859581206, Valid loss: 0.38501134514808655, IoU: 0.7514509558677673, Prec: 0.8565557599067688, Rec 0.8615244030952454\n",
      "Epoch 982/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08351114392280579\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07171665165159437, Valid loss: 0.38251200318336487, IoU: 0.7517637014389038, Prec: 0.8562465906143188, Rec 0.8622094988822937\n",
      "Epoch 983/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06694835424423218\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0711377223332723, Valid loss: 0.37994974851608276, IoU: 0.7508412599563599, Prec: 0.8539384603500366, Rec 0.8633522987365723\n",
      "Epoch 984/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08860057592391968\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07076983782980177, Valid loss: 0.3808825612068176, IoU: 0.7510524392127991, Prec: 0.8539630770683289, Rec 0.8636045455932617\n",
      "Epoch 985/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07311640679836273\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07066413594616784, Valid loss: 0.37915968894958496, IoU: 0.7514254450798035, Prec: 0.8551355600357056, Rec 0.8628921508789062\n",
      "Epoch 986/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08338162302970886\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07206157578362359, Valid loss: 0.38528233766555786, IoU: 0.7519935369491577, Prec: 0.8595184087753296, Rec 0.8592314720153809\n",
      "Epoch 987/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06094284728169441\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07149230382508702, Valid loss: 0.3818660080432892, IoU: 0.7506808042526245, Prec: 0.855579674243927, Rec 0.8614551424980164\n",
      "Epoch 988/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06735647469758987\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0716713430152999, Valid loss: 0.3799791932106018, IoU: 0.7502936124801636, Prec: 0.8536098599433899, Rec 0.862946629524231\n",
      "Epoch 989/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07624445855617523\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07057888971434699, Valid loss: 0.37932467460632324, IoU: 0.7509685754776001, Prec: 0.8540061712265015, Rec 0.8634437322616577\n",
      "Epoch 990/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06674129515886307\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07122239288356569, Valid loss: 0.37949657440185547, IoU: 0.7511626482009888, Prec: 0.8560633659362793, Rec 0.8616455793380737\n",
      "Epoch 991/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07939963042736053\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07182224293549856, Valid loss: 0.3734942078590393, IoU: 0.7514970302581787, Prec: 0.8528226613998413, Rec 0.8653359413146973\n",
      "Epoch 992/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07456485927104955\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.0712430715560913, Valid loss: 0.3876396119594574, IoU: 0.7516034841537476, Prec: 0.8600031733512878, Rec 0.8582421541213989\n",
      "Epoch 993/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07052674889564514\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07120913333363003, Valid loss: 0.3779486119747162, IoU: 0.7513008713722229, Prec: 0.8554263114929199, Rec 0.8624222874641418\n",
      "Epoch 994/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07551971822977066\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07154795775810878, Valid loss: 0.37558773159980774, IoU: 0.7513563632965088, Prec: 0.8533461689949036, Rec 0.8646261096000671\n",
      "Epoch 995/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06587745249271393\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07124816377957661, Valid loss: 0.3770112693309784, IoU: 0.7509504556655884, Prec: 0.854327380657196, Rec 0.8630876541137695\n",
      "Epoch 996/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.08690427988767624\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07185795257488886, Valid loss: 0.3782919645309448, IoU: 0.75200355052948, Prec: 0.8583055734634399, Rec 0.8604756593704224\n",
      "Epoch 997/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.05825610086321831\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07107785865664482, Valid loss: 0.3784419894218445, IoU: 0.7507003545761108, Prec: 0.8545586466789246, Rec 0.8625162243843079\n",
      "Epoch 998/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.09398404508829117\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07276069770256678, Valid loss: 0.38001567125320435, IoU: 0.7517472505569458, Prec: 0.8575764894485474, Rec 0.8608540296554565\n",
      "Epoch 999/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.06193178519606594\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07093648372424974, Valid loss: 0.3837447762489319, IoU: 0.751218318939209, Prec: 0.8573316335678101, Rec 0.860401451587677\n",
      "Epoch 1000/1000\n",
      "\u001b[KBatch 12/12, Train loss: 0.07829157263040543\n",
      "Epoch finished in 0.4 seconds\n",
      "Train loss: 0.07129315088192621, Valid loss: 0.3877602517604828, IoU: 0.7517956495285034, Prec: 0.8598419427871704, Rec 0.8586527109146118\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from recipes import train_vessel_manual as train_pytorch\n",
    "import torchtrainer\n",
    "\n",
    "params = {\n",
    "    # Dataset\n",
    "    'img_dir': Path('../data/vessel_manual/images'),\n",
    "    'label_dir': Path('../data/vessel_manual/labels'),      \n",
    "    'train_val_split': 0.1,\n",
    "    # Model\n",
    "    'model_layers': (1, 1, 1), \n",
    "    'model_channels': (16,32,64), \n",
    "    'model_type': 'unet',\n",
    "    # Training\n",
    "    'epochs': 200,\n",
    "    'lr': 0.01,\n",
    "    'batch_size_train': 8,\n",
    "    'batch_size_valid': 8, \n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 0.,\n",
    "    'seed': 12,\n",
    "    'loss': 'cross_entropy',\n",
    "    'scheduler_power': 0.9,\n",
    "    'class_weights': (0.3414, 0.6586),\n",
    "    # Efficiency\n",
    "    'device': 'cuda',\n",
    "    'num_workers': 3,  # 3 is a good compromise\n",
    "    'use_amp': True,\n",
    "    'pin_memory': False,\n",
    "    'non_blocking': False,\n",
    "    # Logging\n",
    "    'log_dir': '../logs_vessel_manual',\n",
    "    'experiment':'unet_l_1_1_1_c_16_32_64',\n",
    "    'save_every':1,                \n",
    "    'save_best':True,\n",
    "    # Other\n",
    "    'resume': False,\n",
    "}\n",
    "\n",
    "#Train using pure Pytorch\n",
    "logger, ds_train, ds_valid, model = train_pytorch.run(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU4AAAD9CAYAAADTep4GAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA8lElEQVR4nO3deVhTx/oH8G8SSNgJOwHZVERFwRWKexXF9WprW6xU0bpURUtFrbUVwdaKtj+tXVy6iNpbW61ea71V4SqKVkSwLiiKKIjFjUUpu4Ql8/sDORKDSkIghLyf58kjmZxz8h5iXubMzJnhMcYYCCGENBpf0wEQQoi2ocRJCCFKosRJCCFKosRJCCFKosRJCCFKosRJCCFKosRJCCFKosRJCCFKosRJCCFKosRJCCFK0nji3LhxI1xdXWFgYABfX18kJyc/d/sNGzbAw8MDhoaGcHJywsKFC1FRUdGkYxJCiFKYBu3atYsJhUIWHR3Nrly5wmbNmsXEYjHLzc1tcPudO3cykUjEdu7cybKyslhsbCyTSCRs4cKFKh+TEEKUpdHE6ePjw0JCQrjnNTU1zMHBgUVFRTW4fUhICBs6dKhcWVhYGOvfv7/KxySEEGXpaaqmW1lZiXPnzmHZsmVcGZ/Ph7+/PxITExvcp1+/fvjpp5+QnJwMHx8f3Lx5E4cOHcKUKVNUPiYASKVSSKVS7rlMJkNBQQGsrKzA4/GaeqqEkFaEMYaSkhI4ODiAz1ettVJjifPBgweoqamBnZ2dXLmdnR2uXbvW4D6TJ0/GgwcPMGDAADDGUF1djTlz5uDDDz9U+ZgAEBUVhZUrVzbxjAgh2uT27dto166dSvtqLHGqIj4+HqtXr8amTZvg6+uLjIwMhIaG4pNPPkF4eLjKx122bBnCwsK450VFRXB2dsbt27dhZmb2/J2jGvGL7zIemLBR5fgIIepTXFwMJycnmJqaqnwMjSVOa2trCAQC5ObmypXn5ubC3t6+wX3Cw8MxZcoUzJw5EwDQvXt3lJWVYfbs2fjoo49UOiYAiEQiiEQihXIzM7MXJ05RIy7lDfjAi45DCGlRTWmG09hwJKFQiN69eyMuLo4rk8lkiIuLg5+fX4P7lJeXK7RJCAQCALXtFqocs9noGQLtX679ue+Mln1vQkiz0uilelhYGIKDg9GnTx/4+Phgw4YNKCsrw/Tp0wEAU6dOhaOjI6KiogAA48aNw/r169GzZ0/uUj08PBzjxo3jEuiLjtlixE5A0F6gNBcwd2zZ9yaENCuNJs7AwEDk5+djxYoVyMnJQY8ePRATE8N17mRnZ8vVMJcvXw4ej4fly5fj7t27sLGxwbhx4/Dpp582+pgthscHBHqUNAlpg3iM0WJtTysuLoa5uTmKiope3MYZad5wuW1XYN6zh0ARQjRDqe/3M2j8lss2i0e/WkLaKvp2NxcLV01HQAhpJpQ4m8uY9ZqOgBDSTChxNhfTFu6MIoS0GEqchBCiJEqchBCiJEqcTVbvti2rjrX/9nlbM6EQQlqEVk3y0Srx+ACrqf3ZpT8w+wQgNNZsTISQZkWJs6l4PKDuFgI9A0BkotFwCCHNjy7V1UlPcYYlQkjbQ4mzyeq1ceobai4MQkiLocTZVPXn9KMaJyE6gRJnk9VLnCKarJgQXUCJU50MLTQdASGkBVDibKr6syAZiDUWBiGk5VDibKr6bZyGYo2FQQhpOZQ4m6xe4jR4xqTGhJA2hRJnU9XdNQTQpTohOoISZ1NVVzz52YB61QnRBZQ41Ukg1MjbMsZw6sYDFJRVauT9CdE1dK+6OjVhgXtV3C18BBORHrxX/g8A4GRpiP/M6Yc7hY+QdLMAMwe6obyyBuaG+i0aFyFtHSVOLXUtpxgjN/wpV3a74BF8Vsdxz9fGXAMAfP1mT+y/cBejukvwqLIaHWxM0K+jNYDa2ioA8Fo46ROizShxaqGjV3Mx88e/Gr39gl8uAADiruVxZRJzA9wvqm2fndbPFf+UV2KslwM625ti99nbcLczQS9nCzhZGqk3eELaAEqcWuazmGvYFJ/Z5OPUJU0A2H76FgDg94v3GtzW3FAfi0Z0goG+AGDAa73bgc+nGirRXZQ4tUhltUwtSVNZRY+qsOL3K9zz9/9zCX7trRDczxViI32YG+qjTFqN17YkAgD2h/SHm5UxzI2obZW0TZQ4tcCBlHt49/Hl9ot0tjfFFD8XrP/fdTxsxl72xJsPkXjzYYOvTdiYwP28e/ZLaGdpBFtTEfQFfPxTVgmxkT61qRKtRomzqUwdgJKGL3HVQVpd02DS7NfBCqcznySud4e5Y3wPB7S3NgaPx0OQrwuqamQ4c/Mhfjt/F85WRnilpyMGfx7fbLE2JPC7M9zPfB4gezxb/uHQgdDj87D99C3weMB7/p1gbSICYwwpd4rQwcYYpgZUYyWtE4/VdasSTnFxMczNzVFUVAQzsxcMat83G7i0Gxi0BBi6XK1x5JdI0ffTowrlX07qgfE9HMEYQ1UNQ3ZBGTrYmDSqFnc++x8s+89lhPq7435RBUZ3t0dOUQWsjEWwMxfh4KX76OEkxtB1JwAAb/o445fkbLWe17MsCfDAyev5SMoqAADsm9cP3u3EYIwhI78UnWxNqW2VNJlS3+9noBqnuqj5PvWU24UYX++St77xPRwB1A4hEurx0NHWtNHH7eVsgdiFg+TKJOZPZq5/tVc7lEqrueczB7ph77nbqKqp/fsaPa0PHpRUoriiCp3sTNHLxQLdImIb/f7P83lsutzzVzedBgDYmIqQXyJFkK8zZg9qj4oqGSyM9GFrZoDiiioY6Akg1KN7OUjLocTZVFyFXX01odS7Rc9Mmrtmv6S293kWY6EAI7raoVrG4GZljGOLhmD2v89hxdiu8Otg9dx9V03ohuX7U7nn6qix5pdIAQA7k7KxM0nxWCM97eFibYRbD8qwdGRnWBmLYGqgp1A7raiqgYG+AI8qa1BcUQU+jwcbU5q1nyiPEmeTPU6cauzsWPe/9AbLD707EF0dmv9+eB6Ph++m9uGeO1ka4XDowBfu98GoznjrJReM83bg7mbydbNE1KvdUSqt5mqmAZ52uPWgHJ3sTWFuqIfkrAJczy3ljuPfxQ5H03IbHW/MlRzu59grjd8PAGxNRSh6VAUrYyEsTYQY1U2CeUM6yDV7VFTV4MzNh3ipvRVyiiog4PMUxrdWVstQXFEFaxNKxLqAEmdTNUON83h6vkJZyMsdWiRpqiLmvYE4kZ6P6f3dAABmBnro7miOu4WP0Me1dlZ8E5Ee0j4eib/+LoCvm5XCpfXTdzAxxvDF0Rv4Ku5Gs8ae97g2e6+oAveKKpB6txiF5ZVwsjSSG4L1tIsrhoMHHkT6fKTcLsQnB68i7X4JNgX1QtGjKrzW68lYV5mMUdtsG0OJs8nU17dWI2NIftwxUmfWQDcsGOYOs1bcw9zZ3gyd7Z8kdR6Ph9/m9QOPx4OgXsIwFAow0N2mwWM83bHF4/Hgbvtkjfrz4cPR65Mjao68Yd//mfXCbXp83HAs7/z7HADg/b2XAADbpvXF9O1nMbiTDfJLpBjn7YD9F+5i7WtecLM2RmF5JVysjBsVV2W1DDweoC+g9lxNo8TZVEw9l+qMMXT48JBC+UdjujbpuJqip4Yvt6zegA9L44ZnnuoqMYOTpeFzL9Gn+rngx8S/mxyPKqZvPwsAOHG99iri6v1iAPJjXQHgx7d9sP/CXYT6u+PbkzchkzGsHO+JvefuwERU25xR1767cXIvjPGSPPd97/xTDitjEQyFAnWfEgElTjVQz6X6tZwShbJ5Qzo06Zjaro+rJYDazqqnpa4MwMXsQrzU3hJ6Aj72/HUb57ML8cl4T/xTXoWCskqsOZyGUP9O6OEkxvIxXbHgl/NKt4EO7WyLY/Xu8W8uU6OTAQD7Ltzlynadvd3gtiE/n0fIz0+ev9GnHfQFfOxMyoZIjw9ptYx77UL4cJy8kQ9HsSF+TPwblsZCzB/ascG22JTbhVgbcw2BfZ3Q3toELtZG+CPlPgI87WBlIsKxa7kwNdBH38efy/PUDZVrq6MdWsU4zo0bN+Lzzz9HTk4OvL298fXXX8PHx6fBbYcMGYITJ04olI8ePRoHDx4EAEybNg07duyQez0gIAAxMTGNikepcV6/BgNX9wOjPgN832nU8Rvi+sFBhbK0j0fqfI3hdkE5zI30YWagL/c7urVmjErHq5ExnLn5EF7tzNE9srYD65PxnujX0RqlFdW4nluCJY8vswEgc/VoZD0oxYSNp9GvgxUMhYJn3tPfln05qQdCd13knm+b1heX7hTBw94E13JKMKCjNfeHLre4AkP/Lx5llTXYO8cPlsZCHEi5h1kD20PA5yE6IQvZD8sxf2hHtLNQnESGMYYbeaWwMzOAiUgPKXcK0aOdmGsnrq6RNemKpk2M49y9ezfCwsKwZcsW+Pr6YsOGDQgICEB6ejpsbW0Vtt+3bx8qK5/cSvjw4UN4e3vj9ddfl9tu5MiR2LZtG/dcJGru3k71Nv6LjfR1PmkCkOu97mxvims5Jejf8flDop5HwOeh/+Mp9f5YMAD5pVK87PHk/5m3kxjdHM0x6ss/ue072poidWUAgNov9fyXOyL5VgFGd5OgZ71214QPhsLGRAShXu2tpfVf83GzxI9v+6BzeO0f73Wve+Pmg9qRBBuPt/z8A8qqnzSBJ00QdTYcbbgTr27+goa2ebpG/UpPR5zKeMANP6tPj89DtYxx/weA2v8Pr/dxwid/XAUA/N/r3pjQw0EtzUQvovHEuX79esyaNQvTp08HAGzZsgUHDx5EdHQ0PvjgA4XtLS3lLxN27doFIyMjhcQpEolgb2/ffIFzmt7GufK/ir23f33kr/Lx2qrt032w99xtTPJxVsvxujk2fNNCF4kZvpncEw5iQ4XXeDwe3O1M4W6neNOBY73t608effqDobB5fK/+0bDBKCyv5GpnAODVToy1MdewOag3OtmZwG2ZYlt3ne3T+8LMUB/bEm7hvylPar7fTunNdUwBwKhu9jicmtPQIVqt3+o1Uzyt+vG9uvWbtK7llHBJEwAW70nBKz0dmy/AejSaOCsrK3Hu3DksW7aMK+Pz+fD390diYuJz9nxi69atmDRpEoyN5Xsm4+PjYWtrCwsLCwwdOhSrVq2ClVXDNRWpVAqp9MlfueLi4safRBNbOtYcvoZtCbfkyo6GDW6Rv5raxt7cAPOHurfIe431cmjUduFju+KTP67i4/GecuV8Pg9nlg1DVY1MLgF3rDdSoE6Apz0CPJ/8kf/qzZ7YeCwDA92t8a6/O4QCPq7cK8KD0koMeVw77ukkxsRejlj6n0t4z78TAjzt4d/FFnHX8nBk4WB0tDXBg1Ip0nNK0L+jNapqZHD/6DCA2tpbbxcLWBgJEXMlB6YiPSR+OAw1NQxrY68h6eZDdJGY4cjVXLn2UgCY3t8V6TklOJ35EDxe7e+pfgLXpHeHucuN4mhOGm3jvHfvHhwdHXH69Gn4+flx5e+//z5OnDiBpKSk5+6fnJwMX19fJCUlybWJ1tVC3dzckJmZiQ8//BAmJiZITEyEQKB4+RsZGYmVK1cqlDeqDWT3W0Daf4HR/wf4zHrBGSt6um3zcOhAdJG0zvGapGF5JRWwNTXQdBioqpGhsLzqmXdDVVTV4Or9YvR0EnPDv6pqZM8d3sQYQ3llDQR8HooeVcHOrPY8a2QMjDHuD3zWgzJcvP0PXvawhdhICMYYqmUMK35PBWPAO4M7QI/Pg1CPjzv/PEIXiSkmfXcGl+4U4a2XnLF8TFf8cek+NsVnYOpLLhDpC3DpTiHaW5ug6FEVxnhJsP/CXXx78ib6uFjgg1GdsepgGhzFhnipgxVsTIQY2e35Iw3qqKONU6sT5zvvvIPExERcunTpudvdvHkTHTp0wNGjRzFs2DCF1xuqcTo5OTXuF7srCLj2BzBmHdB35vO3bcDTiTNlxQiax5LoBMaYUtMLMsZwKuMBujuaQ2yk+sKI6kicGr0etLa2hkAgQG6u/BCR3NzcF7ZPlpWVYdeuXZgxY8YL36d9+/awtrZGRkZGg6+LRCKYmZnJPZSn/CXC+ex/FMpMDTTe7ExIi1B2TlYej4eB7jZNSprqotHEKRQK0bt3b8TFPVlgTCaTIS4uTq4G2pA9e/ZAKpXirbfeeuH73LlzBw8fPoRE0riqvFJUHABf9KiKm/2nPro1j5DWT+M9EGFhYfj++++xY8cOpKWlYe7cuSgrK+N62adOnSrXeVRn69atmDBhgkKHT2lpKZYsWYIzZ87g1q1biIuLw/jx49GxY0cEBAQ045kol/C+P3lToaydhWIvLiGk9dH4dWFgYCDy8/OxYsUK5OTkoEePHoiJiYGdnR0AIDs7G3y+fH5PT0/HqVOn8L///U/heAKBAJcuXcKOHTtQWFgIBwcHjBgxAp988kkzjeVUrcb5zXH5ZoPoaX3g1U6sppgIIc1J5cRZXV2N+Ph4ZGZmYvLkyTA1NcW9e/dgZmYGExPFIRfPM3/+fMyfP7/B1+Lj4xXKPDw88Kw+LUNDQ8TGqmdi3UZRoW/t8p0ihbKhne3UEQ0hpAWolDj//vtvjBw5EtnZ2ZBKpRg+fDhMTU2xdu1aSKVSbNmyRd1xtmKNv1ddJmPIK5Eip7jihdsSQlovlRJnaGgo+vTpg5SUFLk2xldeeQWzZik/llGrKdE5tHhvCvadv6vOOY8JIRqgUuL8888/cfr0aQiF8sMCXF1dcffus2+bapsaX+Pcd772d/P01f1Iz5a4NZQQoi4qJU6ZTIaamhqF8jt37sDUtPELh7UJTZyPM3SYOxYM7ajGgAghzU2l4UgjRozAhg0buOc8Hg+lpaWIiIjA6NGj1RWbllE+cQb7uWDh8E50XzohWkalGue6desQEBCArl27oqKiApMnT8aNGzdgbW2NX375Rd0xtnKNq3FmPyxXKBvn3biJJAghrYtKibNdu3ZISUnB7t27kZKSgtLSUsyYMQNBQUEwNNSxQdyNGI5UXSPDu7suKJT3acRM2oSQ1kflcZx6enoICgpCUFCQOuPRQi/uHIr87xVcvF0oVxY+VjvXEiKEqNjGGRUVhejoaIXy6OhorF27tslBaZVGdA79dCZboWzGALfmiogQ0sxUSpzffvstOnfurFDu6empY4PfAXUt1kYI0R4qJc6cnJwGZxqysbHB/fv3mxyUVnlBjTOmgeULji8e0owBEUKam0qJ08nJCQkJCQrlCQkJcHDQ1Z5ixcRZKq3GnJ/OyZWd/cgfbtbGCtsSQrSHSp1Ds2bNwnvvvYeqqioMHToUABAXF4f3338fixYtUmuArd+ze9U/3HdZocyCZncnROuplDiXLFmChw8fYt68edxSvQYGBli6dGmDc2e2ac+5VD/w1CJWKStG0GB3QtoAlRInj8fD2rVrER4ejrS0NBgaGsLd3b0F1i7XHr9fVLxnn9YSIqRtaNJExiYmJujbt6+6YtFOXccD9l6AtfyytaG7Lso9n9bPteViIoQ0K5USZ1lZGdasWYO4uDjk5eVBJpNfe/nmTcVlIdqsBpYEPnRZcWRB5L88FcoIIdpJpcQ5c+ZMnDhxAlOmTIFEIlF6tbq2bt7O85oOgRDSjFRKnIcPH8bBgwfRv39/dcfTJtmYUtsvIW2JSl28FhYWsLSkCSoaa8pLLpoOgRCiRiolzk8++QQrVqxAebniVGlE3juD22PWwPaaDoMQokYqz8eZmZkJOzs7uLq6Ql9ffpjN+fO628YXdSiN+/k9f3e8599Jg9EQQpqDSolzwoQJag6j7fj25JMRBcNoyV9C2iSVEmdERIS642iTJGIDTYdACGkGdP+fGslk8vetW5tQbzohbZFKNc6amhp88cUX+PXXX5Gdnc3dr16noKBALcFpm+RbT87b2dJIg5EQQpqTSjXOlStXYv369QgMDERRURHCwsLw6quvgs/nIzIyUs0haofKahkmfXeGez6iK7VvEtJWqZQ4d+7cie+//x6LFi2Cnp4e3nzzTfzwww9YsWIFzpw58+IDtEElFVVyzxeN8NBQJISQ5qbyDPDdu3cHUDvRR1FREQBg7NixOHjwoPqi0yJl0hq554ZCgYYiIYQ0N5USZ7t27bglMjp06ID//e9/AICzZ8/q7NRypdJqTYdACGkhKiXOV155BXFxcQCABQsWIDw8HO7u7pg6dSrefvtttQaoLShxEqI7VOpVX7NmDfdzYGAgnJ2dkZiYCHd3d4wbN05twWmT89n/cD9vn67jc5QS0sY1aSLjOn5+fvDz81PHobQSYwxbT2UBAGYPao8hHrYajogQ0pxUTpz37t3DqVOnGpzI+N13321yYNokv1SK/BIpAGDu4A4ajoYQ0txUSpzbt2/HO++8A6FQCCsrK7mJjHk8ns4lzoeltTcAWJsIYWEs1HA0hJDmplLnUHh4OFasWIGioiLcunULWVlZ3EOVZTM2btwIV1dXGBgYwNfXF8nJyc/cdsiQIeDxeAqPMWPGcNswxrBixQpIJBIYGhrC398fN27cUOVUG6WyurbGLdKjIUiE6AKVEmd5eTkmTZoEPr/pt7rv3r0bYWFhiIiIwPnz5+Ht7Y2AgADk5eU1uP2+fftw//597pGamgqBQIDXX3+d2+azzz7DV199hS1btiApKQnGxsYICAhARUVFk+NtSGVNbeIU6tGt/4ToApW+6TNmzMCePXvUEsD69esxa9YsTJ8+HV27dsWWLVtgZGSE6OjoBre3tLSEvb099zhy5AiMjIy4xMkYw4YNG7B8+XKMHz8eXl5e+PHHH3Hv3j3s379fLTE/TVpVV+OkxEmILlCpjTMqKgpjx45FTEwMunfvrjCR8fr16xt1nMrKSpw7dw7Lli3jyvh8Pvz9/ZGYmNioY2zduhWTJk2CsbExACArKws5OTnw9/fntjE3N4evry8SExMxadIkhWNIpVJIpVLueXFxcaPemzuPmtq7hqjGSYhuUDlxxsbGwsOj9n7spzuHGuvBgweoqamBnZ38hBh2dna4du3aC/dPTk5Gamoqtm7dypXl5ORwx3j6mHWvPS0qKgorV65sdNxPq2vjFAoocRKiC1ReOiM6OhrTpk1TczjK2bp1K7p37w4fH58mHWfZsmUICwvjnhcXF8PJyanR+0vrOof0KXESogtU+qaLRCK1LA1sbW0NgUCA3NxcufLc3FzY29s/d9+ysjLs2rULM2bMkCuv20+ZY4pEIpiZmck9lCGlGichOkWlb3poaCi+/vrrJr+5UChE7969ufveAUAmkyEuLu6FdyLt2bMHUqkUb731lly5m5sb7O3t5Y5ZXFyMpKSkZru7qaKqto2TZkQiRDeodKmenJyMY8eO4Y8//oCnp6dC59C+ffsafaywsDAEBwejT58+8PHxwYYNG1BWVobp06cDAKZOnQpHR0dERUXJ7bd161ZMmDABVlZWcuU8Hg/vvfceVq1aBXd3d7i5uSE8PBwODg7Ntshc3QQfRkK13MFKCGnlVPqmi8VivPrqq2oJIDAwEPn5+VixYgVycnLQo0cPxMTEcJ072dnZCuNF09PTcerUKW46u6e9//77KCsrw+zZs1FYWIgBAwYgJiYGBgbNs3ha+eO5OE1ElDgJ0QU8xhh78WZPVFdX4+eff8aIESNe2A6prYqLi2Fubo6ioqJGtXdGHriC7advYd6QDnh/ZOcWiJAQoiplv98NUbqNU09PD3PmzJEb96jryitrL9WNqcZJiE5QqXPIx8cHFy5cUHcsWqussvZS3Yg6hwjRCSpVkebNm4dFixbhzp076N27N3fXTh0vLy+1BKctyqRU4yREl6j0Ta+7bbH+9HE8Hg+MMfB4PNTU1Dxr1zaprnPImHrVCdEJKn3Ts7Ky1B2HVit73MZpJKJLdUJ0gUqJ08XFRd1xaLVHj9s4DfUpcRKiC1S+tszMzMSGDRuQlpYGAOjatStCQ0PRoYPuLR1R9XjpEH265ZIQnaDSNz02NhZdu3ZFcnIyvLy84OXlhaSkJHh6euLIkSPqjrHVq6quHQpL96oTohtUqnF+8MEHWLhwodwywXXlS5cuxfDhw9USnLaoflzj1BM0fko9Qoj2UqmKlJaWpjArEQC8/fbbuHr1apOD0jZVNbU1Tn1KnIToBJUSp42NDS5evKhQfvHiRdja6t6a4lU11MZJiC5R6VJ91qxZmD17Nm7evIl+/foBABISErB27Vq5CYF1RfXjGqceJc42qaamBlVVVZoOgzSSvr4+BILmHeGiUuIMDw+Hqakp1q1bx60X5ODggMjISJ1bUx2o16vOp0v1toQxhpycHBQWFmo6FKIksVgMe3t7pZbyUUajE+eBAwcwatQo6Ovrg8fjYeHChVi4cCFKSkoAAKamps0SYGtXI2Oom1+KLtXblrqkaWtrCyMjo2b7EhL1YYyhvLycW15cIpE0y/s0OnG+8soryMnJgY2NDQQCAe7fvw9bW1udTZh16to3AepVb0tqamq4pPn0ZNmkdTM0NAQA5OXlwdbWtlku2xtdRbKxscGZM2cAgLsnnQCF5U/avqjG2XbUtWkaGRlpOBKiirrPrbnaphtd45wzZw7Gjx8PHo8HHo/33EmMdWmSj8V7UrifKXG2PVRB0E7N/bk1OnFGRkZi0qRJyMjIwL/+9S9s27YNYrG4GUPTDqcyHnA/C6hziBCdoFSveufOneHh4YHg4GBMnDgRJiYmzRUXIYS0WkpfWzLGsHPnTty/f7854iGENNG0adMavaJrfHw8eDxeg0OuXF1dsWHDBrXG1lYonTj5fD7c3d3x8OHD5oiHEEJaPZV6M9asWYMlS5YgNTVV3fEQ0moxxlBeWa2Rh5KL0XKkUineffdd2NrawsDAAAMGDMDZs2fV/JvRPSrdOTR16lSUl5fD29sbQqGQGzdVp6CgQC3BEdKaPKqqQdcVsRp576sfB8BIhaVZ3n//ffznP//Bjh074OLigs8++wwBAQHIyMiApaVlM0SqG1RKnNTuQUjrV1ZWhs2bN2P79u0YNWoUAOD777/HkSNHsHXrVixZskTDEWovlRJncHCwuuMgpNUz1Bfg6scBGntvZWVmZqKqqgr9+/fnyvT19eHj48Ot3EBU06SlM7Zt24bMzEx8+eWXsLW1xeHDh+Hs7AxPT091xkhIq8Dj8VS6XG7NzMzMAABFRUUK47ILCwthbm6ugahaP5U6h06cOIHu3bsjKSkJ+/btQ2lpKQAgJSUFERERag2QEKKaDh06QCgUIiEhgSurqqrC2bNn0bVrVwCAu7s7+Hw+zp07J7fvzZs3UVRUhE6dOrVozNpCpcT5wQcfYNWqVThy5AiEQiFXPnToUO5+dl0x0N1a0yEQ0iBjY2PMnTsXS5YsQUxMDK5evYpZs2ahvLycW8HB1NQUM2fOxKJFi3DgwAFkZWXh5MmTCAoKwksvvcTNt0vkqXTdcfnyZfz8888K5ba2tnjw4EEDe7RdLlZG+PMGEDrMXdOhEKJgzZo1kMlkmDJlCkpKStCnTx/ExsbCwsKC2+bLL7/EmjVrsHTpUvz999+wt7fH8OHD8emnn9K9+s+gUuIUi8W4f/8+3Nzc5MovXLgAR0dHtQSmLeqG1/HpPxhpJbZv3879bGBggK+++gpfffXVM7c3MDBAZGQkIiMjmz+4NkKlS/VJkyZh6dKlyMnJAY/Hg0wmQ0JCAhYvXoypU6eqO8ZWTfY4cVLeJER3qJQ4V69ejS5dusDZ2RmlpaXo2rUrBg0ahH79+mH58uXqjrGVq82clDcJ0R1KXarLZDJ8/vnnOHDgACorKzFlyhRMnDgRpaWl6NmzJ9zdda+d7/FyQ+DTlHKE6AylEuenn36KyMhI+Pv7w9DQED///DMYY4iOjm6u+Fo9BtXuISaEaC+lLtV//PFHbNq0CbGxsdi/fz/++9//YufOnZDJZC/euY2iziFCdI9SiTM7OxujR4/mnvv7+4PH4+HevXtqD0xbUOcQIbpHqcRZXV0NAwMDuTJ9ff0mLYi0ceNGuLq6wsDAAL6+vkhOTn7u9oWFhQgJCYFEIoFIJEKnTp1w6NAh7vXIyEhuXaS6R+fOnVWO70XqLtWpiZMQ3aFUGydjDNOmTYNIJOLKKioqMGfOHBgbG3Nl+/bta9Txdu/ejbCwMGzZsgW+vr7YsGEDAgICkJ6eDltbW4XtKysrMXz4cNja2mLv3r1wdHTE33//rXCPraenJ44ePfrkJPWa7/7iukt1HvWrE6IzlMooDc2K9NZbb6n85uvXr8esWbMwffp0AMCWLVtw8OBBREdH44MPPlDYPjo6GgUFBTh9+jT09fUB1E7v/zQ9Pb3nrsKpTnUTzNKlOiG6Q6nEuW3bNrW9cWVlJc6dO4dly5ZxZXw+H/7+/khMTGxwnwMHDsDPzw8hISH4/fffYWNjg8mTJ2Pp0qVyi87fuHEDDg4OMDAwgJ+fH6KiouDs7PzMWKRSKaRSKfe8uLi40efxpI2TMifRXTweD7/99luj1jpSZtvWSmMLgT948AA1NTWws7OTK7ezs0NOTk6D+9y8eRN79+5FTU0NDh06hPDwcKxbtw6rVq3itvH19cX27dsRExODzZs3IysrCwMHDkRJSckzY4mKioK5uTn3cHJyavR51A1GorRJWotp06Zx7ftCoRAdO3bExx9/jOrq6mZ7z/v373OTJatz29ZKqyYXlMlksLW1xXfffQeBQIDevXvj7t27+Pzzz7np7Op/IF5eXvD19YWLiwt+/fVXbkaYpy1btgxhYWHc8+Li4kYnz7pLdeocIq3JyJEjsW3bNkilUhw6dAghISHQ19eXu8IDaq/86s9wpiplmsZaqhmtOWmsxmltbQ2BQIDc3Fy58tzc3Gf+YiUSCTp16iR3Wd6lSxfk5OSgsrKywX3EYjE6deqEjIyMZ8YiEolgZmYm92gsRpfquoMxoLJMMw8lF2sTiUSwt7eHi4sL5s6dC39/fxw4cIBbOvjTTz+Fg4MDPDw8AAC3b9/GG2+8AbFYDEtLS4wfPx63bt2SO2Z0dDQ8PT0hEokgkUgwf/587jUej4f9+/cDqE3G8+fPh0QigYGBAVxcXBAVFdXgtkDtbGtDhw6FoaEhrKysMHv2bG6OX+DJcsf/93//B4lEAisrK4SEhDRpNE9TaazGKRQK0bt3b8TFxXFtHTKZDHFxcXIfSH39+/fHzz//DJlMBj6/Nudfv34dEonkmX81S0tLkZmZiSlTpjTLedBwJB1SVQ6sdtDMe394DxAav3i7ZzA0NOSW9I6Li4OZmRmOHDkCoHZy44CAAPj5+eHPP/+Enp4eVq1ahZEjR+LSpUsQCoXYvHkzwsLCsGbNGowaNQpFRUVyEyTX99VXX+HAgQP49ddf4ezsjNu3b+P27dsNbltWVsa999mzZ5GXl4eZM2di/vz5crM8HT9+HBKJBMePH0dGRgYCAwPRo0cPzJo1S+XfSVNo9FI9LCwMwcHB6NOnD3x8fLBhwwaUlZVxvexTp06Fo6Mj99dq7ty5+OabbxAaGooFCxbgxo0bWL16Nd59913umIsXL8a4cePg4uKCe/fuISIiAgKBAG+++WaznAN30xTVOEkrxBhDXFwcYmNjsWDBAuTn58PY2Bg//PADV9n46aefIJPJ8MMPP3BXTtu2bYNYLEZ8fDxGjBiBVatWYdGiRQgNDeWO3bdv3wbfMzs7G+7u7hgwYAB4PB5cXFyeGd/PP/+MiooK/Pjjj9yQxm+++Qbjxo3D2rVruT4QCwsLfPPNNxAIBOjcuTPGjBmDuLg43UycgYGByM/Px4oVK5CTk4MePXogJiaG+2VlZ2dzNUsAcHJyQmxsLBYuXAgvLy84OjoiNDQUS5cu5ba5c+cO3nzzTTx8+BA2NjYYMGAAzpw5Axsbm2Y5B0azI+kOfaPamp+m3lsJf/zxB0xMTFBVVQWZTIbJkycjMjISISEh6N69u9wVWkpKCjIyMmBqaip3jIqKCmRmZiIvLw/37t3DsGHDGvXe06ZNw/Dhw+Hh4YGRI0di7NixGDFiRIPbpqWlwdvbW24ceP/+/SGTyZCens7lAk9PT7kmOolEgsuXLzf696FuGu8cmj9//jMvzePj4xXK/Pz8nrs8x65du9QVWqPQveo6hMdr0uVyS3r55ZexefNmCIVCODg4yN0EUj9JAbXNWb1798bOnTsVjmNjYyNXeWmMXr16ISsrC4cPH8bRo0fxxhtvwN/fH3v37lXtZABu3HadunmANUXjiVPb0b3qpDUyNjZGx44dG7Vtr169sHv3btja2j6zY9TV1RVxcXF4+eWXG3VMMzMzBAYGIjAwEK+99hpGjhyJgoICWFpaym3XpUsXbN++HWVlZVxCT0hIAJ/P5zquWiON9aq3HdQ5RLRbUFAQrK2tMX78ePz555/IyspCfHw83n33Xdy5cwdA7RwQ69atw1dffYUbN27g/Pnz+Prrrxs83vr16/HLL7/g2rVruH79Ovbs2QN7e3uFW6Pr3tvAwADBwcFITU3F8ePHsWDBAkyZMkVhjHdrQomziWR0rzrRckZGRjh58iScnZ3x6quvokuXLpgxYwYqKiq4GmhwcDA2bNiATZs2wdPTE2PHjsWNGzcaPJ6pqSk+++wz9OnTB3379sWtW7dw6NChBi/5jYyMEBsbi4KCAvTt2xevvfYahg0bhm+++aZZz7mpeIwpOUBMBxQXF8Pc3BxFRUUvHNM5fVsyjqfn4/PXvPB6n8bfcURat4qKCmRlZcHNzU1hRjDS+j3v81Pm+/0sVONsIrpXnRDdQ4mziehedUJ0DyXOJuLuVaffJCE6g77uTUQTGROieyhxNhF35xDlTUJ0BiXOJqq7eYE6hwjRHZQ4m8jEQA/mhvoQCuhXSYiuoFsum+j7qX00HQIhpIVRNYkQQpREiZMQonb1Z3m/desWeDweLl68qNGY1IkSJyFtTP3F2vT19eHm5ob3338fFRUVmg6tzaA2TkLaoLrF2qqqqnDu3DkEBweDx+Nh7dq1mg6tTaAaJyGNxBhDeVW5Rh7KzsVTt1ibk5MTJkyYAH9/f26NIZlMhqioKLi5ucHQ0BDe3t4KkwxfuXIFY8eOhZmZGUxNTTFw4EBkZmYCAM6ePYvhw4fD2toa5ubmGDx4MM6fP6+eX7KWoBonIY30qPoRfH/21ch7J01OgpGSy2fUSU1NxenTp7m1f6KiovDTTz9hy5YtcHd3x8mTJ/HWW2/BxsYGgwcPxt27dzFo0CAMGTIEx44dg5mZGRISErh12UtKShAcHIyvv/4ajDGsW7cOo0ePxo0bNxSW32irKHES0gbVrTlUXV0NqVQKPp+Pb775BlKpFKtXr8bRo0fh5+cHAGjfvj1OnTqFb7/9FoMHD8bGjRthbm6OXbt2cUtWdOrUiTv20KFD5d7ru+++g1gsxokTJzB27NiWO0kNosRJSCMZ6hkiaXKSxt5bGXVrDpWVleGLL76Anp4eJk6ciCtXrqC8vBzDhw+X276yshI9e/YEAFy8eBEDBw5UWOenTm5uLpYvX474+Hjk5eWhpqYG5eXlyM7OVu3ktBAlTkIaicfjqXy53NLqrzkUHR0Nb29vbN26Fd26dQMAHDx4EI6OjnL7iEQiALVrsD9PcHAwHj58iC+//BIuLi4QiUTw8/NDZWVlM5xJ60SJk5A2js/n48MPP0RYWBiuX78OkUiE7OxsDB48uMHtvby8sGPHDlRVVTVY60xISMCmTZswevRoAMDt27fx4MGDZj2H1oZ61QnRAa+//joEAgG+/fZbLF68GAsXLsSOHTuQmZnJLby2Y8cOALVLdhcXF2PSpEn466+/cOPGDfz73/9Geno6AMDd3R3//ve/kZaWhqSkJAQFBb2wltrWUI2TEB2gp6eH+fPn47PPPkNWVhZsbGwQFRWFmzdvQiwWo1evXvjwww8BAFZWVjh27BiWLFmCwYMHQyAQoEePHujfvz8AYOvWrZg9ezZ69eoFJycnrF69GosXL9bk6bU4WqytAepYzIloN1qsTbvRYm2EENLKUOIkhBAlUeIkhBAlUeIkhBAlUeIk5Dmo71Q7NffnRomTkAbUDfwuLy/XcCREFXWf27NuG20qGsdJSAMEAgHEYjHy8vIAAEZGRrSSqRZgjKG8vBx5eXkQi8UQCATN8j6UOAl5Bnt7ewDgkifRHmKxmPv8mgMlTkKegcfjQSKRwNbWFlVVVZoOhzSSvr5+s9U061DiJOQFBAJBs38RiXbReOfQxo0b4erqCgMDA/j6+iI5Ofm52xcWFiIkJAQSiQQikQidOnXCoUOHmnRMQghRhkYT5+7duxEWFoaIiAicP38e3t7eCAgIeGabUmVlJYYPH45bt25h7969SE9Px/fffy83r6CyxySEEKUxDfLx8WEhISHc85qaGubg4MCioqIa3H7z5s2sffv2rLKyUm3HbEhRUREDwIqKihq9DyFEO6jj+62xNs7KykqcO3cOy5Yt48r4fD78/f2RmJjY4D4HDhyAn58fQkJC8Pvvv8PGxgaTJ0/G0qVLIRAIVDomAEilUkilUu55UVERgNpZVAghbUvd95o1YZC8xhLngwcPUFNTAzs7O7lyOzs7XLt2rcF9bt68iWPHjiEoKAiHDh1CRkYG5s2bh6qqKkRERKh0TKB21b+VK1cqlDs5OalwZoQQbVBSUgJzc3OV9tWqXnWZTAZbW1t89913EAgE6N27N+7evYvPP/8cERERKh932bJlCAsLk3ufgoICWFlZvXDQc3FxMZycnHD79u02OXdnWz8/oO2fY1s/P0C5c2SMoaSkBA4ODiq/n8YSp7W1NQQCAXJzc+XKc3NznzlwVSKRKIzR6tKlC3JyclBZWanSMYHaRarqFqqqIxaLlTofMzOzNvufEmj75we0/XNs6+cHNP4cVa1p1tFYr7pQKETv3r0RFxfHlclkMsTFxXHrPT+tf//+yMjIgEwm48quX78OiUQCoVCo0jEJIURZGh2OFBYWhu+//x47duxAWloa5s6di7KyMkyfPh0AMHXqVLmOnrlz56KgoAChoaG4fv06Dh48iNWrVyMkJKTRxySEkKbSaBtnYGAg8vPzsWLFCuTk5KBHjx6IiYnhOneys7PB5z/J7U5OToiNjcXChQvh5eUFR0dHhIaGYunSpY0+prqJRCJEREQoXOq3FW39/IC2f45t/fyAlj9HWqyNEEKUpPFbLgkhRNtQ4iSEECVR4iSEECVR4iSEECVR4mwibZzCLioqCn379oWpqSlsbW0xYcIEpKeny20zZMgQ8Hg8ucecOXPktsnOzsaYMWNgZGQEW1tbLFmyBNXV1S15Ks8UGRmpEH/nzp251ysqKhASEgIrKyuYmJhg4sSJCjdOtObzc3V1VTg/Ho/HDc3Txs/v5MmTGDduHBwcHMDj8bB//3651xljWLFiBSQSCQwNDeHv748bN27IbVNQUICgoCCYmZlBLBZjxowZKC0tldvm0qVLGDhwIAwMDODk5ITPPvtM+WDVM9+Ibtq1axcTCoUsOjqaXblyhc2aNYuJxWKWm5ur6dCeKyAggG3bto2lpqayixcvstGjRzNnZ2dWWlrKbTN48GA2a9Ysdv/+fe5RfzaZ6upq1q1bN+bv788uXLjADh06xKytrdmyZcs0cUoKIiIimKenp1z8+fn53Otz5sxhTk5OLC4ujv3111/spZdeYv369eNeb+3nl5eXJ3duR44cYQDY8ePHGWPa+fkdOnSIffTRR2zfvn0MAPvtt9/kXl+zZg0zNzdn+/fvZykpKexf//oXc3NzY48ePeK2GTlyJPP29mZnzpxhf/75J+vYsSN78803udeLioqYnZ0dCwoKYqmpqeyXX35hhoaG7Ntvv1UqVkqcTaCOKexag7y8PAaAnThxgisbPHgwCw0NfeY+hw4dYnw+n+Xk5HBlmzdvZmZmZkwqlTZnuI0SERHBvL29G3ytsLCQ6evrsz179nBlaWlpDABLTExkjLX+83taaGgo69ChA5PJZIwx7f/8nk6cMpmM2dvbs88//5wrKywsZCKRiP3yyy+MMcauXr3KALCzZ89y2xw+fJjxeDx29+5dxhhjmzZtYhYWFnLnuHTpUubh4aFUfHSprqK6Kez8/f25ssZMYdca1U2jZ2lpKVe+c+dOWFtbo1u3bli2bJncUrmJiYno3r273I0FAQEBKC4uxpUrV1om8Be4ceMGHBwc0L59ewQFBSE7OxsAcO7cOVRVVcl9dp07d4azszP32WnD+dWprKzETz/9hLfffltuUhpt//zqy8rKQk5OjtxnZm5uDl9fX7nPTCwWo0+fPtw2/v7+4PP5SEpK4rYZNGgQhEIht01AQADS09Pxzz//NDoerZodqTVRdQq71kYmk+G9995D//790a1bN6588uTJcHFxgYODAy5duoSlS5ciPT0d+/btAwDk5OQ0eO51r2mar68vtm/fDg8PD9y/fx8rV67EwIEDkZqaipycHAiFQoWJXOzs7LjYW/v51bd//34UFhZi2rRpXJm2f35Pq4upoZjrf2a2trZyr+vp6cHS0lJuGzc3N4Vj1L1mYWHRqHgoceq4kJAQpKam4tSpU3Lls2fP5n7u3r07JBIJhg0bhszMTHTo0KGlw1TaqFGjuJ+9vLzg6+sLFxcX/PrrrzA0NNRgZOq3detWjBo1Sm6aNG3//Fo7ulRXkapT2LUm8+fPxx9//IHjx4+jXbt2z93W19cXAJCRkQGgds3xhs697rXWRiwWo1OnTsjIyIC9vT0qKytRWFgot039z05bzu/vv//G0aNHMXPmzOdup+2fX11Mz/u+2dvbK6wtVl1djYKCArV/rpQ4VaTNU9gxxjB//nz89ttvOHbsmMKlS0MuXrwIoHZOVADw8/PD5cuX5f6jHjlyBGZmZujatWuzxN0UpaWlyMzMhEQiQe/evaGvry/32aWnpyM7O5v77LTl/LZt2wZbW1uMGTPmudtp++fn5uYGe3t7uc+suLgYSUlJcp9ZYWEhzp07x21z7NgxyGQy7g+Hn58fTp48iaqqKm6bI0eOwMPDo9GX6QBoOFJT7Nq1i4lEIrZ9+3Z29epVNnv2bCYWi+V6KlujuXPnMnNzcxYfHy83XKW8vJwxxlhGRgb7+OOP2V9//cWysrLY77//ztq3b88GDRrEHaNuOMuIESPYxYsXWUxMDLOxsWk1w3UWLVrE4uPjWVZWFktISGD+/v7M2tqa5eXlMcZqhyM5OzuzY8eOsb/++ov5+fkxPz8/bv/Wfn6M1Y7icHZ2ZkuXLpUr19bPr6SkhF24cIFduHCBAWDr169nFy5cYH///TdjrHY4klgsZr///ju7dOkSGz9+fIPDkXr27MmSkpLYqVOnmLu7u9xwpMLCQmZnZ8emTJnCUlNT2a5du5iRkRENR2ppX3/9NXN2dmZCoZD5+PiwM2fOaDqkFwLQ4GPbtm2MMcays7PZoEGDmKWlJROJRKxjx45syZIlCqsC3rp1i40aNYoZGhoya2trtmjRIlZVVaWBM1IUGBjIJBIJEwqFzNHRkQUGBrKMjAzu9UePHrF58+YxCwsLZmRkxF555RV2//59uWO05vNjjLHY2FgGgKWnp8uVa+vnd/z48Qb/XwYHBzPGaockhYeHMzs7OyYSidiwYcMUzv3hw4fszTffZCYmJszMzIxNnz6dlZSUyG2TkpLCBgwYwEQiEXN0dGRr1qxROlaaVo4QQpREbZyEEKIkSpyEEKIkSpyEEKIkSpyEEKIkSpyEEKIkSpyEEKIkSpyEEKIkSpyEEKIkSpyEqKih5R2IbqDESbTStGnTGlxzZ+TIkZoOjegAmo+TaK2RI0di27ZtcmUikUhD0RBdQjVOorVEIhHs7e3lHnVTg/F4PGzevBmjRo2CoaEh2rdvj71798rtf/nyZQwdOhSGhoawsrLC7NmzFVZEjI6OhqenJ0QiESQSCebPny/3+oMHD/DKK6/AyMgI7u7uOHDgQPOeNGkVKHGSNis8PBwTJ05ESkoKgoKCMGnSJKSlpQEAysrKEBAQAAsLC5w9exZ79uzB0aNH5RLj5s2bERISgtmzZ+Py5cs4cOAAOnbsKPceK1euxBtvvIFLly5h9OjRCAoKQkFBQYueJ9EAFWeAIkSjgoODmUAgYMbGxnKPTz/9lDFWO3XenDlz5Pbx9fVlc+fOZYwx9t133zELCwu5JZEPHjwot/Kjg4MD++ijj54ZAwC2fPly7nlpaSkDwA4fPqy28yStE7VxEq318ssvY/PmzXJl9VfqfHomfj8/P24m9LS0NHh7e8PY2Jh7vX///pDJZEhPTwePx8O9e/cwbNiw58bg5eXF/WxsbAwzMzOF5RtI20OJk2gtY2NjhUtndWnsgm76+vpyz3k8HmQyWXOERFoRauMkbdaZM2cUnnfp0gUA0KVLF6SkpKCsrIx7PSEhAXw+Hx4eHjA1NYWrq6vcGjeE1KEaJ9FaUqlUYQ1wPT09WFtbAwD27NmDPn36YMCAAdi5cyeSk5OxdetWAEBQUBAiIiIQHByMyMhI5OfnY8GCBZgyZQq3znZkZCTmzJkDW1tbjBo1CiUlJUhISMCCBQta9kRJq0OJk2itmJgYbtXGOh4eHrh27RqA2h7vXbt2Yd68eZBIJPjll1+4FRyNjIwQGxuL0NBQ9O3bF0ZGRpg4cSLWr1/PHSs4OBgVFRX44osvsHjxYlhbW+O1115ruRMkrRatOUTaJB6Ph99++w0TJkzQdCikDaI2TkIIURIlTkIIURK1cZI2iVqgSHOiGichhCiJEichhCiJEichhCiJEichhCiJEichhCiJEichhCiJEichhCiJEichhCjp/wHbjUvzitIj1gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 320x240 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot results\n",
    "\n",
    "def plot_metrics(logger, type='lt'):\n",
    "    '''Plot losses and IoU. `lt` is the logger used in Lightning.'''\n",
    "\n",
    "    if type=='lt':\n",
    "        metrics = logger.metrics\n",
    "        epochs, _ = zip(*metrics['val_loss'])\n",
    "        metrics = [list(zip(*metrics[k]))[1] for k in ['train_loss', 'val_loss', 'iou', 'prec', 'rec']]\n",
    "        train_loss, valid_loss, iou, prec, rec = metrics    \n",
    "    elif type=='pt':\n",
    "        epochs, metrics = zip(*logger.data.items())\n",
    "        train_loss, valid_loss, iou, prec, rec = zip(*metrics)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_loss, label='Train loss')\n",
    "    plt.plot(epochs, valid_loss, label='Valid loss')\n",
    "    plt.ylim((0, 0.4))\n",
    "    plt.xlim((0, 200))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, iou, label='IoU')\n",
    "    plt.plot(epochs, prec, label='Precision')\n",
    "    plt.plot(epochs, rec, label='Recall')\n",
    "    plt.ylim((0.6, 0.8))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Performance')\n",
    "\n",
    "def plot_examples(ds, model, n=4):\n",
    "    \"\"\"Plot some example segmentations\"\"\"\n",
    "\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "    indices = random.sample(range(len(ds)),n)\n",
    "    for i, idx in enumerate(indices):\n",
    "        x, y = ds[idx]\n",
    "        x_or, y_or = ds.get_item(idx)\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(x[None].cuda())[0].cpu()\n",
    "        x = x[0]\n",
    "        y_pred = torch.max(y_pred, dim=0)[1]\n",
    "\n",
    "        plt.figure(figsize=[20,5])\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(x_or, 'gray')\n",
    "        plt.title('Original image')\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(x, 'gray')\n",
    "        plt.title('Augmented image')\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(y, 'gray')\n",
    "        plt.title('Ground truth')\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(y_pred, 'gray')\n",
    "        plt.title('Prediction')\n",
    "\n",
    "plot_metrics(logger, type='pt')\n",
    "#plot_examples(ds_valid, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze model statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, tensor(-64.0225), tensor(24.8368)),\n",
       " (1, tensor(-37.0607), tensor(13.7886)),\n",
       " (2, tensor(-32.1525), tensor(12.9102)),\n",
       " (3, tensor(-38.5950), tensor(13.4953)),\n",
       " (4, tensor(-34.7780), tensor(16.4175)),\n",
       " (5, tensor(-23.4627), tensor(11.7179)),\n",
       " (6, tensor(-34.4972), tensor(13.7270)),\n",
       " (7, tensor(-29.1929), tensor(11.6199)),\n",
       " (8, tensor(-55.4941), tensor(14.5814)),\n",
       " (9, tensor(-38.3041), tensor(16.2493))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if output values are too large\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "stats = []\n",
    "with torch.no_grad():\n",
    "    for idx, (x, y) in enumerate(ds_valid):\n",
    "        if idx%10==0:\n",
    "            print(idx)\n",
    "        output = model(x[None].to('cuda'))[0].to('cpu')\n",
    "        stats.append((idx, output.min(), output.max()))\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  ('iou', tensor(0.8441)),\n",
       "  ('prec', tensor(0.8488)),\n",
       "  ('rec', tensor(0.9935))),\n",
       " (1,\n",
       "  ('iou', tensor(0.6121)),\n",
       "  ('prec', tensor(0.6329)),\n",
       "  ('rec', tensor(0.9489))),\n",
       " (2,\n",
       "  ('iou', tensor(0.7782)),\n",
       "  ('prec', tensor(0.8197)),\n",
       "  ('rec', tensor(0.9389))),\n",
       " (3,\n",
       "  ('iou', tensor(0.6989)),\n",
       "  ('prec', tensor(0.7092)),\n",
       "  ('rec', tensor(0.9797))),\n",
       " (4,\n",
       "  ('iou', tensor(0.8589)),\n",
       "  ('prec', tensor(0.9151)),\n",
       "  ('rec', tensor(0.9333))),\n",
       " (5,\n",
       "  ('iou', tensor(0.6302)),\n",
       "  ('prec', tensor(0.6354)),\n",
       "  ('rec', tensor(0.9873))),\n",
       " (6,\n",
       "  ('iou', tensor(0.7270)),\n",
       "  ('prec', tensor(0.8121)),\n",
       "  ('rec', tensor(0.8740))),\n",
       " (7,\n",
       "  ('iou', tensor(0.6979)),\n",
       "  ('prec', tensor(0.7146)),\n",
       "  ('rec', tensor(0.9677))),\n",
       " (8,\n",
       "  ('iou', tensor(0.4749)),\n",
       "  ('prec', tensor(0.4750)),\n",
       "  ('rec', tensor(0.9995))),\n",
       " (9,\n",
       "  ('iou', tensor(0.7884)),\n",
       "  ('prec', tensor(0.7928)),\n",
       "  ('rec', tensor(0.9931)))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check performance\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "stats = []\n",
    "with torch.no_grad():\n",
    "    for idx, (x, y) in enumerate(ds_valid):\n",
    "        output = model(x[None].to('cuda')).to('cpu')\n",
    "        acc = torchtrainer.perf_funcs.segmentation_accuracy(output, y[None], ('iou', 'prec', 'rec'))\n",
    "        stats.append((idx, *list(acc.items())))\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('litseg.model.conv1', tensor(-23.9948), tensor(28.5901)),\n",
       " ('litseg.model.bn1', tensor(-13.7820), tensor(13.7432)),\n",
       " ('litseg.model.relu', tensor(0.), tensor(13.7432)),\n",
       " ('litseg.model.encoder.stage_0.0.conv1', tensor(-46.2537), tensor(42.8798)),\n",
       " ('litseg.model.encoder.stage_0.0.bn1', tensor(-16.3660), tensor(20.0193)),\n",
       " ('litseg.model.encoder.stage_0.0.relu1', tensor(0.), tensor(20.0193)),\n",
       " ('litseg.model.encoder.stage_0.0.conv2', tensor(-50.0530), tensor(55.3143)),\n",
       " ('litseg.model.encoder.stage_0.0.bn2', tensor(-22.2832), tensor(22.9372)),\n",
       " ('litseg.model.encoder.stage_0.0.relu2', tensor(0.), tensor(36.0959)),\n",
       " ('litseg.model.encoder.stage_0.0.downsample.0',\n",
       "  tensor(-16.9323),\n",
       "  tensor(24.5988)),\n",
       " ('litseg.model.encoder.stage_0.0.downsample.1',\n",
       "  tensor(-18.4771),\n",
       "  tensor(17.8221)),\n",
       " ('litseg.model.encoder.stage_0.0.downsample',\n",
       "  tensor(-18.4771),\n",
       "  tensor(17.8221)),\n",
       " ('litseg.model.encoder.stage_0.0', tensor(0.), tensor(36.0959)),\n",
       " ('litseg.model.encoder.stage_0', tensor(0.), tensor(36.0959)),\n",
       " ('litseg.model.encoder.stage_1.0.conv1', tensor(-98.0210), tensor(95.2401)),\n",
       " ('litseg.model.encoder.stage_1.0.bn1', tensor(-20.8519), tensor(22.6670)),\n",
       " ('litseg.model.encoder.stage_1.0.relu1', tensor(0.), tensor(22.6670)),\n",
       " ('litseg.model.encoder.stage_1.0.conv2', tensor(-59.8261), tensor(58.9635)),\n",
       " ('litseg.model.encoder.stage_1.0.bn2', tensor(-20.7973), tensor(26.0096)),\n",
       " ('litseg.model.encoder.stage_1.0.relu2', tensor(0.), tensor(45.3798)),\n",
       " ('litseg.model.encoder.stage_1.0.downsample.0',\n",
       "  tensor(-29.3193),\n",
       "  tensor(41.9330)),\n",
       " ('litseg.model.encoder.stage_1.0.downsample.1',\n",
       "  tensor(-21.2695),\n",
       "  tensor(23.1265)),\n",
       " ('litseg.model.encoder.stage_1.0.downsample',\n",
       "  tensor(-21.2695),\n",
       "  tensor(23.1265)),\n",
       " ('litseg.model.encoder.stage_1.0', tensor(0.), tensor(45.3798)),\n",
       " ('litseg.model.encoder.stage_1', tensor(0.), tensor(45.3798)),\n",
       " ('litseg.model.encoder.stage_2.0.conv1', tensor(-121.7335), tensor(140.1188)),\n",
       " ('litseg.model.encoder.stage_2.0.bn1', tensor(-22.3644), tensor(25.5225)),\n",
       " ('litseg.model.encoder.stage_2.0.relu1', tensor(0.), tensor(25.5225)),\n",
       " ('litseg.model.encoder.stage_2.0.conv2', tensor(-101.5128), tensor(152.4065)),\n",
       " ('litseg.model.encoder.stage_2.0.bn2', tensor(-26.1558), tensor(25.9963)),\n",
       " ('litseg.model.encoder.stage_2.0.relu2', tensor(0.), tensor(44.7967)),\n",
       " ('litseg.model.encoder.stage_2.0.downsample.0',\n",
       "  tensor(-62.3086),\n",
       "  tensor(50.6583)),\n",
       " ('litseg.model.encoder.stage_2.0.downsample.1',\n",
       "  tensor(-22.0932),\n",
       "  tensor(23.6239)),\n",
       " ('litseg.model.encoder.stage_2.0.downsample',\n",
       "  tensor(-22.0932),\n",
       "  tensor(23.6239)),\n",
       " ('litseg.model.encoder.stage_2.0', tensor(0.), tensor(44.7967)),\n",
       " ('litseg.model.encoder.stage_2', tensor(0.), tensor(44.7967)),\n",
       " ('litseg.model.mid_block.conv1', tensor(-217.4089), tensor(231.8032)),\n",
       " ('litseg.model.mid_block.bn1', tensor(-30.3715), tensor(28.2808)),\n",
       " ('litseg.model.mid_block.relu1', tensor(0.), tensor(28.2808)),\n",
       " ('litseg.model.mid_block.conv2', tensor(-173.6687), tensor(182.3213)),\n",
       " ('litseg.model.mid_block.bn2', tensor(-28.3259), tensor(29.6424)),\n",
       " ('litseg.model.mid_block.relu2', tensor(0.), tensor(72.6485)),\n",
       " ('litseg.model.mid_block', tensor(0.), tensor(72.6485)),\n",
       " ('litseg.model.decoder.stage_2.0.conv.0',\n",
       "  tensor(-155.9111),\n",
       "  tensor(236.4284)),\n",
       " ('litseg.model.decoder.stage_2.0.conv.1', tensor(-27.0677), tensor(28.1902)),\n",
       " ('litseg.model.decoder.stage_2.0.conv.2', tensor(0.), tensor(28.1902)),\n",
       " ('litseg.model.decoder.stage_2.0.conv', tensor(0.), tensor(28.1902)),\n",
       " ('litseg.model.decoder.stage_2.0.interpolate', tensor(0.), tensor(28.1902)),\n",
       " ('litseg.model.decoder.stage_2.0', tensor(0.), tensor(28.1902)),\n",
       " ('litseg.model.decoder.stage_2.1', tensor(0.), tensor(45.3798)),\n",
       " ('litseg.model.decoder.stage_2.2.0.conv1',\n",
       "  tensor(-300.6649),\n",
       "  tensor(334.8069)),\n",
       " ('litseg.model.decoder.stage_2.2.0.bn1', tensor(-26.3223), tensor(27.5679)),\n",
       " ('litseg.model.decoder.stage_2.2.0.relu1', tensor(0.), tensor(27.5679)),\n",
       " ('litseg.model.decoder.stage_2.2.0.conv2',\n",
       "  tensor(-198.6697),\n",
       "  tensor(181.5499)),\n",
       " ('litseg.model.decoder.stage_2.2.0.bn2', tensor(-33.0171), tensor(31.4769)),\n",
       " ('litseg.model.decoder.stage_2.2.0.relu2', tensor(0.), tensor(57.3876)),\n",
       " ('litseg.model.decoder.stage_2.2.0.downsample.0',\n",
       "  tensor(-107.7532),\n",
       "  tensor(122.2751)),\n",
       " ('litseg.model.decoder.stage_2.2.0.downsample.1',\n",
       "  tensor(-24.8738),\n",
       "  tensor(31.0291)),\n",
       " ('litseg.model.decoder.stage_2.2.0.downsample',\n",
       "  tensor(-24.8738),\n",
       "  tensor(31.0291)),\n",
       " ('litseg.model.decoder.stage_2.2.0', tensor(0.), tensor(57.3876)),\n",
       " ('litseg.model.decoder.stage_2.2', tensor(0.), tensor(57.3876)),\n",
       " ('litseg.model.decoder.stage_1.0.conv.0', tensor(-87.6211), tensor(201.0599)),\n",
       " ('litseg.model.decoder.stage_1.0.conv.1', tensor(-29.1784), tensor(31.1660)),\n",
       " ('litseg.model.decoder.stage_1.0.conv.2', tensor(0.), tensor(31.1660)),\n",
       " ('litseg.model.decoder.stage_1.0.conv', tensor(0.), tensor(31.1660)),\n",
       " ('litseg.model.decoder.stage_1.0.interpolate', tensor(0.), tensor(31.1660)),\n",
       " ('litseg.model.decoder.stage_1.0', tensor(0.), tensor(31.1660)),\n",
       " ('litseg.model.decoder.stage_1.1', tensor(0.), tensor(36.0959)),\n",
       " ('litseg.model.decoder.stage_1.2.0.conv1',\n",
       "  tensor(-192.0357),\n",
       "  tensor(240.6983)),\n",
       " ('litseg.model.decoder.stage_1.2.0.bn1', tensor(-26.9225), tensor(32.6592)),\n",
       " ('litseg.model.decoder.stage_1.2.0.relu1', tensor(0.), tensor(32.6592)),\n",
       " ('litseg.model.decoder.stage_1.2.0.conv2',\n",
       "  tensor(-104.8311),\n",
       "  tensor(129.2032)),\n",
       " ('litseg.model.decoder.stage_1.2.0.bn2', tensor(-29.0055), tensor(34.0144)),\n",
       " ('litseg.model.decoder.stage_1.2.0.relu2', tensor(0.), tensor(57.8440)),\n",
       " ('litseg.model.decoder.stage_1.2.0.downsample.0',\n",
       "  tensor(-83.1335),\n",
       "  tensor(104.7131)),\n",
       " ('litseg.model.decoder.stage_1.2.0.downsample.1',\n",
       "  tensor(-30.1494),\n",
       "  tensor(27.1800)),\n",
       " ('litseg.model.decoder.stage_1.2.0.downsample',\n",
       "  tensor(-30.1494),\n",
       "  tensor(27.1800)),\n",
       " ('litseg.model.decoder.stage_1.2.0', tensor(0.), tensor(57.8440)),\n",
       " ('litseg.model.decoder.stage_1.2', tensor(0.), tensor(57.8440)),\n",
       " ('litseg.model.decoder.stage_0.0.interpolate', tensor(0.), tensor(57.8440)),\n",
       " ('litseg.model.decoder.stage_0.0', tensor(0.), tensor(57.8440)),\n",
       " ('litseg.model.decoder.stage_0.1', tensor(0.), tensor(57.8440)),\n",
       " ('litseg.model.decoder.stage_0.2.0.conv1',\n",
       "  tensor(-198.6606),\n",
       "  tensor(273.4151)),\n",
       " ('litseg.model.decoder.stage_0.2.0.bn1', tensor(-25.3716), tensor(34.0739)),\n",
       " ('litseg.model.decoder.stage_0.2.0.relu1', tensor(0.), tensor(34.0739)),\n",
       " ('litseg.model.decoder.stage_0.2.0.conv2',\n",
       "  tensor(-152.5443),\n",
       "  tensor(151.4948)),\n",
       " ('litseg.model.decoder.stage_0.2.0.bn2', tensor(-29.9573), tensor(28.6254)),\n",
       " ('litseg.model.decoder.stage_0.2.0.relu2', tensor(0.), tensor(52.1903)),\n",
       " ('litseg.model.decoder.stage_0.2.0.downsample.0',\n",
       "  tensor(-113.8058),\n",
       "  tensor(98.7920)),\n",
       " ('litseg.model.decoder.stage_0.2.0.downsample.1',\n",
       "  tensor(-29.6621),\n",
       "  tensor(29.5518)),\n",
       " ('litseg.model.decoder.stage_0.2.0.downsample',\n",
       "  tensor(-29.6621),\n",
       "  tensor(29.5518)),\n",
       " ('litseg.model.decoder.stage_0.2.0', tensor(0.), tensor(52.1903)),\n",
       " ('litseg.model.decoder.stage_0.2', tensor(0.), tensor(52.1903)),\n",
       " ('litseg.model.conv_output', tensor(-64.0225), tensor(24.8368)),\n",
       " ('litseg.model', tensor(-64.0225), tensor(24.8368)),\n",
       " ('litseg', tensor(-64.0225), tensor(24.8368))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check intermediate activations of the model\n",
    "insp = torchtrainer.inspector.Inspector(model)\n",
    "insp.start_tracking_activations()\n",
    "\n",
    "model.eval()\n",
    "model.to('cuda')\n",
    "with torch.no_grad():\n",
    "    output = model(ds_valid[0][0][None].to('cuda'))\n",
    "acts = insp.get_activations()\n",
    "\n",
    "stats = []\n",
    "for k, v in acts.items():\n",
    "    if v is not None:\n",
    "        stats.append((k, v.min(), v.max()))\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': 0.0, 'activations': 0.0, 'flops': 0.0, 'memory': 0.4987959861755371, 'time_cpu': 0.017999887466430664, 'time_gpu': 0.03507097625732422, 'info': ['params: M', 'activations: G', 'flops: G', 'memory: GiB', 'time_cpu: s', 'time_gpu: s']}\n",
      "{'params': 0.0, 'activations': 0.0, 'flops': 0.0, 'memory': 3.0346055030822754, 'time_cpu': 0.007999658584594727, 'time_gpu': 0.17833984375, 'info': ['params: M', 'activations: G', 'flops: G', 'memory: GiB', 'time_cpu: s', 'time_gpu: s']}\n"
     ]
    }
   ],
   "source": [
    "# Benchmark model\n",
    "\n",
    "model = torchtrainer.models.resunet.ResUNet((3,3,3), (16,32,64))\n",
    "stats_train = torchtrainer.profiling.benchmark_model(model, (8, 1, 256, 256), no_grad=False, call_backward=True, use_float16=True, return_model_info=False)\n",
    "stats_val = torchtrainer.profiling.benchmark_model(model, (8, 1, 1104, 1376), no_grad=True, call_backward=False, use_float16=True, return_model_info=False)\n",
    "print(stats_train)\n",
    "print(stats_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
