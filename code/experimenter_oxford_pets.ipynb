{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "def cat_list(images, fill_value=0):\n",
    "    max_size = tuple(max(s) for s in zip(*[img.shape for img in images]))\n",
    "    batch_shape = (len(images),) + max_size\n",
    "    batched_imgs = images[0].new(*batch_shape).fill_(fill_value)\n",
    "    for img, pad_img in zip(images, batched_imgs):\n",
    "        pad_img[..., : img.shape[-2], : img.shape[-1]].copy_(img)\n",
    "    return batched_imgs\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images, targets = list(zip(*batch))\n",
    "    batched_imgs = cat_list(images, fill_value=0)\n",
    "    batched_targets = cat_list(targets, fill_value=255)\n",
    "    return batched_imgs, batched_targets\n",
    "\n",
    "root = Path('../data/oxford-iiit-pet/images')\n",
    "files = os.listdir(root)\n",
    "\n",
    "imgs = []\n",
    "for file in files[:8]:\n",
    "    img = ToTensorV2()(image=np.array(Image.open(root/file)))['image']\n",
    "    imgs.append(img)\n",
    "\n",
    "batch = collate_fn(imgs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
